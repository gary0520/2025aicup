{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c42c77",
   "metadata": {},
   "source": [
    "### Ë≥áÊñôËΩâÊèõ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbca5e9",
   "metadata": {},
   "source": [
    "#### ÈÇÑÊ≤íÊúâÁµêÊùüÁ¨¶Ëôü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b494c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished! JSONL with IDs saved at: train_with_id.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_entities(raw_label):\n",
    "    if raw_label.strip() == \"PHI:Null\":\n",
    "        return {}\n",
    "\n",
    "    entity_dict = {}\n",
    "    for item in raw_label.strip().split(\"\\\\n\"):\n",
    "        if not item:\n",
    "            continue\n",
    "        if ':' not in item:\n",
    "            continue\n",
    "        key, value = item.split(\":\", 1)\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        if key not in entity_dict:\n",
    "            entity_dict[key] = []\n",
    "        entity_dict[key].append(value)\n",
    "    return entity_dict\n",
    "\n",
    "def convert_tsv_to_jsonl(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "        for line in infile:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            example_id, text, raw_label = parts\n",
    "            entities = parse_entities(raw_label)\n",
    "            output_obj = {\n",
    "                \"id\": example_id,  # ‚úÖ Âä†‰∏äÈü≥Ê™îÂ∞çÊáâÁöÑ ID\n",
    "                \"input\": f\"Extract sensitive information (e.g., names, dates, professions, etc.) from the following text and respond in JSON format.\\nText: {text}\",\n",
    "                \"output\": json.dumps(entities, ensure_ascii=False)\n",
    "            }\n",
    "            json_line = json.dumps(output_obj, ensure_ascii=False)\n",
    "            outfile.write(json_line + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Finished! JSONL with IDs saved at: {output_path}\")\n",
    "\n",
    "# === Âü∑Ë°åËΩâÊèõ ===\n",
    "convert_tsv_to_jsonl(\"/home/student1/ai/train3/task2_train.tsv\", \"train_with_id.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d74484",
   "metadata": {},
   "source": [
    "### Ë®ìÁ∑¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e977cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29b9685c4804891accec8909541639f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6d0f0082884c35931c441913fa2617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e40ebeab774cd79971cf4dcab90a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/293 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student1/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_207326/2939827369.py:89: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='365' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/730 30:00 < 30:10, 0.20 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.857100</td>\n",
       "      <td>1.843284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.725600</td>\n",
       "      <td>1.759868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.613700</td>\n",
       "      <td>1.756223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.550600</td>\n",
       "      <td>1.772328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.497200</td>\n",
       "      <td>1.808820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHWCAYAAABkNgFvAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfyBJREFUeJzt3XdYU1cDBvD3JoSwNwgKAuJWxG1xW7fWWds6WqV2fHXU7q+1Q0Hb2mrbz9ZWu6y2tdhW666iOHDViauKCwUniIDsFZL7/RETiQQIIZAA7+958khuzr333EPAl5NzzxFEURRBRERERFQLScxdASIiIiIiYzHMEhEREVGtxTBLRERERLUWwywRERER1VoMs0RERERUazHMEhEREVGtxTBLRERERLUWwywRERER1VoMs0RERERUazHMElG1CwsLQ0BAgFH7hoeHQxAE01bIwiQmJkIQBKxcubLGzy0IAsLDw7XPV65cCUEQkJiYWOG+AQEBCAsLM2l9qvJeIaL6iWGWqB4TBMGgR0xMjLmrWu/NmjULgiAgPj6+zDLvvfceBEHAmTNnarBmlXf79m2Eh4fj1KlT5q6KluYPis8++8zcVSGiSrIydwWIyHx+/fVXnee//PILoqOjS21v1apVlc7zww8/QKVSGbXv+++/j3feeadK568LJk2ahCVLliAyMhJz5szRW2b16tUIDg5Gu3btjD7PM888g/Hjx0Mulxt9jIrcvn0bERERCAgIQPv27XVeq8p7hYjqJ4ZZonrs6aef1nl++PBhREdHl9r+sLy8PNjZ2Rl8HplMZlT9AMDKygpWVvxV1a1bNzRt2hSrV6/WG2YPHTqEhIQEfPLJJ1U6j1QqhVQqrdIxqqIq7xUiqp84zICIytW3b1+0bdsWsbGx6N27N+zs7PDuu+8CADZu3Ijhw4ejYcOGkMvlCAoKwvz586FUKnWO8fA4yJIf6X7//fcICgqCXC5Hly5dcOzYMZ199Y2ZFQQBM2fOxIYNG9C2bVvI5XK0adMGUVFRpeofExODzp07w8bGBkFBQfjuu+8MHoe7f/9+PPHEE2jcuDHkcjn8/Pzw2muvIT8/v9T1OTg44NatWxg9ejQcHBzg6emJN998s1RbZGRkICwsDM7OznBxccGUKVOQkZFRYV0Ade/shQsXcOLEiVKvRUZGQhAETJgwAUVFRZgzZw46deoEZ2dn2Nvbo1evXtizZ0+F59A3ZlYURXz44Yfw9fWFnZ0d+vXrh3PnzpXaNz09HW+++SaCg4Ph4OAAJycnDB06FKdPn9aWiYmJQZcuXQAAzz77rHYoi2a8sL4xs7m5uXjjjTfg5+cHuVyOFi1a4LPPPoMoijrlKvO+MFZKSgqee+45NGjQADY2NggJCcHPP/9cqtzvv/+OTp06wdHREU5OTggODsaXX36pfV2hUCAiIgLNmjWDjY0N3N3d0bNnT0RHR5usrkT1Bbs7iKhCaWlpGDp0KMaPH4+nn34aDRo0AKAOPg4ODnj99dfh4OCA3bt3Y86cOcjKysKiRYsqPG5kZCSys7Pxn//8B4IgYOHChRg7diyuXr1aYQ/dgQMHsG7dOkyfPh2Ojo746quv8Pjjj+P69etwd3cHAJw8eRJDhgyBj48PIiIioFQqMW/ePHh6ehp03WvWrEFeXh6mTZsGd3d3HD16FEuWLMHNmzexZs0anbJKpRKDBw9Gt27d8Nlnn2Hnzp34/PPPERQUhGnTpgFQh8JRo0bhwIEDeOmll9CqVSusX78eU6ZMMag+kyZNQkREBCIjI9GxY0edc//555/o1asXGjdujNTUVPz444+YMGECXnjhBWRnZ2P58uUYPHgwjh49Wuqj/YrMmTMHH374IYYNG4Zhw4bhxIkTGDRoEIqKinTKXb16FRs2bMATTzyBwMBA3LlzB9999x369OmDuLg4NGzYEK1atcK8efMwZ84cvPjii+jVqxcAoHv37nrPLYoiRo4ciT179uC5555D+/btsX37drz11lu4desW/ve//+mUN+R9Yaz8/Hz07dsX8fHxmDlzJgIDA7FmzRqEhYUhIyMDr7zyCgAgOjoaEyZMQP/+/fHpp58CAM6fP4+DBw9qy4SHh2PBggV4/vnn0bVrV2RlZeH48eM4ceIEBg4cWKV6EtU7IhHRfTNmzBAf/rXQp08fEYD47bffliqfl5dXatt//vMf0c7OTiwoKNBumzJliujv7699npCQIAIQ3d3dxfT0dO32jRs3igDEzZs3a7fNnTu3VJ0AiNbW1mJ8fLx22+nTp0UA4pIlS7TbRowYIdrZ2Ym3bt3Sbrt8+bJoZWVV6pj66Lu+BQsWiIIgiNeuXdO5PgDivHnzdMp26NBB7NSpk/b5hg0bRADiwoULtduKi4vFXr16iQDEFStWVFinLl26iL6+vqJSqdRui4qKEgGI3333nfaYhYWFOvvdu3dPbNCggTh16lSd7QDEuXPnap+vWLFCBCAmJCSIoiiKKSkporW1tTh8+HBRpVJpy7377rsiAHHKlCnabQUFBTr1EkX191oul+u0zbFjx8q83offK5o2+/DDD3XKjRs3ThQEQec9YOj7Qh/Ne3LRokVlllm8eLEIQFy1apV2W1FRkRgaGio6ODiIWVlZoiiK4iuvvCI6OTmJxcXFZR4rJCREHD58eLl1IiLDcJgBEVVILpfj2WefLbXd1tZW+3V2djZSU1PRq1cv5OXl4cKFCxUe96mnnoKrq6v2uaaX7urVqxXuO2DAAAQFBWmft2vXDk5OTtp9lUoldu7cidGjR6Nhw4back2bNsXQoUMrPD6ge325ublITU1F9+7dIYoiTp48War8Sy+9pPO8V69eOteydetWWFlZaXtqAfUY1Zdfftmg+gDqcc43b97Evn37tNsiIyNhbW2NJ554QntMa2trAIBKpUJ6ejqKi4vRuXNnvUMUyrNz504UFRXh5Zdf1hma8eqrr5YqK5fLIZGo/1tRKpVIS0uDg4MDWrRoUenzamzduhVSqRSzZs3S2f7GG29AFEVs27ZNZ3tF74uq2Lp1K7y9vTFhwgTtNplMhlmzZiEnJwd79+4FALi4uCA3N7fcIQMuLi44d+4cLl++XOV6EdV3DLNEVKFGjRppw1FJ586dw5gxY+Ds7AwnJyd4enpqbx7LzMys8LiNGzfWea4Jtvfu3av0vpr9NfumpKQgPz8fTZs2LVVO3zZ9rl+/jrCwMLi5uWnHwfbp0wdA6euzsbEpNXyhZH0A4Nq1a/Dx8YGDg4NOuRYtWhhUHwAYP348pFIpIiMjAQAFBQVYv349hg4dqvOHwc8//4x27dppx2N6enri77//Nuj7UtK1a9cAAM2aNdPZ7unpqXM+QB2c//e//6FZs2aQy+Xw8PCAp6cnzpw5U+nzljx/w4YN4ejoqLNdM8OGpn4aFb0vquLatWto1qyZNrCXVZfp06ejefPmGDp0KHx9fTF16tRS43bnzZuHjIwMNG/eHMHBwXjrrbcsfko1IkvFMEtEFSrZQ6mRkZGBPn364PTp05g3bx42b96M6Oho7RhBQ6ZXKuuuefGhG3tMva8hlEolBg4ciL///htvv/02NmzYgOjoaO2NSg9fX03NAODl5YWBAwfir7/+gkKhwObNm5GdnY1JkyZpy6xatQphYWEICgrC8uXLERUVhejoaDz66KPVOu3Vxx9/jNdffx29e/fGqlWrsH37dkRHR6NNmzY1Nt1Wdb8vDOHl5YVTp05h06ZN2vG+Q4cO1Rkb3bt3b1y5cgU//fQT2rZtix9//BEdO3bEjz/+WGP1JKoreAMYERklJiYGaWlpWLduHXr37q3dnpCQYMZaPeDl5QUbGxu9iwyUt/CAxr///otLly7h559/xuTJk7Xbq3K3ub+/P3bt2oWcnByd3tmLFy9W6jiTJk1CVFQUtm3bhsjISDg5OWHEiBHa19euXYsmTZpg3bp1OkMD5s6da1SdAeDy5cto0qSJdvvdu3dL9XauXbsW/fr1w/Lly3W2Z2RkwMPDQ/u8Miu6+fv7Y+fOncjOztbpndUMY9HUryb4+/vjzJkzUKlUOr2z+upibW2NESNGYMSIEVCpVJg+fTq+++47fPDBB9pPBtzc3PDss8/i2WefRU5ODnr37o3w8HA8//zzNXZNRHUBe2aJyCiaHrCSPV5FRUVYunSpuaqkQyqVYsCAAdiwYQNu376t3R4fH19qnGVZ+wO61yeKos70SpU1bNgwFBcXY9myZdptSqUSS5YsqdRxRo8eDTs7OyxduhTbtm3D2LFjYWNjU27djxw5gkOHDlW6zgMGDIBMJsOSJUt0jrd48eJSZaVSaake0DVr1uDWrVs62+zt7QHAoCnJhg0bBqVSia+//lpn+//+9z8IgmDw+GdTGDZsGJKTk/HHH39otxUXF2PJkiVwcHDQDkFJS0vT2U8ikWgXsigsLNRbxsHBAU2bNtW+TkSGY88sERmle/fucHV1xZQpU7RLrf766681+nFuRcLDw7Fjxw706NED06ZN04aitm3bVriUasuWLREUFIQ333wTt27dgpOTE/76668qjb0cMWIEevTogXfeeQeJiYlo3bo11q1bV+nxpA4ODhg9erR23GzJIQYA8Nhjj2HdunUYM2YMhg8fjoSEBHz77bdo3bo1cnJyKnUuzXy5CxYswGOPPYZhw4bh5MmT2LZtm05vq+a88+bNw7PPPovu3bvj33//xW+//abTowsAQUFBcHFxwbfffgtHR0fY29ujW7duCAwMLHX+ESNGoF+/fnjvvfeQmJiIkJAQ7NixAxs3bsSrr76qc7OXKezatQsFBQWlto8ePRovvvgivvvuO4SFhSE2NhYBAQFYu3YtDh48iMWLF2t7jp9//nmkp6fj0Ucfha+vL65du4YlS5agffv22vG1rVu3Rt++fdGpUye4ubnh+PHjWLt2LWbOnGnS6yGqDxhmicgo7u7u2LJlC9544w28//77cHV1xdNPP43+/ftj8ODB5q4eAKBTp07Ytm0b3nzzTXzwwQfw8/PDvHnzcP78+QpnW5DJZNi8eTNmzZqFBQsWwMbGBmPGjMHMmTMREhJiVH0kEgk2bdqEV199FatWrYIgCBg5ciQ+//xzdOjQoVLHmjRpEiIjI+Hj44NHH31U57WwsDAkJyfju+++w/bt29G6dWusWrUKa9asQUxMTKXr/eGHH8LGxgbffvst9uzZg27dumHHjh0YPny4Trl3330Xubm5iIyMxB9//IGOHTvi77//LrUcsUwmw88//4zZs2fjpZdeQnFxMVasWKE3zGrabM6cOfjjjz+wYsUKBAQEYNGiRXjjjTcqfS0ViYqK0rvIQkBAANq2bYuYmBi88847+Pnnn5GVlYUWLVpgxYoVCAsL05Z9+umn8f3332Pp0qXIyMiAt7c3nnrqKYSHh2uHJ8yaNQubNm3Cjh07UFhYCH9/f3z44Yd46623TH5NRHWdIFpSNwoRUQ0YPXo0p0UiIqojOGaWiOq0h5eevXz5MrZu3Yq+ffuap0JERGRS7JklojrNx8cHYWFhaNKkCa5du4Zly5ahsLAQJ0+eLDV3KhER1T4cM0tEddqQIUOwevVqJCcnQy6XIzQ0FB9//DGDLBFRHcGeWSIiIiKqtThmloiIiIhqLYZZIiIiIqq16t2YWZVKhdu3b8PR0bFSSyoSERERUc0QRRHZ2dlo2LChzvLR+tS7MHv79m34+fmZuxpEREREVIEbN27A19e33DL1Lsxqlhu8ceMGnJycDNpHoVBgx44dGDRoEGQyWXVWr85h2xmPbVc1bD/jse2qhu1nPLad8epa22VlZcHPz0+b28pT78KsZmiBk5NTpcKsnZ0dnJyc6sQbpCax7YzHtqsatp/x2HZVw/YzHtvOeHW17QwZEsobwIiIiIio1mKYJSIiIqJai2GWiIiIiGqtejdmloiIiGonURRRXFwMpVJp7qpYHIVCASsrKxQUFNSa9pHJZJBKpVU+DsMsERERWbyioiIkJSUhLy/P3FWxSKIowtvbGzdu3Kg18+gLggBfX184ODhU6TgMs0RERGTRVCoVEhISIJVK0bBhQ1hbW9eawFZTVCoVcnJy4ODgUOEiA5ZAFEXcvXsXN2/eRLNmzarUQ8swS0RERBatqKgIKpUKfn5+sLOzM3d1LJJKpUJRURFsbGxqRZgFAE9PTyQmJkKhUFQpzNaOqyUiIqJ6r7aENDKMqXrX+a4gIiIiolqLwwyqmVIl4mhCOlKyC+DlaIOugW6QSjjOh4iIiMgUGGarUdTZJERsjkNSZoF2m4+zDeaOaI0hbX3MWDMiIqL6qS50MgUEBODVV1/Fq6++au6qWASG2WoSdTYJ01adgPjQ9uTMAkxbdQLLnu7IQEtERFSDarqTqaIxoXPnzkV4eHilj3vs2DHY29sbWSu1vn37on379li8eHGVjmMJOGa2GihVIiI2x5UKsgC02yI2x0Gp0leCiIiITE3TyVQyyAIPOpmiziaZ/JxJSUnax+LFi+Hk5KSz7c0339SW1SwIYQhPT0/O6lACw2w1OJqQXuqHpSQRQFJmAY4mpNdcpYiIiOoQURSRV1Rs0CO7QIG5m86V28kUvikO2QUKg44nioZ1Rnl7e2sfzs7OEARB+/zChQtwdHTEtm3b0KlTJ8jlchw4cABXrlzBqFGj0KBBAzg4OKBLly7YuXOnznEDAgJ0elQFQcCPP/6Ip59+Gg4ODmjWrBk2bdpkXMPe99dff6FNmzaQy+UICAjA559/rvP60qVL0axZM9jY2KBBgwYYN26c9rW1a9ciODgYtra2cHd3x4ABA5Cbm1ul+pSHwwyqQUp22UHWmHJERESkK1+hROs5201yLBFAclYBgsN3GFQ+bt5g2FmbJkK98847+Oyzz9CkSRO4urrixo0bGDZsGD766CPI5XL88ssvGDFiBC5evIjGjRuXeZz58+dj7ty5+OKLL/DNN99g0qRJuHbtGtzc3Cpdp9jYWDz55JMIDw/HU089hX/++QfTp0+Hu7s7wsLCcPz4ccyaNQu//vorunfvjvT0dOzfvx+Aujd6woQJWLhwIcaMGYPs7Gzs37/f4D8AjMEwWw28HG1MWo6IiIjqpnnz5mHgwIHa525ubggJCdE+nz9/PtavX49NmzZh5syZZR5nypQpGDduHJycnPDxxx/jq6++wtGjRzFkyJBK1+mLL75A//798cEHHwAAmjdvjri4OCxatAhhYWG4fv067O3t8dhjj8HR0RH+/v7o0KEDAHWYLS4uxtixY+Hv7w8ACA4OrnQdKoNhthp0DXSDj7MNkjML9H6kIQDwdlbfQUlERESVZyuTIm7eYIPKHk1IR9iKYxWWW/lsF4P+b7aVGb9a1cM6d+6s8zwnJwfh4eH4+++/tcEwPz8f169fL/c4JQOjvb09nJyckJKSYlSdzp8/j1GjRuls69GjBxYvXgylUomBAwfC398fTZo0wZAhQzBkyBCMGTMGdnZ2CAkJQf/+/REcHIzBgwdj0KBBGDduHFxdXY2qiyE4ZrYaSCUC5o5orfc1zX2Nc0e0rnVTgRAREVkKQRBgZ21l0KNXM0/4ONugrP91BahnNejVzNOg45lq5SoApWYlePPNN7F+/Xp8/PHH2L9/P06dOoXg4GAUFRWVexyZTKZ7TYIAlUplsnqW5OjoiBMnTmD16tXw8fHBnDlzEBISgoyMDEilUkRHR2Pbtm1o3bo1lixZghYtWiAhIaFa6gIwzFabIW19sOzpjvB0lOts93a24bRcRERENahkJ9PDMdTSOpkOHjyIsLAwjBkzBsHBwfD29kZiYmKN1qFVq1Y4ePBgqXo1b94cUqm6V9rKygoDBgzAwoULcebMGSQmJmL37t0A1EG6R48eiIiIwMmTJ2FtbY3169dXW305zKAaDWnrg55NPdE2XD1A/aewLujT3NMifliIiIjqE00n08PzzHpb2GJGzZo1w7p16zBixAgIgoAPPvig2npY7969i1OnTuls8/HxwRtvvIEuXbpg/vz5eOqpp3Do0CF8/fXXWLp0KQBgy5YtuHr1Knr37g1XV1ds3boVKpUKLVq0wJEjR7Br1y4MGjQIXl5eOHLkCO7evYtWrVpVyzUADLPVzsHGCrYyKfIVSjT1dGCQJSIiMpMhbX0wsLW3Ra8A9sUXX2Dq1Kno3r07PDw88PbbbyMrK6tazhUZGYnIyEidbfPnz8f777+PP//8E3PmzMH8+fPh4+ODefPmISwsDADg4uKCdevWITw8HAUFBWjWrBlWr16NNm3a4Pz589i3bx8WL16MrKws+Pv74/PPP8fQoUOr5RoAM4fZBQsWYN26dbhw4QJsbW3RvXt3fPrpp2jRokW5+2VkZOC9997DunXrkJ6eDn9/fyxevBjDhg2roZpXjpu9NW5l5CM9rwiN3TnJMRERkblIJQJCg9xr/LxhYWHaMAioV+DSN11VQECA9uN6jRkzZug8f3jYgSiKUKlUOqE3IyOj3PrExMSU+/rjjz+Oxx9/XO9rPXv2LHP/Vq1aISoqqtxjm5pZx8zu3bsXM2bMwOHDhxEdHQ2FQoFBgwaVO7FuUVERBg4ciMTERKxduxYXL17EDz/8gEaNGtVgzSvHzd4aAJCeW2jmmhARERHVLWbtmX04ua9cuRJeXl6IjY1F79699e7z008/IT09Hf/884/2zr2AgIDqrmqVuGrDrMLMNSEiIiKqWyxqzGxmZiYAlLtaxaZNmxAaGooZM2Zg48aN8PT0xMSJE/H2229r77ArqbCwEIWFD3pENV3wCoUCCoVh4VJTztDyD3O1VTfz3ax8o49RW1W17eoztl3VsP2Mx7arGraf8cpqO4VCof0ovbpuhqrtNEMWNO1UG6hUKoiiCIVCUSrDVebnRxCrc32xSlCpVBg5ciQyMjJw4MCBMsu1bNkSiYmJmDRpEqZPn474+HhMnz4ds2bNwty5c0uVDw8PR0RERKntkZGRsLOrmfGr6xIl2JskQf+GKoz0rx1vMCIiIkthZWUFb29v+Pn5wdra2tzVIRMpKirCjRs3kJycjOLiYp3X8vLyMHHiRGRmZsLJyanc41hMmJ02bRq2bduGAwcOwNfXt8xyzZs3R0FBARISErQp/osvvsCiRYuQlJRUqry+nlk/Pz+kpqZW2DgaCoUC0dHRGDhwYKlJiQ2xbO9VfLEzHuM6NsKCMW0qvX9tVtW2q8/YdlXD9jMe265q2H7GK6vtCgoKcOPGDQQEBMDGhkvB6yOKIrKzs+Ho6GjSRR2qU0FBARITE+Hn51fq+5qVlQUPDw+DwqxFDDOYOXMmtmzZgn379pUbZAH1/GcymUynO7pVq1ZITk5GUVFRqb/Y5HI55HL5w4eBTCar9C8ZY/YBAA9HWwBARn5xvf3FZmzbEduuqth+xmPbVQ3bz3gPt51SqYQgCJBIJJBIuN6TPpqhBZp2qg0kEgkEQdD7s1KZnx2zXq0oipg5cybWr1+P3bt3IzAwsMJ9evTogfj4eJ3xIJcuXYKPj4/FfvTA2QyIiIiIqodZw+yMGTOwatUqREZGwtHREcnJyUhOTkZ+fr62zOTJkzF79mzt82nTpiE9PR2vvPIKLl26hL///hsff/xxqTnYLIm7gybMlr+uMhERERFVjlmHGSxbtgyAeuLgklasWKGdWPj69es63eV+fn7Yvn07XnvtNbRr1w6NGjXCK6+8grfffrumql1prnYMs0RERETVwaxh1pB7z/StMBEaGorDhw9XQ42qh/v9YQZZBcVQKFWQSWvHWBYiIiKyfImJiQgMDMS+ffvQo0cPc1enxjFV1QBnWxk0yz7fy2PvLBERUY3bswDYu1D/a3sXql+vBmFhYRAEodRjyJAh1XK+svTt2xevvvpqjZ6zpjDM1gCJROBQAyIiInOSSIE9H5UOtHsXqrdLSi+8ZCpDhgxBUlKSzmP16tXVdr76hmG2hjxY0pZhloiIqMpEESjKNfwROgPo/ZY6uO7+UL1t94fq573fUr9u6LEqOUW/XC6Ht7e3zsPV1RUAMHHiRDz11FM65RUKBTw8PPDLL78AAKKiotCzZ0+4uLjA3d0djz32GK5cuWKadrzvr7/+Qps2bSCXyxEQEIDPP/9c5/WlS5eiWbNmsLGxQYMGDTBu3Djta2vXrkVwcDBsbW3h7u6OAQMGIDc316T1K49FzDNbH7gxzBIREZmOIg/4uKFx++5bpH6U9bwi794GrO2NO/dDJk2ahCeeeAI5OTlwcHAAAGzfvh15eXkYM2YMACA3Nxevv/462rVrh5ycHMyZMwdjxozBqVOnTDKnbGxsLJ588kmEh4fjqaeewj///IPp06fD3d0dYWFhOH78OGbNmoVff/0V3bt3R3p6Ovbv3w8ASEpKwoQJE7Bw4UKMGTMG2dnZ2L9/v0H3RZkKw2wNcbs/zOAewywREVG9smXLFm1Q1Xj33Xfx7rvvYvDgwbC3t8f69evxzDPPAAAiIyMxcuRIODo6AgAef/xxnX1/+ukneHp6Ii4uDm3btq1y/b744gv0798fH3zwAQD1aqtxcXFYtGgRwsLCcP36ddjb2+Oxxx6Do6Mj/P390aFDBwDqMFtcXIyxY8fC398fABAcHFzlOlUGw2wNcbs/12wawywREVHVyezUPaSVdeB/6l5YqTWgLFIPMej5WuXPXQn9+vXTTkeq4ebmBgCwsrLCk08+id9++w3PPPMMcnNzsXHjRvz+++/aspcvX8acOXNw5MgRpKamaheOun79uknC7Pnz5zFq1CidbT169MDixYuhVCoxcOBA+Pv7o0mTJhgyZAiGDBmCMWPGwM7ODiEhIejfvz+Cg4MxePBgDBo0COPGjdMOo6gJHDNbQ9gzS0REZEKCoP6ovzKPQ9+og2y/94AP7qr/3bdIvb0yxxGESlXV3t4eTZs21XlowiygHmqwa9cupKSkYMOGDbC1tdWZ7WDEiBFIT0/HDz/8gCNHjuDIkSMAgKKimskUjo6OOHHiBFavXg0fHx/MmTMHISEhyMjIgFQqRXR0NLZt24bWrVtjyZIlaNGiBRISEmqkbgDDbI3RjJllzywREZEZaGYt6Pce0Oe/6m19/qt+rm+WgxrUvXt3+Pn54Y8//sBvv/2GJ554AjKZDACQlpaGixcv4v3330f//v3RqlUr3Lt3z6Tnb9WqFQ4ePKiz7eDBg2jevDmkUvUsD1ZWVhgwYAAWLlyIM2fOIDExEbt37wYACIKAHj16ICIiAidPnoS1tTXWr19v0jqWh8MMaogmzHKeWSIiIjNQKXWDrIbmuUpZbacuLCxEcnKyzjYrKyt4eHhon0+cOBHffvstLl26hD179mi3u7q6wt3dHd9//z18fHxw/fp1vPPOO0bV4+7duzh16pTONh8fH7zxxhvo0qUL5s+fj6eeegqHDh3C119/jaVLlwJQj/m9evUqevfuDVdXV2zduhUqlQotWrTAkSNHsGvXLgwaNAheXl44cuQI7t69i1atWhlVR2MwzNYQbc9sDsMsERFRjes3u+zXHg64JhYVFQUfHx+dbS1atMCFCxe0zydNmoSPPvoI/v7+Oqt4SSQS/P7775g1axbatm2LFi1a4KuvvkLfvn0rXY/IyEhERkbqbJs/fz7ef/99/Pnnn5gzZw7mz58PHx8fzJs3D2FhYQAAFxcXrFu3DuHh4SgoKECzZs2wevVqtGnTBufPn8e+ffuwePFiZGVlwd/fH59//jmGDh1a6foZi2G2hrBnloiIqP5ZuXIlVq5cWWG5Vq1alTmd1YABAxAXF6ezrWTZgIAAKJVKZGVllXn8mJiYcs//+OOPl5o1QaNnz55l7t+qVStERUWVe+zqxjGzNaTkPLM1OfcaERERUV3GMFtDNGFWoRSRXVhs5toQERER1Q0MszXERiaFnbX6jkBOz0VERERkGgyzNYjTcxERERGZFsNsDdLeBMYwS0REVGm856RuMdX3k2G2BrFnloiIqPI0Cwjk5eWZuSZkSpoVzDQLMxiLU3PVIC5pS0REVHlSqRQuLi5ISUkBANjZ2UGo5JKydZ1KpUJRUREKCgogkVh+X6VKpcLdu3dhZ2cHK6uqxVGG2RpUcnouIiIiMpy3tzcAaAMt6RJFEfn5+bC1ta01QV8ikaBx48ZVri/DbA1yZZglIiIyiiAI8PHxgZeXFxQKhbmrY3EUCgX27duH3r17a4dlWDpra2uT9CIzzNYgd4ZZIiKiKpFKpVUeY1kXSaVSFBcXw8bGptaEWVOx/EEVdYi2Z5ZL2hIRERGZBMNsDWLPLBEREZFpMczWII6ZJSIiIjIthtkapOmZzS4oRlGxysy1ISIiIqr9GGZrkJONDFKJevqJDI6bJSIiIqoyhtkaJJEIcLVT32HIVcCIiIiIqo5htoa52nHcLBEREZGpMMzWMK4CRkRERGQ6DLM1jGGWiIiIyHQYZmsYwywRERGR6TDM1jAunEBERERkOgyzNYxL2hIRERGZDsNsDdMOM8hhmCUiIiKqKobZGqYJs/fYM0tERERUZQyzNUwTZrloAhEREVHVMczWMG3PbG4RRFE0c22IiIiIajeG2RqmWQGsWCUiq6DYzLUhIiIiqt0YZmuYjUwKe2spAHXvLBEREREZj2HWDNwcOG6WiIiIyBQYZs3AzY4LJxARERGZAsOsGZS8CYyIiIiIjMcwawaunJ6LiIiIyCQYZs3AnQsnEBEREZkEw6wZaHtmuaQtERERUZUwzJoBe2aJiIiITINh1gw0CydwzCwRERFR1TDMmoG7A2czICIiIjIFhlkzcLOXA+A8s0RERERVZdYwu2DBAnTp0gWOjo7w8vLC6NGjcfHiRYP3//333yEIAkaPHl19lawGmkUTcgqLUVisNHNtiIiIiGovs4bZvXv3YsaMGTh8+DCio6OhUCgwaNAg5ObmVrhvYmIi3nzzTfTq1asGampaTrZWkEoEAMC9XIWZa0NERERUe1mZ8+RRUVE6z1euXAkvLy/Exsaid+/eZe6nVCoxadIkREREYP/+/cjIyKjmmpqWIAhwtbNGak4h0nOL4O1sY+4qEREREdVKZg2zD8vMzAQAuLm5lVtu3rx58PLywnPPPYf9+/eXW7awsBCFhYXa51lZWQAAhUIBhcKwXlFNOUPLG8LNTobUnEKkZOWhmaetyY5raaqj7eoLtl3VsP2Mx7arGraf8dh2xqtrbVeZ6xBEURSrsS4GU6lUGDlyJDIyMnDgwIEyyx04cADjx4/HqVOn4OHhgbCwMGRkZGDDhg16y4eHhyMiIqLU9sjISNjZ2Zmq+pW25JwE8VkSTGmmREcPi/gWEBEREVmEvLw8TJw4EZmZmXByciq3rMX0zM6YMQNnz54tN8hmZ2fjmWeewQ8//AAPDw+Djjt79my8/vrr2udZWVnw8/PDoEGDKmwcDYVCgejoaAwcOBAymcygfSoSlXUa8efuoHHzNhj2SGOTHNMSVUfb1Rdsu6ph+xmPbVc1bD/jse2MV9faTvNJuiEsIszOnDkTW7Zswb59++Dr61tmuStXriAxMREjRozQblOpVAAAKysrXLx4EUFBQTr7yOVyyOXyUseSyWSV/mYbs09Z3B3VdcrML64Tb7qKmLLt6hu2XdWw/YzHtqsatp/x2HbGqyttV5lrMGuYFUURL7/8MtavX4+YmBgEBgaWW75ly5b4999/dba9//77yM7Oxpdffgk/P7/qrK5Jaeea5ZK2REREREYza5idMWMGIiMjsXHjRjg6OiI5ORkA4OzsDFtb9U1RkydPRqNGjbBgwQLY2Nigbdu2OsdwcXEBgFLbLZ2bnfovDi6cQERERGQ8s4bZZcuWAQD69u2rs33FihUICwsDAFy/fh0SSd1bqMzNgauAEREREVWV2YcZVCQmJqbc11euXGmaytQwzSpgDLNERERExqt7XZ61hJu9JszWjfngiIiIiMyBYdZMNGH2Xl4RVCrOM0tERERkDIZZM3G1V98AplSJyC4oNnNtiIiIiGonhlkzkVtJ4SBXD1lOyy2soDQRERER6cMwa0YlhxoQERERUeUxzJqRJsym5TDMEhERERmDYdaM2DNLREREVDUMs2ak7ZnlXLNERERERmGYNSNtzyzDLBEREZFRGGbNiD2zRERERFXDMGtGXNKWiIiIqGoYZs2IwwyIiIiIqoZh1oxcOcyAiIiIqEoYZs3InT2zRERERFXCMGtGmp7Z3CIlChRKM9eGiIiIqPZhmDUjJxsrWEkEAFw4gYiIiMgYDLNmJAjCg3GzXNKWiIiIqNIYZs3MnUvaEhERERmNYdbMXDnXLBEREZHRGGbNzM2BYZaIiIjIWAyzZsZVwIiIiIiMxzBrZppVwBhmiYiIiCqPYdbM3DnMgIiIiMhoDLNmprkBjEvaEhEREVUew6yZcUlbIiIiIuMxzJqZK8fMEhERERmNYdbMSi6aoFKJZq4NERERUe3CMGtmLvfHzKpEIDNfYebaEBEREdUuDLNmZm0lgaONFQAgnUvaEhEREVUKw6wF4FyzRERERMZhmLUADLNERERExmGYtQBc0paIiIjIOAyzFoA9s0RERETGYZi1AAyzRERERMZhmLUAblwFjIiIiMgoDLMWQLMKWBrDLBEREVGlMMxagJKrgBERERGR4RhmLYC2ZzaHYZaIiIioMhhmLYA7bwAjIiIiMgrDrAXQ9MzmK5TIL1KauTZEREREtQfDrAVwlFtBJhUAAOkcN0tERERkMIZZCyAIAqfnIiIiIjICw6yFcLXj9FxERERElcUwayHcHdgzS0RERFRZDLMWgj2zRERERJXHMGsh3DlmloiIiKjSGGYtBJe0JSIiIqo8hlkLwZ5ZIiIiospjmLUQrlwFjIiIiKjSGGYthGaeWS6aQERERGQ4s4bZBQsWoEuXLnB0dISXlxdGjx6NixcvlrvPDz/8gF69esHV1RWurq4YMGAAjh49WkM1rj5u7JklIiIiqjSzhtm9e/dixowZOHz4MKKjo6FQKDBo0CDk5uaWuU9MTAwmTJiAPXv24NChQ/Dz88OgQYNw69atGqy56WnCbEZeEZQq0cy1ISIiIqodrMx58qioKJ3nK1euhJeXF2JjY9G7d2+9+/z22286z3/88Uf89ddf2LVrFyZPnlxtda1umnlmVSKQma/QhlsiIiIiKptZw+zDMjMzAQBubm4G75OXlweFQlHmPoWFhSgsLNQ+z8rKAgAoFAooFAqDzqEpZ2h5YznZWCGroBh3MnLhaC1U67lqSk21XV3Etqsatp/x2HZVw/YzHtvOeHWt7SpzHYIoihbxmbZKpcLIkSORkZGBAwcOGLzf9OnTsX37dpw7dw42NjalXg8PD0dERESp7ZGRkbCzs6tSnU1t/kkpUgsEzGpTjCAnc9eGiIiIyDzy8vIwceJEZGZmwsmp/FBkMWF22rRp2LZtGw4cOABfX1+D9vnkk0+wcOFCxMTEoF27dnrL6OuZ9fPzQ2pqaoWNo6FQKBAdHY2BAwdCJpMZtI8xnvz+CE7eyMTX40MwuE2DajtPTaqptquL2HZVw/YzHtuuath+xmPbGa+utV1WVhY8PDwMCrMWMcxg5syZ2LJlC/bt22dwkP3ss8/wySefYOfOnWUGWQCQy+WQy+Wltstkskp/s43ZpzLcHdT1zCpU1Yk3YknV3XZ1Gduuath+xmPbVQ3bz3hsO+PVlbarzDWYNcyKooiXX34Z69evR0xMDAIDAw3ab+HChfjoo4+wfft2dO7cuZprWXMeTM9VWEFJIiIiIgLMHGZnzJiByMhIbNy4EY6OjkhOTgYAODs7w9bWFgAwefJkNGrUCAsWLAAAfPrpp5gzZw4iIyMREBCg3cfBwQEODg7muRATcbNX98ym59aNwdtERERE1c2s88wuW7YMmZmZ6Nu3L3x8fLSPP/74Q1vm+vXrSEpK0tmnqKgI48aN09nns88+M8clmJSbvbpLnT2zRERERIYx+zCDisTExOg8T0xMrJ7KWABtz2wee2aJiIiIDGHWnlnSxZ5ZIiIiosphmLUgmp7ZexwzS0RERGQQhlkL4nZ/Sds09swSERERGYRh1oK4OajDbIFChfwipZlrQ0RERGT5GGYtiL21FNZS9beEvbNEREREFWOYtSCCIGgXTuC4WSIiIqKKMcxaGFd7jpslIiIiMhTDrIVx1y5pW2TmmhARERFZPoZZC+PKMEtERERkMIZZC8OeWSIiIiLDMcxaGNf7c83ey2OYJSIiIqoIw6yF0cw1m5bDMEtERERUEYZZC+PGnlkiIiIigzHMWhg37dRcDLNEREREFWGYtTDuDppFExhmiYiIiCrCMGthNDeAZeQroFSJZq4NERERkWVjmLUwrnYyAIAoAhkcN0tERERULoZZC2MllcDZVh1oOdcsERERUfkYZi0QF04gIiIiMgzDrAXikrZEREREhmGYtUCcnouIiIjIMAyzFki7cALDLBEREVG5GGYtkHZJW4ZZIiIionIxzFogLmlLREREZBiGWQvkxhvAiIiIiAxiVJi9ceMGbt68qX1+9OhRvPrqq/j+++9NVrH6jGGWiIiIyDBGhdmJEydiz549AIDk5GQMHDgQR48exXvvvYd58+aZtIL1EcMsERERkWGMCrNnz55F165dAQB//vkn2rZti3/++Qe//fYbVq5cacr61Uslw6woimauDREREZHlMirMKhQKyOVyAMDOnTsxcuRIAEDLli2RlJRkutrVU5owW1isQl6R0sy1ISIiIrJcRoXZNm3a4Ntvv8X+/fsRHR2NIUOGAABu374Nd3d3k1awPrKzlsLaSv2t4VADIiIiorIZFWY//fRTfPfdd+jbty8mTJiAkJAQAMCmTZu0ww/IeIIgwJ3jZomIiIgqZGXMTn379kVqaiqysrLg6uqq3f7iiy/Czs7OZJWrz9zsrZGUWYB0zjVLREREVCajembz8/NRWFioDbLXrl3D4sWLcfHiRXh5eZm0gvWV9iawHIZZIiIiorIYFWZHjRqFX375BQCQkZGBbt264fPPP8fo0aOxbNkyk1awvtKEWa4CRkRERFQ2o8LsiRMn0KtXLwDA2rVr0aBBA1y7dg2//PILvvrqK5NWsL5yvb+kbRrHzBIRERGVyagwm5eXB0dHRwDAjh07MHbsWEgkEjzyyCO4du2aSStYX7lzmAERERFRhYwKs02bNsWGDRtw48YNbN++HYMGDQIApKSkwMnJyaQVrK9cNWGWwwyIiIiIymRUmJ0zZw7efPNNBAQEoGvXrggNDQWg7qXt0KGDSStYX3FqLiIiIqKKGTU117hx49CzZ08kJSVp55gFgP79+2PMmDEmq1x9pumZvccwS0RERFQmo8IsAHh7e8Pb2xs3b94EAPj6+nLBBBPS9MzyBjAiIiKishk1zEClUmHevHlwdnaGv78//P394eLigvnz50OlUpm6jvWSpmc2M1+BYiXblIiIiEgfo3pm33vvPSxfvhyffPIJevToAQA4cOAAwsPDUVBQgI8++siklayPXGxlEARAFIF7eQp4OsrNXSUiIiIii2NUmP3555/x448/YuTIkdpt7dq1Q6NGjTB9+nSGWROwkkrgbCtDRp4C9/KKGGaJiIiI9DBqmEF6ejpatmxZanvLli2Rnp5e5UqRmmYVsDTONUtERESkl1FhNiQkBF9//XWp7V9//TXatWtX5UqRmpsdl7QlIiIiKo9RwwwWLlyI4cOHY+fOndo5Zg8dOoQbN25g69atJq1gfebGGQ2IiIiIymVUz2yfPn1w6dIljBkzBhkZGcjIyMDYsWNx7tw5/Prrr6auY73lxrlmiYiIiMpl9DyzDRs2LHWj1+nTp7F8+XJ8//33Va4YPQizXAWMiIiISD+jemapZjDMEhEREZXPrGF2wYIF6NKlCxwdHeHl5YXRo0fj4sWLFe63Zs0atGzZEjY2NggODq6z43QZZomIiIjKZ9Ywu3fvXsyYMQOHDx9GdHQ0FAoFBg0ahNzc3DL3+eeffzBhwgQ899xzOHnyJEaPHo3Ro0fj7NmzNVjzmsEbwIiIiIjKV6kxs2PHji339YyMjEqdPCoqSuf5ypUr4eXlhdjYWPTu3VvvPl9++SWGDBmCt956CwAwf/58REdH4+uvv8a3335bqfNbOt4ARkRERFS+SoVZZ2fnCl+fPHmy0ZXJzMwEALi5uZVZ5tChQ3j99dd1tg0ePBgbNmzQW76wsBCFhYXa51lZWQAAhUIBhUJhUL005QwtbypOcnXHeVpuIYqKiiAIQo2e3xTM1XZ1Aduuath+xmPbVQ3bz3hsO+PVtbarzHUIoiiK1VgXg6lUKowcORIZGRk4cOBAmeWsra3x888/Y8KECdptS5cuRUREBO7cuVOqfHh4OCIiIkptj4yMhJ2dnWkqX00KlcB/j6r/3vi0azFspGauEBEREVENyMvLw8SJE5GZmQknJ6dyyxo9NZepzZgxA2fPni03yBpj9uzZOj25WVlZ8PPzw6BBgypsHA2FQoHo6GgMHDgQMpnMpPUrj1Il4r3YnVAoRVg1bo/BwT6QSmpX76y52q4uYNtVDdvPeGy7qmH7GY9tZ7y61naaT9INYRFhdubMmdiyZQv27dsHX1/fcst6e3uX6oG9c+cOvL299ZaXy+WQy+Wltstkskp/s43Zx1hRZ5MQsTkOCqW64/yNtWfxWXQ85o5ojSFtfWqkDqZUk21X17DtqobtZzy2XdWw/YzHtjNeXWm7ylyDWWczEEURM2fOxPr167F7924EBgZWuE9oaCh27dqlsy06Olq7rG5dEHU2CdNWnUBSZoHO9uTMAkxbdQJRZ5PMVDMiIiIiy2LWMDtjxgysWrUKkZGRcHR0RHJyMpKTk5Gfn68tM3nyZMyePVv7/JVXXkFUVBQ+//xzXLhwAeHh4Th+/DhmzpxpjkswOaVKRMTmOOgbyKzZFrE5DkqVRQx1JiIiIjIrs4bZZcuWITMzE3379oWPj4/28ccff2jLXL9+HUlJD3oiu3fvjsjISHz//fcICQnB2rVrsWHDBrRt29Ycl2ByRxPSS/XIliQCSMoswNGE9JqrFBEREZGFMuuYWUMmUoiJiSm17YknnsATTzxRDTUyv5TssoOsMeWIiIiI6jKz9sxSaV6ONiYtR0RERFSXMcxamK6BbvBxtkFFE3CtO3ETOYXFNVInIiIiIkvFMGthpBIBc0e0BoBSgbbk8zWxNzH0y304lsixs0RERFR/McxaoCFtfbDs6Y7wdtYdSuDtbINvn+6I3198BI1cbHEjPR9PfncIn0ZdQFGxyky1JSIiIjIfi1g0gUob0tYHA1t742hCOlKyC+DlaIOugW7aFcCiXu2FiM1xWBt7E8tiriDm4l0sfqo9Wng7mrnmRERERDWHYdaCSSUCQoPc9b7maCPDZ0+EYECrBnh3/b84n5SFEUsO4K3BLfBcz0BIJAKUKrHMMExERERUFzDM1nJD2nqjo78LZv/1L3ZdSMFHW89j5/k7GBnSEF/videZs9bH2abWLodLREREpA/HzNYBXo42+HFKZ3wyNhh21lIcSUjHexvOcjlcIiIiqvMYZusIQRAwvmtjbHm5J2RS/UMJuBwuERER1TUMs3XMnaxCKJRlB1Uuh0tERER1CcNsHcPlcImIiKg+YZitYwxd5vbXQ9dw5GoaRJHDDYiIiKj24mwGdYxmOdzkzAKUF1OPX7uHp74/jLaNnPB8zyYYFuwDayvdv204tRcRERFZOobZOkazHO60VScgADqBVhND54xojcspOfgr9ibO3srCq3+cwoJt5zE5NACTujWGi501os4mIWJzHKf2IiIiIovGMFsHaZbDfTiMej8URt8c1AKRR67h50PXcCerEIu2X8SS3ZfRNdAN+y6lljquZmqvZU93ZKAlIiIii8AwW0dVtBwuALjZW2Pmo83wQu8m2HI6CcsPJCAuKUtvkAXUvbwC1FN7DWztzSEHREREZHYMs3VYecvhliS3kuLxTr4Y27ERfjqQgPl/ny+zbMmpvQw5NhEREVF14mwGpCUIAjwc5QaV5dReREREZAkYZkmHoVN7GVqOiIiIqDoxzJIOzdRe5Y2G9XaSo2ugW43ViYiIiKgsDLOkQzO1F4AyA62DXIaiYlW110WpEnHoSho2nrqFQ1fSoFTV7AIP5j4/ERERVYw3gFEpZU3t5eFgjZzCYsTfzcGLvx7Hj1M6Q24lrZY6mHueW3Ofn4iIiAzDMEt6lTW116kb9/DM8qPYfzkVMyNPYumkjpBJTdvBH3U2CdNWnSi1gllNzXNr7vMTERGR4TjMgMqkmdprVPtGCA1yh1QioJO/G36c3BnWVhJEx93Bm2tOm/Tjd6VKRMTmOL1L8Wq2RWyOq7aP/M19fiIiIqochlmqtO5NPfDt0x1hJRGw8dRtvLf+X4iiacLd0YR0nY/2H1ZyntvqYO7zExERUeUwzJJRHm3ZAF+O7wCJAPx+7AbmbzlvkkB7LT3XoHLVNc+tocflPLtERESWgWGWjDa8nQ8WjgsBAPx0MAH/i75k9LFUKhF/HruBj8tZfawkLwMXd6is5HJ6ZXXPz3l2iYiILAFvAKMqGdfJF3lFxZiz8Ry+2h0PW2srTOsbVKljxF5LR/imOPx7KxOAeqxuRWNSVxxMQEtvJ7jaWxtd95LyioqxYOsF/Hr4WrnlBADezjacZ5eIiMhCsGeWqmxyaADeGdoSAPBp1AX8cijRoP2SMwvw6u8n8fiyQ/j3ViYc5VZ4f3grLH6qPQSUnudW81wqAXbEpWDol/vxT3xqlet/4vo9DP/qgDbI9mnuqff8GnNHtIZUUt6yEkRERFRT2DNLJvFSnyDkFRbjq93xmLPxHGxlUozt6IsjCemITRXgnpCO0KZekEoEFCiU+HH/VXyz5wryFUoIAvBUZz+8MagFPO8PH5BJhVLzvHrfn+fV19UOs1afxNXUXExafgT/6R2E1wc2h7VV5f42KypW4atdl7E0Jh4qEfB2ssGiJ9qhVzNPvfPMSiUClozvwGm5iIiILAjDLJnMawObI6dQiZ8OJuC/a8/go63nkZGnACDFL5ePw9vZBqNCGmLr2STcSM8HAHTyd0X4iDYI9nXWOVZZ89xqekS3zOqJ+VvisProDXy79woOxqfiy/Ht0cTTwaC6XkzOxmt/nEJcUhYAYEyHRggf0QbOdrJS57+enovwTeeQr1DBxpofZhAREVkShlkyGUEQ8MFjrXAxOQsHr6TdD7IPJGcW4Lt9VwGoe0FnD2uJkSENIQj6P7LXzHOrj521FRaMbYc+zT3x9l//4t9bmXhsyQGEj2iDJzr7QhDU424fDsMAsPzAVXy2/RKKlCq42snw0ZhgDAsu3duqOX9okDviU3Lww/4E/LAvAY+2bFCVZiIiIiITYpglk1KJwJW75U+v5SC3wo7XesPJVlbl8w1p64MQPxe8/sdpHLqahv/+dQZ7L93Foy298NmOizrDBDwd5XC2kSH+bg4AoH9LLyx4PNigmQnCegTip4OJOHQ1DWdvZaJtI+cK9yEiIqLqx89MyaSOJqQjOav86a1yCotx7naWyc7p42yLVc93w9tDWsJKIuDvf5PwxprTpRY/uJtdiPi7OZBbSfDp48H4cUpng6fYauRii+H3e2+XH0gwWd2JiIioahhmyaTMteiAVCJgWt8g/Pmf0ApnGnC2lWFcJ78yhzeU5YVeTQAAm0/fRlJmvtF1JSIiItNhmCWTMrSns7oWHSgsVlU4R21KdqFRy9EG+zqjW6AbilUiVv6TaGQNiYiIyJQYZsmkuga6wcfZpsw5WgUAPtW46EBZPb6vWq3Fy9J1+svtXQjsWWDQ8TW9s5FHriOnsNj4ihIREZFJMMySSUklAuaOaA2g7EUPqnPRgbJ6fJWiBG/IHgRabbm9C4E9HwESqUHHf7SlF5p42CO7oBh/HrthkjoTERGR8RhmyeSGtPXBsqc7wttZN1h6O9tg2dMdq3XRgbJ6hpcox+JzxTi8IVuLd+03qXuGNUG233tAn/8adHyJRMDUnoEAgJ8OJqBYqTLxFRAREVFlcGouqhaaRQcOxadgx/4jGNSrm3YFsOqk6RmetuoEBAAlR89+rRyLpsItvIjfgfl/AKIItJ8IdHupUud4vKMvPt9xETfv5WP7uTsY3o4rghEREZkLe2ap2kglAroFuqGTh4huJVbvqm7l9QwHt2mrfiLej7mnIoFPGgPfPAJsnAnErgTunANUyjKPb2stxTOP+AMAfth/FaJY/g1nREREVH3YM0t1UpnL4cYcAS4CEKSAqARsnIGCTODuefXj5K/qA1g7AA07AL5dAN/OQKPOgOODlb+eCQ3At/uu4tSNDMReu4fOAdVzQxsRERGVj2GW6qxSy+HuXQjs+/TBGFnNmNkerwB+jwA3jwG3jgO3TgBFOUDifvVDw7mxOtj6doanbxc80c4Dv51IwQ/7rzLMEhERmQnDLNUP+m720vy75yOgnwMwYK76uUoJ3L2oDrc3jwG3YoGU80DmdfXjnHpGhA8lMjxh7YfTl5ri7sGR8GzVA3ANBCq5GAMREREZj2GW6geVUv+sBZrnJcfISqRAg9bqR6cp6m0FWcDtkw/C7c1jEHLvor3kKtrjKhC9A4gGYOeuHpJwvwcXjTqphzIQERFRtWCYpfqh3+yyXzNkWi4bJ6BJH/UDUN9AlnEdF2N342BMFDpKryDE6hqEvDTg8nb1Q8Ojxf2xt53U/3q2AqT80SMiIjIF/o9KZAxBAFz90bx/GF491xTzkrLwdu9ATGuR/2Ds7c1jwL1EIPWi+nFqlXpfmR3QsOODcNuoM+DE6b2IiIiMwTBLVAWCIOCFXoF4/c/TWHH4Np7r8yisfTs9KJCbCtw8/iDc3joBFGYB1w6oHxpOvrrhtmF78MeTiIjMas8C9dA7fZ9g7l14fwhfOZ981hD+b0lURY+1a4hPoy7gTlYhNp2+jXGdfB+8aO8BtBiifgCASgWkXirRe3scSIkDsm4CcTeBuI3qchIrSL3aoF2xB4R/c4DG3QD3IN5cRkRENUciVd8kDegG2pI3VVsAs4bZffv2YdGiRYiNjUVSUhLWr1+P0aNHl7vPb7/9hoULF+Ly5ctwdnbG0KFDsWjRIri7u5e7H1F1sbaSIKx7ID6NuoAf91/F4x0bQSgrdEokgFdL9aPjM+pthTnqm8s04fbmMSDnDiTJpxEIAJt2qcvZuqpvKNPOfdtJva0aKFVi6Tl6a2jRCyIisgCKfKDdU0DmTXVwvRULeLcDivOBf5ZUain46mbWMJubm4uQkBBMnToVY8eOrbD8wYMHMXnyZPzvf//DiBEjcOvWLbz00kt44YUXsG7duhqoMZF+E7s2xpLdl3EhORsH4lPRq5mn4TvLHYDAXuoHoL65LPMmiq8dRuKBtWgiT4ck+QyQfw+I36l+aLg3KzFzQmegQRtAKqvStUSdTULE5jgkZRZot/k422DuiNYY0pZje4mIai2VCshPB3LuANnJQE6K+mvtI+XB9sJM3X0vRakfgEUFWcDMYXbo0KEYOnSoweUPHTqEgIAAzJo1CwAQGBiI//znP/j000+rq4pEBnG2k+HJzn5Y+U8iftifULkw+zBBAFz8INp741yiNfyHDYNEEIE7Z7XTguHmcSD9CpB2Wf04vVq9r5WterytJtz6dgGcGxl86qizSZi26gQeXqA3ObMA01adwLKnOzLQEhFZmqI8IOMWXHMuQ7iwGchP0xNYU4DcFEBVbPhxpXL16pcODdT//4gqQCKzqCAL1LIxs6GhoXj33XexdetWDB06FCkpKVi7di2GDRtW5j6FhYUoLCzUPs/KygIAKBQKKBQKg86rKWdoeXqgPrXd5Ed88cuhROy7dBfnbqajeQPHKh1Pp+1kMsArWP3oEKYukJcG4fYJCLdiIdyOVX9dkAlcP6R+3Cc6eENs1Blio07qh3cIYG1f6nxKlYjwTedKBVkAEAEIACI2n0PfZu61YshBfXrvmRrbrmrYfsZj25WgUgJ5aUBuCoT7gVTITQFyUiDkqntShfsBVSjMhgxAbwC4XPGhRTt3wKEBRHsvwMELokMDwN4LooPX/X+9AQcvQO4ECAIk+z+D9OYxiFJrCMoiKHcvgKrXm9V6+ZV5DwiiKOr7v6vGCYJg0JjZNWvWYOrUqSgoKEBxcTFGjBiBv/76CzKZ/o9Ww8PDERERUWp7ZGQk7OzsTFF1Iq0VFyU4lS5BN08VJjZV1ezJRRUcCpPhmnsFrnlX4Jp7BU75NyCBbj1UkCDL1hf37Jvinl0Q7tkHIUfujctZUnwdJ63wNDNbK9HM2SJ+bRAR1TpSZSFsijMgV2RArsiETXEmbO5/Lb//tY0iE9bFWaV+f5dHKchQIHNBgcwFhVbOKJQ5o0DmjAIrFxTK7j+3ckGhzAmiYHhfZvPkDWiVtA7nfcbikvfoUs+rS15eHiZOnIjMzEw4OTmVW7ZWhdm4uDgMGDAAr732GgYPHoykpCS89dZb6NKlC5YvX653H309s35+fkhNTa2wcTQUCgWio6MxcODAMkMz6Vff2u7k9Qw8+cNRyKQC9r7RG56OcqOPZZK2K8qFkHxa3Xt7KxbCreMQcpJLFRPlTkhxaovfk7xxUhWEU6qmyID+nuUvngjGiHaWP9Sgvr33TIltVzVsP+PV2rZTKYG8VHWvac4dPb2pdx5sL8o1+LAiBPWsOJpe07J6Ux28oRDkiN6506RtJ9n/GaT7PoGy9zs6PbFlbTelrKwseHh4GBRma9UwgwULFqBHjx546623AADt2rWDvb09evXqhQ8//BA+PqX/g5XL5ZDLSwcKmUxW6W+2MfuQWn1pu65BnujY2AUnrmfgt2M30bOpZ5VnBKhS28lcgKA+6odG5q0H897ejAVun4RQmIUGd//BKyV+IySoGuCk2AynVEE4qWqGC2JjKGAFHxf7WvW9rC/vverAtqsatp/xLKbtCrMfjDnVe8OUZizqXfV4UkPJ7NTjUB0aqD/Od7z/sb5DA8DhwdeCvad2xcgK//e4/7G8SdtOANDvPUj7/Bc6n9s9OhuQSiFVKSGtpu9TZa6hVoXZvLw8WFnpVlkqVTevhXQwE+GFXk0w7bcTWBpzBd/suaLdbjEzAjg3Uj9aj1I/VypQePssNm7eAGlSLNoL8QiSJCFQcgeBuIOxUvXiDoWiDHEIRMilAUB+l/s3l/ly7lsiql2UxerwqQmiOcklvr4DZJcIqQrDe1EBAbD3fHDDlM5DE1jvfy2v2j0VNaaqS8HXELOG2ZycHMTHx2ufJyQk4NSpU3Bzc0Pjxo0xe/Zs3Lp1C7/88gsAYMSIEXjhhRewbNky7TCDV199FV27dkXDhg3NdRlEOjR/Vz3895WlzghwO7sY/9mQi39vdYVE6AqVCDgjByGSK+ggxKO9JB4dJPFwEXLRAZeAI5eAI/d3dmhwf9Wy+/PfNuygnmqMiKgmieL9XtQyppkquT03FdB7q2sZrB3u95SW6D3VF1jt3LW9qFSzzNrqx48fR79+/bTPX3/9dQDAlClTsHLlSiQlJeH69eva18PCwpCdnY2vv/4ab7zxBlxcXPDoo49yai6yGEqViPl/x+l97cGMAHEY2NrbImYEOJaYjmmrYpGaUwQ3e2t8M7EjMvOLELE5DvsyHbAPIYAS8HGSY1xgEW6d3Yf2Qjz6OVyHb9EV9RiwC1vUDwAQJIBX6xKLO3QBPJqrF4sgorrP1MufKhUPelFL9piW7E3VBNbifMOPK0iA+2NPy/qIX/sv/0C3eGYNs3379i13eMDKlStLbXv55Zfx8ssvV2OtiIx3NCFdZ7GBh4kAkjILcDQhHaFB5l21LvLIdczddBYKpYhWPk74/plO8HNTz/AxsLW33hXANp4Kwet/nsacDBEjWrni894irJNO3F+57Lh6Wd47Z9WPEz+rTyR3Ahp1fDDvrW9n9Q0NRFT3GLL8qSgCBZl6x59Ks5IQmhgHqx8+UW/LS6vc+eVOJcJoA91Q6vhQL6qk4tlbqHZgfziRCaVklx1kS7qenltumFWqRBxJSEdsqgD3hHSENvUyWU9uUbEKEZvP4bcj6k89hrfzwaJx7WBn/eDXgVQi6K3fqPaNYCuTYmbkSWw+fw9ZSk98+/R02Ha//59CVlKJZXmPA7dPAIVZwNUY9UPDNUA33HoHA1bGz/xARDVIqQAUeeqJ+hV5QFGueulTRa76k5lWo9TB9cYRwLeretWo2ycAp0bAyV+B/Z8Dxfp/V0oAeAFAdomNglQ3lD48/lTbm+qldw5tqvsYZolMyMvRxqBys9f9iz+P30TPph7o2cwD7f1cIJOqP4rXXU5Wil8uHzfZzWOpOYWYvuoEjiamQxCANwe1wPS+QRAqcRPXoDbeWB7WGS/+Eou9l+5iyoqjWD6lMxxtZICTD+A0Amg1Ql1YWQzcPf9g5oSbx4DUi8C9RPXj7Fp1Oak14BNyP+Def7j4l31zmSEfZfas3gm9iSyWSnk/YJYMmvq+ztMNpWUF1IdfVxk4mf3Dy29n3dJ9Xe5cordUHVSVdh44HZ+Mdj0Gwsqlkfo1WzcOVaJyMcwSmVDXQDf4ONsgObOgzNsLpBIBSpWI2Gv3EHvtHr7cdRn21lI80sQd7g7W+PP4zVL7VPbmMaVKLDVM4HxSFl785ThuZxbAUW6FLye0x6MtGxh1nb2aeeLX57ri2RXHcDQhHU//eAQrn+0KV3vrhy7WSt3r6h0MdJ6q3pafoe6l0YTbm8fUa4VrvtbcXGbvqRtuG3YEbO7PNWjIR5lUO5h6jGVtoFKWHSJ1gma+/q8rCqjKopq5DkGq7gmV2aqnmnr460tR6umqBCkwbGHpj/5ltqWbRqHAjXtbEdykn3rlQyIDMMwSmZBUImDuiNaYtuoEBOjeL6vpY/xmYge0aeiMg/Gp2B+fin/iU3EvT4FdF1LKPG5lbh7T7dlVc7GVIbeoGAqliCYe9vh+cmc09araTQ2dA9yw+sVH8MzyIzh9MxPjvz+MX5/rCi+nCnqnbV2AoEfVD0A9fu5ewoOhCTePAcn/qm/6uLRN/QDULeDZ8n647QJ0eUE30JYMsn3+q51zkSycJf5holKpbyYqyivRM1myl/J+gNT5OlcbSqVFuXjk1jVIf1mq/jhdG1bvly3jI3bTE+4HTDt1cNR8bW13f5vma/sKXrcrEVZLHEtqXfanJ3sXAhe3qssoi4C8dKDL8zV03VTfMMwSmdiQtj5Y9nTHUoHS+6GhAuO7Nsb4ro2hUomIS8rCb0euYfXRG2UeV3Pz2BPL/kE7Pxf4utrC19UOfm7qf51tZYg6m4Rpq06U6hXOyFcHu7YNnfDbC4/A2dY0PR5tGznjz/+E4unlR3DxTjae/O4QVj3fDT7OtnpvINNLEAC3JupHuyfV2xQFQPKZB+H21nEg47p6yMLd8+pxd4D6P8o9HwExH6tDsXtz9X5/ToYUAjolJUO6cRMglanvXtY8JNISz+9/LXnoealyVdhPZ9vD+5XcVrKMUMZ+JV6r9H4Sy5sXWBNgy/vD5GGiqKdnUs/H4Tpf6wulZexXmbvi9ZAAaADojvssizZIGhIqDS17f5uV3Dzf74e/f5rngEXNTUp1B8MsUTUY0tanzBkBHiaRCGjbyBmPNHEvN8xqnLiRgRM3Mkptd5RLka9QlTt7YlpuERzkpv2xb9bAEWv+0x0TfzyMxLQ8jFhyAFYSAXdzHnzUWekxvzIbwK+r+qGRfafEzWXHgNsngaIc9WuaWVHSLqkfUAcKXwC4V+VLrHv0huD7QVcihZUgweBCBazi3wYkVlUIz2XtpyfkN2h7/w+TBeqPpt2aAgn7gIvb9AfUmmL1cHjU87X1/d7K+18rJTY4ff4y2nV+BFY2TnrK2j3o4bS0Py6qSt8fIvr+YCEyIYZZompS1owAZTH05rGpPQJgbSXFjXt5uHkvHzfT85CWW4TsQmWF+1bXtGCN3e2w9qXuGPXNAdzJKiz1ukkWjHBsALQcrn4A6nGH294Gjv2gDlyqYqD5UKDZQEBUQVmsQNy5f9G6VUtIBagDkqhSf4QsqgBRef+58sFr2jJKPWXEMvYr8ZrJ9nuojvrqqfNcWbmlNEWl+lHGjTwCABsAyM4w7ntVFZrrSI9XPypiZaMTJPV/PF6yx7KssnoCqpWtUTceqRQK3EjZiuBWw+rfuE+VUn+Puua5quLfU0SVxTBLZCEqunlMgHqownvDW5fq4c0rKsavh65hwbYLFZ7H0OnDKsvTUV5q1TONalkwYv/n6iD78EeZjToCff4LlUKBq3e3omW3YdW2drjFMTYEa0O3+rlCUYQD+/aiZ4/ukEkF9WsPB249+5U+dnn7PVSnK7uAK7vVvbiiEmgxHGg7toIAase5Qi1NLVn+lOoWhlkiC2HIzWNzR5QOsgBgZ22Fdr4uBp3H0B7gylIPqSjdK6th0gUjDPkos/trVTtHbSSRQD3Aooq/2hUKZNklqqdLq4k/BPYuVAfZh/8wadieAYiIKsSJ24gsiObmMW9n3cDp7WxT4Uf0mp7dsvo8BajHrnYNdDNdhUswtMf3doYJxjuW91Fmv/egUhZrF504kpAOpaoS67BTzSrrD5N+76m3711o3voRkcVjzyyRhdHcPHYoPgU79h/BoF7dDFoBrCo9u6ZgaI9vxOY4XEvLw6RH/NGgomm8ylLOR5lR7s+oZ5LYcRymXnSCqgHHWBJRFbFnlsgCSSUCugW6oZOHiG7lTWv1kKr07FZVRT3DACARgKyCYny1Ox49PtmNmZEncDwxHeJDg22VKhGHrqRh46lbOHQlzeCeVc3UZCWnRAMe3IAWdTapspdF1a3f7LKHEvT5b91bMIGITI49s0R1TGWmBTMlQ3qGv5rQAQIE/PxPIo4mpmPLmSRsOZOENg2dMKV7AEaGNETMxZRSc/Qa0rOqVImI2Byn9+a5arkBjYiILALDLFEdVNlpwUzF0AUjhrfzwbnbmfjln2vYcOoWzt3Own/XnkHEpnPILSr9sfLDU3sVK1VIyy3C3exC3M0uREp2AWKv3SvVI1uSSW9AIyIii8EwS0QmZWjPcJuGzvh0XDu8M7Ql/jh+A7/8k4jbZYRRTW/rzMiTcLb9F+l5ijKnAatIdU1NRkRE5sEwS0QmV5meYVd7a7zUJwjBjZwx6ccj5ZYtVolIy1VP9C8RAA8HOTwd5fBylEMURcRcSq3wfNU1NRkREZkHwywRWYTUnLLnqC3pv4Nb4InOfnCzt9bp7VWqRPT8dHeFi05U19RkRERkHpzNgIgsgqE9ph0au8LTUV5q2ILmBjQAZc6oUJ1TkxERkXkwzBKRRTDFog9lTU0GAC/1CeI8s0REdRDDLBFZhPJ6Viuz6MOQtj448PajWDW1MyY3U2JEsDcAYM/FFKi4EhgRUZ3DMEtEFsNUiz6UXHRizmOt4GhjhQvJ2dh85nZ1VNuiGLvgBBFRbcUbwIjIoph60QcXOxle7NUEn0dfwv+iL2FYsA9k0rr5d3zU2SSjFpwgIqrN6uZvdCKq1TRTe41q3wihQe5Vvmnr2Z6BcLe3RmJaHv6KvWmiWpbNHL2jXMqXiOor9swSUZ3nILfCtL5B+PDv8/hq12WM7tAINjJptZzLHL2jXMqXiOoz9swSUb3w9CP+8HG2we3MAkQeuV4t5zBX7+jRhHSDl/IlIqprGGaJqF6wkUnx8qPNAABLY+KRW1hs0uNX1DsKqHtHq2PIgaFL9HIpXyKqixhmiajeeKKzL/zd7ZCaU4SV/ySa9Njm7B29l1tkULmfDiTgwOVUiCJnOCCiuoNhlojqDZlUgtcGNAcAfLf3CjLzFSY7tjl6R5My8zFr9UmEb44zqPzpm5l4evkRDP1yP9bG3kRRsapUGaVKxJGEdMSmCjiSkF7jU3txajEiqizeAEZE9cqIkIZYGhOPS3dy8MO+q3hzcAuTHNfQ5XgvJGVjWLCqStODFSiUWH4gAV/vjke+QglBAHoEeeBAfCoEQGeog+Z2r3mj2uDK3Vz8efwGLiRn4801p7Ew6gKmdA/ApG6N4WJn/dDNa1L8cvl4jU7txanFiMgY7JklonpFKhHwxiB1gP3pYAJScwpNclxfV1sYMlHAsr1X0GfhHiw/kKB33G55PZOiKCI67g4G/W8fFm2/iHyFEp38XbF5Zk+ser4bvi1nwYlnQgMQPrINDr3TH/8d0gINnORIyS7Eou0XEbpgN6b8dBQvmXFqL04tRkTGYs8sEdU7g1o3QIivM07fzMTSPVcw5/4yusbKyCvCsyuPQZM7y+odHdm+IQ7Gp+F2ZgHmb4nDV7suY3KoP6Z0D4CHg7zcnsmmXg6I2ByH/ZdTAQANnOR4d1grjAxpCEFQn8GQBSec7WSY3rcpnu/ZBFvO3MYP+xNwPikLey/d1XttNTG1F6cWI6KqYJglonpHEAS8ObgFnll+FKsOX8PzvQLR0MXWqGPlFykxdeUxxKfkwNvJBi/3b4qvd8frBFLvEh+VFyiUWHfiFr7fdwWJaXlYsjse3++7im5N3LDvUmqp4ydnFuClVScgEQCVCFhLJXi+VyBm9GsKe3npX+GaBScqYm0lwdiOvhjToRGW70/Ah1vPl1m25M1rhhy7sipz81x1nJ+IajeGWSKql3o29UC3QDccSUjHkt2XsWBsu0ofo1ipwszIEzhxPQNONlb45bmuaN7AEeO7NC6zd9RGJsXEbo3xVBc/7DiXjG/3XsHpm5l6gyzwoIdXJQL9W3rhg8daI8DD3tjLLkUQBHg6yQ0qW11Te3FqMSKqCo6ZJaJ6SRAEvHX/5q8/j99EQmpupfYXRRGz1/2LXRdSILeS4KewLmjewBGAYcvxSiUChgb7YMOMHvhgeCuDzvl8ryYmDbIaht68Zmi52nZ+IqrdGGaJqN7qHOCGfi08oVSJWLzzUqX2XbT9ItbE3oREAL6e2BGdA9yMqoMgCPBwNG/PaNdAN/g426C80ajezuoe5uo6v5NN2R8UClCPHa6u8xNR7cYwS0T1mmZmg02nb+NCcpZB+6w4mIClMVcAAB+PCcbA1g2qVAdz90xKJQLm3r8JrqxA29C5+npFt5y5jayC8ldkmzuiNW/+IiK9GGaJqF5r28gZw4N9IIrA5zsq7p3dfPo25m1RL1Lw5qDmGN+1cZXrUFHPaE30TA5p64Nleqb2crO3hpVEwInrGXhv/b8mXz1s1/k7eP3P0wCAvs09S50fAP7TpwnnmSWiMjHMElG999rA5pAIQHTcHZy6kVFmuQOXU/H6n6cgisCUUH/M6NfUJOcvr2dU87wmeiaHtPXBgbcfxaqpnTG5mRKrpnbGsfcGYMmEDpAIwO/HbmDh9osmO9/hq2mY/tsJKFUixnRohJ/CuuDg249i9QuP4Mvx7TG6fUMAQMzFu1BxJTAiKgPDLBHVe029HDC2oy8A4LMywtrZW5n4z6/HoVCKGB7sgzkj2mjndzWFsnpGNYse1FTPpFQioFugGzp5iOh2fxaGocE++HhMMABgWcwVfL/vSpXP8+/NTDz/83EUFqswoJUXFo5rB4lE0Ll5LmJkWzjaWOFCcja2/MtFE4hIP07NRUQE4JX+zbDx1C0ciE/FP1dS0T3IQ/vatbRchK04itwiJboHueOLp0KqpZfUkEUPzGV818bIyFfgk20X8PHWC3CxtcaTXfyMOlZ8Sg6mrDiKnMJidAt0w9cTO+pd3tfZToYXejXBF9GXsDj6Eoa19YZVFZYBJqK6ib8ViIgA+LnZYcL98a+Loi7g0JVUbDx1C1Fnk/D0j0eQmlOE1j5O+O6ZTpBbSautHoZM62UuL/UJwn/6NAEAvLPujFFLzN68l4dnlh9Bem4R2vk648cpnWEjK7s9n+0RAFc7Ga6m5mL9yVtG152I6i6GWSKi+2b2awqZVMDJG5mY8MMRvPL7Kby06gRu3MuHu4M1Vk7tAkcbmbmraVbvDGmJ8V38oBKBWatP4WC8/sUe9LmbXYhnlh9FUmYBgjztsfLZrhW2p6ONDC/1CQIAfLnrMoqKVVWqPxHVPQyzRET3nbh+Dwql/huN0nKKcOLavRqukeURBAEfjQnG0LbeKFKq8OIvx3G6nJvmNDLzFZjy01EkpOaikYstVj3fDW721gadc3JoADwd5bh5Lx9/Hr9RxSsgorqGYZaICIBSJSJic1yZrwsAIjbHQcm76iGVCFg8vj16NvVAbpESYSuOIj4lu8zy+UVKPP/zMcQlZcHDQY5Vz3eDj7OtweeztZZi5v2ZI5bsvowChbLK10BEdQfDLBERgKMJ6UjKLHuFLRFAUmYBjiak11ylLJjcSorvnumEED8X3MtT4Okfj+LmvTwoVSIOXUnDxlO3cOhKGvKLlJj2WyyOJd6Do40VfpnaFYFGLMk7vqsfGjrb4E5WIX47cr0arsgyPNx+/OOJqGKczYCICIYvFVtdS8rWRvZyK6wM64InvzuEyyk5GLv0HwBASnahtoyNTIIChQo2MglWhHVB64ZORp1LbiXFrP7N8M66f7F0TzzGd/GDvbxu/RcWdTYJEZvjdP6o8nG2wdwRrbloBFE52DNLRATzLylbW7naW+PX57rBzc4aKdmFOkEWAAoU6hu2XujVBJ0DqraC2eOdfOHvboe03CKs/CexSseyNFFnkzBt1YlSnw4kZxZg2qoTRs0cQVRfMMwSEcEylpStrTwd5RVOIbY29maVPzKXSSV4dUAzAMB3e68gM19RpeNZCs14bX2to9lmyHhtDlGg+ophlogIlrOkbG10NCEdd3MKyy1jqvHGI0MaoZmXA7IKirH8QEKVj2cJTDFeO+psEnp+uhsTfjiMV34/hQk/HEbPT3ezR5fqBYZZIqL7LGVJ2dqmJscbSyUCXh/YHADw04EEpOcWVfmY5mZou0QeuY59l+4i9aE/HDhEgeo7s46e37dvHxYtWoTY2FgkJSVh/fr1GD16dLn7FBYWYt68eVi1ahWSk5Ph4+ODOXPmYOrUqTVTaSKq0yx5SVlLVdPjjQe38Uabhk44dzsL3+27gtlDW5nkuOaSVkGvtsbmM7ex+cxtAEADJznaNHRGS29HRB69XuYQBc2UcgNbe/M9THWWWcNsbm4uQkJCMHXqVIwdO9agfZ588kncuXMHy5cvR9OmTZGUlASViivCEJHpaJaUJcNoxhsnZxboDVUC1L3bphpvLJEIeGNQc0xdeRw//5OI53oEwsup9t2Yl5mnwIJt5/H7sYoXgnC0sUKvZh44n5SNhNRc3MkqxJ2sFOy+kFLufiWHKPA9TXWVWcPs0KFDMXToUIPLR0VFYe/evbh69Src3NS/FAMCAqqpdkREZAjNeONpq05AAHQCbXWNN+7XwgsdGrvg5PUMLI25gvCRbUx27OomiiK2nFFPw6UZMtCzqYd2aWB97bdoXDvtMJecwmJcSMrCudtZ2PZvEg4bMBaZU8pRXVarJunbtGkTOnfujIULF+LXX3+Fvb09Ro4cifnz58PWVv9qMoWFhSgsfPARTlZWFgBAoVBAoTDsTlhNOUPL0wNsO+Ox7aqG7Wc8Y9qufwsPLBkfgg+3XkBy1oPfud7Ocrw3tCX6t/Aw+ffi1UeDMGVlLH47cg3PhvqhoYvhq4pVp/La71ZGPuZuPo+9l9TBtYmHPT4c1RpdAlyx/dwdg9pPLgFCGjkipJEjgjxsDQqzsYlp6NPUzeLn5uXPrfHqWttV5joEURQtYu4OQRAqHDM7ZMgQxMTEYMCAAZgzZw5SU1Mxffp09OvXDytWrNC7T3h4OCIiIkptj4yMhJ2dnamqT0REAFQicCVLQJYCcJIBQU4iqmuopigCX8dJEJ8lQaiXCuODLHfImVIE9iUJ2HpDgiKVAKkgYmAjFQY2EmFV4lbsyrafSgQiTkiRUQSUnocDeDByFrCVigj1EtHLRwU3uf5j1dT3jqgieXl5mDhxIjIzM+HkVP5iK7UqzA4aNAj79+9HcnIynJ2dAQDr1q3DuHHjkJubq7d3Vl/PrJ+fH1JTUytsHA2FQoHo6GgMHDgQMpmschdWz7HtjMe2qxq2n/FqU9vFXruH8T8eg1QiYPusHvB3N28nhVIl4vCVu9h9KBaPhnbCI0GeuJCcjfc3xuHsbfUng539XfDhqDYI8qz8sr76bD93By//fhqA/iEKT3RqhKOJ95CYlgdAPSxkUCsvhHX3Rwc/ZwiCoL9X2EmO94e1xOA2DUxST0PUpveepalrbZeVlQUPDw+Dwqxlf97wEB8fHzRq1EgbZAGgVatWEEURN2/eRLNmzUrtI5fLIZeX/hNUJpNV+pttzD6kxrYzHtuuath+xqsNbfdIUy/0beGJmIt3sXRvAr54qn2VjqdUiUbPZKG7HK0Uv1w+BXtrKfIVSqhEwMnGCu8Oa4UnO/tBYsIuz8fa+8LKSlpqKVzvEkvhqlQi9lxMwU8HE3AwPg3bzt3BtnN3EOLrjE7+rlhxMLHUzXt3sgrx8u+nzTItXW1471mqutJ2lbmGWhVme/TogTVr1iAnJwcODg4AgEuXLkEikcDX19fMtSMiInN4Y2ALxFy8i/WnbmFa3yA0a+Bo1HF0w6iaT4lAWNG+01adKBUIc4uUAIBO/i5Y9nSnalsOuaIp5SQSAf1bNUD/Vg1wITkLPx1IwIZTt3H6ZiZO38zUe0xO7UW1hVkXTcjJycGpU6dw6tQpAEBCQgJOnTqF69evAwBmz56NyZMna8tPnDgR7u7uePbZZxEXF4d9+/bhrbfewtSpU8u8AYyIiOq2YF9nDG7TAKIIfBF90aglXY1deCC/SImrd3Pw3vqzeqcl07idUQB3ez0DVU1IM6XcqPaNEBrkXmb4bOnthIXjQvDPO4/iiU7ldwQZsvoYkbmZtWf2+PHj6Nevn/b566+/DgCYMmUKVq5ciaSkJG2wBQAHBwdER0fj5ZdfRufOneHu7o4nn3wSH374YY3XnYiILMdrA5tj+7k72HZW/dAwpGdVqRIRsTmuzIUHAOC/a8/gWGI6UnOKkJJViDvZBbibVYjswmKD6meJc716OMjRs5kH1sTerLAsp/YiS2bWMNu3b1+Ud//ZypUrS21r2bIloqOjq7FWRERU2ySm5urdrulZfXjcZ25hMW7cy8ON9Hzsv3S3VI/sw7IKirH8QKLe12RSAQplxT3AlhgIDR324OlQvb3KRFVRq8bMEhERPUzTs6qPJmK+ueY0Np++jZsZBbiRnof03KJKn6dfC090D/KAl5Mcno5yNHCygZejHGdvZWLCD0cq3L+6xstWRUWrt2l8su085oxog84BplnFjciUGGaJiKhWO5qQXmHPak6hEn//m6yzzdlWBj83W9hbS3Ek4V6F53mxd5DeYQJdA91rdDlfU6po9TYRgNxKgjO3sjDu20MYHuyDd4a2hJ8b52kny8EwS0REtZqhH9+Pbt8QQ9r6wM/NFn5udnCyUU/9o1SJ6PnpbqPDqDmW8zWlIW19sOzpjmVO7dXR3xVf7LiEP47fwN//JiE67g6m9gzEjH5BcLR5MH1SVaY1I6oKhlkiIqrVDP34/qkujfX2rJoijFYUCGt6ntbKqmhqr08eb4fJoQH4aGscDsan4du9V7Dm+A28Pqg5nursh53n7xg9rRlRVTHMEhFRrVbRuE9DPuY3RRjVBMJD8SnYsf8IBvXqhtCmXrWmd1IztVdZWjd0wqrnumHX+RR8vPU8rqbm4r31Z/HN7njc1jPMo6yb74hMjWGWiIhqNVN9zF9R76ShdekW6Ia08yK61cGP2QVBwIDWDdC7uSdWHb6GxTsv6Q2yABddoJpj1kUTiIiITEHTs+rtrDvkwNvZplI9g4YuPFDfWVtJMLVnID5/MqTcclx0gWoCe2aJiKhOMEXPKlVO3v3leitiiXPsUt3BMEtERHVGReM+ybQMvfnOEufYpbqDwwyIiIjIKJqb78rr+/ax0Dl2qe5gmCUiIiKjaG6+A1BmoH2pT1C9GOqhVIk4dCUNG0/dwqEraVCqKl7imEyDwwyIiIjIaGVNayaTClAoRfx8KBGjOzSCs62snKPUblFnk8w6z65SJeJIQjpiUwW4J6TXqinhTIFhloiIiKpE3813AR52eHzpP7h6NxczI09gRVgXWEnr3gfCUWeTMG3ViVJzHNfUPLu6QVqKXy4fr3cLVtS9dxURERHVuIenNfNxtsUPUzrDVibF/supmL8lztxVNDmlSkTE5ji9i3VotkVsjqu2IQeaIJ300Fy/miAddTapWs5raRhmiYiIqFq0aeiMxePbAwB+PnQNvx5KNGt9TO1oQnqpIFlSdc6za+4gbUkYZomIiKjaDG7jjf8OaQEACN8chwOXU81cI9MxdP7c6phn15xB2tIwzBIREVG1mtYnCGM7NIJSJWL6b7G4cjfH3FWqsryiYhw0MJhXxzy7hgbk6+m5Jj+3pWGYJSIiomolCAI+HhuMjo1dkFVQjOd/Po6MvCJzV8soCqUKvx5KRO+FMfgz9maF5Rs4yatlnl13e2uDys3bHIcluy4jq0Bh8jpYCoZZIiIiqnY2Mim+e6YzGrnYIiE1F9N/OwGFUmXuahlMpRKx6fRtDPhiLz7YeA6pOYXwd7fDcz0DIaDseXZFEUhINW3vaEZeEb7de6XCclKJgNwiJT6PvoSen+zGlzsvIzO/7oVahlkiIiKqEZ6Ocvw4pTPsrKX450oa5m46B1G0jBuUylv0YP/luxj5zQHMWn0S19Ly4OFgjXmj2iD6tT744LHWWPZ0R3g76w4l8HCwhpudNVKyCzHmm4PYdf6OSep5PikLI74+gAPxabC+P9XZw0FaE66XjO+AL8e3R1MvB2QVFON/Oy+h56e78UX0JWTmPQi1tX3BB84zS0RERDWmlY8TvhzfAS/+ehyRR66juZcDwnoEmrVOZS16MKV7APZfvouD8WkAAAe5FV7s3QTP9QyEvfxBhNI3z27XQDdk5BVh2m8ncDQhHc//chxvDmqB6X2DIAjGLWjw95kkvLnmNPIVSvi52eKHyZ2RmJpbqu7eD80z+1i7htj6bxKW7L6MS3dy8NWuy1hxIAFhPQIQ4G6Hz3ZcMtuCD6bAMEtEREQ1amDrBnhnSEss2HYB87bEoYmnA3o09TDLKlZlLXqQlFmAT7ZdAABYSyV4+hF/zOgXBHcHud7jaObZLcndQY5Vz3VDxOZz+O3IdSzafhEXkrOx8PF2sLWWGlxHpUrEZzsuYlmMemhBr2YeWDKhA1zsrNHS2wkDW3vjUHwKduw/gkG9upVqO6lEwIiQhhge7INtZ5Px1a7LuHgnG0t2x+s9X00t+GAqDLNERERU417s3QSXU3KwNvYmXvz1OBzkVkjNKUJNrmJV3lytGrYyKba90gsBHvZGncPaSoKPxgSjlY8Twjedw+bTt3H1bg6+n6weP1yRzDwFZv1+Ensv3QUA/Kd3E7w1uIXOampSiYBugW5IOy+iW6BbmX8ESCQChrfzwdC23og6m4RZv59CsZ4hBSLUwxQiNsdhYGtvi18al2NmiYiIqMYJgoCPxrRFkKc9ChSq+0H2gZpYxaqiuVoBIF+hrLCMIZ5+xB+RLzwCd3trnLudhVFfH8CxxAdzwOobt3rpTjZGfnMAey/dhY1Mgi/Ht8fsYa2qvCywRCLA1V6uN8hq1KZ5atkzS0RERGZhJZEgu6BY72vV3Tt4N7sQq49eN6isqRY96Broho0ze+DFX2IRl5SFiT8cRsTItnCzl5Ua9+piJ0NekRJFxSo0crHF95M7oU1DZ5PUAzDvgg+mxjBLREREZqG+YaqwzNdL9g4+PB71YUqVWOoGrIcDsFIlYv/lu/j96A3sPH+n3J7Jkky56IGvqx3WTgvFW2vP4O8zSXh3/b96y2Xcn22geQMH/P5iKNwMnFfWUIZeU3Us+GBqDLNERERkFob2+kWdTUITT3s0cNIfrMqajUAz5vZ2Rj7+PH4Da47fxK2MfG2Z9n7OSEjNQ1a+Qu+4WQHqmQFMveiBnbUVvp7QAS29HfH5jkvlls0uKIazrcyk5wfUvcQ+zjZIziyo0WuvDgyzREREZBaG9vr9fOgafj50Df7udugS4IauAW7oEuiGAHc7bD+XrHc2guTMAry06gTaNHRCXFIWNNPZOtvKMKZDI4zv6oeW3k7a2QwEQOcYmj7duSNaV8sNUIIgoLN/xUHR0J7pypJKBMwd0dos125qDLNERERkFhX1DgKAnbUUAe52OJ+cjWtpebiWloe195eR9XCwRk5hsd59NdvO3c4CADzSxA0TujbG4DbesJE9mBZrSFsfLHu6Y4VztVYHc49bNee1mxLDLBEREZmFIb2DXzwZgiFtfZBVoEDstXs4lpCOY4npOH0js9QMCGX535MhGNPRt8zXy1r0oLp7JS1h3Kq5rt2UGGaJiIjIbAztHXSykaFfCy/0a+EFAChQKLF0Tzy+KmPi/5IkBgQzfYseVDdLGbdqjms3JYZZIiIiMitN72B5q1g9zEYmRWiQh0Fh1lLvyK9L41bNiYsmEBERkdlpVrHq5FH+KlYlaXo2yyopQD2rgSXfka/pmfZ21g3c3s42tWY5WXNjzywRERHVSnWlZ7MujFs1J4ZZIiIiqrXqyh35tX3cqjkxzBIREVGtxp7N+o1hloiIiGo99mzWX7wBjIiIiIhqLYZZIiIiIqq1GGaJiIiIqNZimCUiIiKiWothloiIiIhqLYZZIiIiIqq1GGaJiIiIqNZimCUiIiKiWothloiIiIhqLYZZIiIiIqq16t1ytqIoAgCysrIM3kehUCAvLw9ZWVmQyWTVVbU6iW1nPLZd1bD9jMe2qxq2n/HYdsara22nyWma3Faeehdms7OzAQB+fn5mrgkRERERlSc7OxvOzs7llhFEQyJvHaJSqXD79m04OjpCEASD9snKyoKfnx9u3LgBJyenaq5h3cK2Mx7brmrYfsZj21UN2894bDvj1bW2E0UR2dnZaNiwISSS8kfF1rueWYlEAl9fX6P2dXJyqhNvEHNg2xmPbVc1bD/jse2qhu1nPLad8epS21XUI6vBG8CIiIiIqNZimCUiIiKiWoth1gByuRxz586FXC43d1VqHbad8dh2VcP2Mx7brmrYfsZj2xmvPrddvbsBjIiIiIjqDvbMEhEREVGtxTBLRERERLUWwywRERER1VoMs0RERERUazHMVuCbb75BQEAAbGxs0K1bNxw9etTcVbI44eHhEARB59GyZUvt6wUFBZgxYwbc3d3h4OCAxx9/HHfu3DFjjc1r3759GDFiBBo2bAhBELBhwwad10VRxJw5c+Dj4wNbW1sMGDAAly9f1imTnp6OSZMmwcnJCS4uLnjuueeQk5NTg1dhHhW1XVhYWKn34pAhQ3TK1Ne2W7BgAbp06QJHR0d4eXlh9OjRuHjxok4ZQ35Wr1+/juHDh8POzg5eXl546623UFxcXJOXYhaGtF/fvn1Lvf9eeuklnTL1sf2WLVuGdu3aaSfzDw0NxbZt27Sv831Xtoraju85NYbZcvzxxx94/fXXMXfuXJw4cQIhISEYPHgwUlJSzF01i9OmTRskJSVpHwcOHNC+9tprr2Hz5s1Ys2YN9u7di9u3b2Ps2LFmrK155ebmIiQkBN98843e1xcuXIivvvoK3377LY4cOQJ7e3sMHjwYBQUF2jKTJk3CuXPnEB0djS1btmDfvn148cUXa+oSzKaitgOAIUOG6LwXV69erfN6fW27vXv3YsaMGTh8+DCio6OhUCgwaNAg5ObmastU9LOqVCoxfPhwFBUV4Z9//sHPP/+MlStXYs6cOea4pBplSPsBwAsvvKDz/lu4cKH2tfrafr6+vvjkk08QGxuL48eP49FHH8WoUaNw7tw5AHzflaeitgP4ngMAiFSmrl27ijNmzNA+VyqVYsOGDcUFCxaYsVaWZ+7cuWJISIje1zIyMkSZTCauWbNGu+38+fMiAPHQoUM1VEPLBUBcv3699rlKpRK9vb3FRYsWabdlZGSIcrlcXL16tSiKohgXFycCEI8dO6Yts23bNlEQBPHWrVs1Vndze7jtRFEUp0yZIo4aNarMfdh2D6SkpIgAxL1794qiaNjP6tatW0WJRCImJydryyxbtkx0cnISCwsLa/YCzOzh9hNFUezTp4/4yiuvlLkP2+8BV1dX8ccff+T7zgiathNFvuc02DNbhqKiIsTGxmLAgAHabRKJBAMGDMChQ4fMWDPLdPnyZTRs2BBNmjTBpEmTcP36dQBAbGwsFAqFTju2bNkSjRs3ZjvqkZCQgOTkZJ32cnZ2Rrdu3bTtdejQIbi4uKBz587aMgMGDIBEIsGRI0dqvM6WJiYmBl5eXmjRogWmTZuGtLQ07WtsuwcyMzMBAG5ubgAM+1k9dOgQgoOD0aBBA22ZwYMHIysrS6enqD54uP00fvvtN3h4eKBt27aYPXs28vLytK+x/dQ9hb///jtyc3MRGhrK910lPNx2GnzPAVbmroClSk1NhVKp1HkDAECDBg1w4cIFM9XKMnXr1g0rV65EixYtkJSUhIiICPTq1Qtnz55FcnIyrK2t4eLiorNPgwYNkJycbJ4KWzBNm+h732leS05OhpeXl87rVlZWcHNzq/dtOmTIEIwdOxaBgYG4cuUK3n33XQwdOhSHDh2CVCpl292nUqnw6quvokePHmjbti0AGPSzmpycrPe9qXmtvtDXfgAwceJE+Pv7o2HDhjhz5gzefvttXLx4EevWrQNQv9vv33//RWhoKAoKCuDg4ID169ejdevWOHXqFN93FSir7QC+5zQYZqnKhg4dqv26Xbt26NatG/z9/fHnn3/C1tbWjDWj+mb8+PHar4ODg9GuXTsEBQUhJiYG/fv3N2PNLMuMGTNw9uxZnbHtZLiy2q/k2Ovg4GD4+Pigf//+uHLlCoKCgmq6mhalRYsWOHXqFDIzM7F27VpMmTIFe/fuNXe1aoWy2q5169Z8z93HYQZl8PDwgFQqLXVH5Z07d+Dt7W2mWtUOLi4uaN68OeLj4+Ht7Y2ioiJkZGTolGE76qdpk/Led97e3qVuQiwuLkZ6ejrb9CFNmjSBh4cH4uPjAbDtAGDmzJnYsmUL9uzZA19fX+12Q35Wvb299b43Na/VB2W1nz7dunUDAJ33X31tP2trazRt2hSdOnXCggULEBISgi+//JLvOwOU1Xb61Nf3HMNsGaytrdGpUyfs2rVLu02lUmHXrl06Y1WotJycHFy5cgU+Pj7o1KkTZDKZTjtevHgR169fZzvqERgYCG9vb532ysrKwpEjR7TtFRoaioyMDMTGxmrL7N69GyqVSvuLjNRu3ryJtLQ0+Pj4AKjfbSeKImbOnIn169dj9+7dCAwM1HndkJ/V0NBQ/Pvvvzp/EERHR8PJyUn7sWddVVH76XPq1CkA0Hn/1df2e5hKpUJhYSHfd0bQtJ0+9fY9Z+470CzZ77//LsrlcnHlypViXFyc+OKLL4ouLi46dwWSKL7xxhtiTEyMmJCQIB48eFAcMGCA6OHhIaakpIiiKIovvfSS2LhxY3H37t3i8ePHxdDQUDE0NNTMtTaf7Oxs8eTJk+LJkydFAOIXX3whnjx5Urx27ZooiqL4ySefiC4uLuLGjRvFM2fOiKNGjRIDAwPF/Px87TGGDBkidujQQTxy5Ih44MABsVmzZuKECRPMdUk1pry2y87OFt98803x0KFDYkJCgrhz506xY8eOYrNmzcSCggLtMepr202bNk10dnYWY2JixKSkJO0jLy9PW6ain9Xi4mKxbdu24qBBg8RTp06JUVFRoqenpzh79mxzXFKNqqj94uPjxXnz5onHjx8XExISxI0bN4pNmjQRe/furT1GfW2/d955R9y7d6+YkJAgnjlzRnznnXdEQRDEHTt2iKLI9115yms7vuceYJitwJIlS8TGjRuL1tbWYteuXcXDhw+bu0oW56mnnhJ9fHxEa2trsVGjRuJTTz0lxsfHa1/Pz88Xp0+fLrq6uop2dnbimDFjxKSkJDPW2Lz27NkjAij1mDJliiiK6um5PvjgA7FBgwaiXC4X+/fvL168eFHnGGlpaeKECRNEBwcH0cnJSXz22WfF7OxsM1xNzSqv7fLy8sRBgwaJnp6eokwmE/39/cUXXnih1B+f9bXt9LUbAHHFihXaMob8rCYmJopDhw4VbW1tRQ8PD/GNN94QFQpFDV9Nzauo/a5fvy727t1bdHNzE+Vyudi0aVPxrbfeEjMzM3WOUx/bb+rUqaK/v79obW0tenp6iv3799cGWVHk+6485bUd33MPCKIoijXXD0xEREREZDocM0tEREREtRbDLBERERHVWgyzRERERFRrMcwSERERUa3FMEtEREREtRbDLBERERHVWgyzRERERFRrMcwSERERUa3FMEtEREREtRbDLBGRBbl79y6mTZuGxo0bQy6Xw9vbG4MHD8bBgwcBAIIgYMOGDeatJBGRBbEydwWIiOiBxx9/HEVFRfj555/RpEkT3LlzB7t27UJaWpq5q0ZEZJEEURRFc1eCiIiAjIwMuLq6IiYmBn369Cn1ekBAAK5du6Z97u/vj8TERADAxo0bERERgbi4ODRs2BBTpkzBe++9BysrdZ+FIAhYunQpNm3ahJiYGPj4+GDhwoUYN25cjVwbEVF14TADIiIL4eDgAAcHB2zYsAGFhYWlXj927BgAYMWKFUhKStI+379/PyZPnoxXXnkFcXFx+O6777By5Up89NFHOvt/8MEHePzxx3H69GlMmjQJ48ePx/nz56v/woiIqhF7ZomILMhff/2FF154Afn5+ejYsSP69OmD8ePHo127dgDUPazr16/H6NGjtfsMGDAA/fv3x+zZs7XbVq1ahf/+97+4ffu2dr+XXnoJy5Yt05Z55JFH0LFjRyxdurRmLo6IqBqwZ5aIyII8/vjjuH37NjZt2oQhQ4YgJiYGHTt2xMqVK8vc5/Tp05g3b562Z9fBwQEvvPACkpKSkJeXpy0XGhqqs19oaCh7Zomo1uMNYEREFsbGxgYDBw7EwIED8cEHH+D555/H3LlzERYWprd8Tk4OIiIiMHbsWL3HIiKqy9gzS0Rk4Vq3bo3c3FwAgEwmg1Kp1Hm9Y8eOuHjxIpo2bVrqIZE8+DV/+PBhnf0OHz6MVq1aVf8FEBFVI/bMEhFZiLS0NDzxxBOYOnUq2rVrB0dHRxw/fhwLFy7EqFGjAKhnNNi1axd69OgBuVwOV1dXzJkzB4899hgaN26McePGQSKR4PTp0zh79iw+/PBD7fHXrFmDzp07o2fPnvjtt99w9OhRLF++3FyXS0RkErwBjIjIQhQWFiI8PBw7duzAlStXoFAo4OfnhyeeeALvvvsubG1tsXnzZrz++utITExEo0aNtFNzbd++HfPmzcPJkychk8nQsmVLPP/883jhhRcAqG8A++abb7Bhwwbs27cPPj4++PTTT/Hkk0+a8YqJiKqOYZaIqB7QNwsCEVFdwDGzRERERFRrMcwSERERUa3FG8CIiOoBjigjorqKPbNEREREVGsxzBIRERFRrcUwS0RERES1FsMsEREREdVaDLNEREREVGsxzBIRERFRrcUwS0RERES1FsMsEREREdVa/wdP2TaCfji1KgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoConfig,\n",
    "    TrainingArguments, Trainer, DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "import torch\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "jsonl_path = \"/home/student1/ai/train_with_id.jsonl\"\n",
    "output_dir = \"/home/student1/ai/mistral7b-phi-lora\"\n",
    "\n",
    "# === ËºâÂÖ•Ë≥áÊñôÈõÜ‰∏¶ÂàáÂàÜ ===\n",
    "raw_dataset = load_dataset(\"json\", data_files={\"data\": jsonl_path})[\"data\"]\n",
    "raw_dataset = raw_dataset.shuffle(seed=42)\n",
    "split_dataset = raw_dataset.train_test_split(test_size=0.2)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"validation\": split_dataset[\"test\"]\n",
    "})\n",
    "\n",
    "# === ËºâÂÖ• tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# === ÂÆâÂÖ®ËºâÂÖ•Ê®°ÂûãÁµêÊßã‰∏¶ÈÖçÁΩÆ device_map ===\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "with init_empty_weights():\n",
    "    empty_model = AutoModelForCausalLM.from_config(config, trust_remote_code=True)\n",
    "device_map = infer_auto_device_map(empty_model, max_memory={0: \"22GiB\", \"cpu\": \"32GiB\"}, no_split_module_classes=[\"MistralDecoderLayer\"])\n",
    "\n",
    "# === ËºâÂÖ•Ê®°Âûã‰∏¶Âä†‰∏ä device_map ===\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# === Âä†ÂÖ• LoRA Ê®°ÁµÑ ===\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# === Tokenize Ëº∏ÂÖ•ËàáËº∏Âá∫ ===\n",
    "def tokenize(example):\n",
    "    text = example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "columns_to_remove = [col for col in dataset[\"train\"].column_names if col in [\"input\", \"output\", \"id\"]]\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=columns_to_remove)\n",
    "\n",
    "# === Ë®ìÁ∑¥ÂèÉÊï∏ ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"none\",\n",
    "    overwrite_output_dir=True\n",
    ")\n",
    "\n",
    "# === Âª∫Á´ã Trainer ===\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# === ÈñãÂßãË®ìÁ∑¥ ===\n",
    "trainer.train()\n",
    "\n",
    "# === ÂÑ≤Â≠ò loss ‰∏¶Áπ™Âúñ ===\n",
    "log_df = pd.DataFrame(trainer.state.log_history)\n",
    "log_df.to_csv(f\"{output_dir}/loss_log.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "if \"loss\" in log_df.columns:\n",
    "    train_loss = log_df[log_df[\"loss\"].notnull()]\n",
    "    plt.plot(train_loss[\"step\"], train_loss[\"loss\"], label=\"Train Loss\", marker='o')\n",
    "if \"eval_loss\" in log_df.columns:\n",
    "    eval_loss = log_df[log_df[\"eval_loss\"].notnull()]\n",
    "    plt.plot(eval_loss[\"step\"], eval_loss[\"eval_loss\"], label=\"Eval Loss\", marker='x')\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{output_dir}/loss_plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d21e05",
   "metadata": {},
   "source": [
    "### Êé®Ë´ñÊ∏¨Ë©¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5f2411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c61336e4b4543089424e140a8646847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Cleaned Prediction:\n",
      "\n",
      "{\n",
      "  \"DOCTOR\": [\n",
      "    \"Chen\"\n",
      "  ],\n",
      "  \"DATE\": [\n",
      "    \"January 3rd\"\n",
      "  ],\n",
      "  \"HOSPITAL\": [\n",
      "    \"Taipei General Hospital\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import re\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "\n",
    "# === ËºâÂÖ• tokenizer ËàáÊ®°ÂûãÔºàÂê´ LoRAÔºâ ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === Ê∏¨Ë©¶Ëº∏ÂÖ• ===\n",
    "text = \"We visited Dr. Chen at Taipei General Hospital on January 3rd.\"\n",
    "\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === Âº∑Âåñ promptÔºåÈÅøÂÖçÈáçË§áÁîüÊàê\n",
    "prompt = f\"\"\"You are an information extraction assistant.\n",
    "Extract the following sensitive entities from the input text: {', '.join(phi_labels)}.\n",
    "Only extract information that is explicitly stated in the input text. Do not assume or infer. Respond with a single valid JSON object.\n",
    "\n",
    "Text: {text}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "# === Êé®Ë´ñ ===\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.2,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# === ÂæåËôïÁêÜÔºöÊäΩÂá∫Á¨¨‰∏ÄÊÆµÂêàÊ≥ï JSON ===\n",
    "def extract_first_json(text):\n",
    "    matches = re.findall(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    for m in matches:\n",
    "        try:\n",
    "            return json.loads(m)\n",
    "        except:\n",
    "            continue\n",
    "    return {}\n",
    "\n",
    "result_json = extract_first_json(decoded)\n",
    "\n",
    "# === È°ØÁ§∫‰πæÊ∑®Ëº∏Âá∫ ===\n",
    "print(\"\\n‚úÖ Cleaned Prediction:\\n\")\n",
    "print(json.dumps(result_json, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ed28f",
   "metadata": {},
   "source": [
    "### Êé®Ë´ñÊï¥ÂÄãanswer1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406ab99",
   "metadata": {},
   "source": [
    "### 0.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343a7f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b82133256e49cda5f37e77cc530d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 1 ÊâπÔºåÁ¥ØÁ©ç 4 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 2 ÊâπÔºåÁ¥ØÁ©ç 8 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 3 ÊâπÔºåÁ¥ØÁ©ç 12 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 4 ÊâπÔºåÁ¥ØÁ©ç 16 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 136\u001b[39m\n\u001b[32m    134\u001b[39m batch = data[i:i+batch_size]\n\u001b[32m    135\u001b[39m uids, prompts = \u001b[38;5;28mzip\u001b[39m(*batch)\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m decoded_outputs = \u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m uid, decoded \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(uids, decoded_outputs):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mbatch_predict\u001b[39m\u001b[34m(batch_prompts)\u001b[39m\n\u001b[32m    119\u001b[39m inputs = tokenizer(batch_prompts, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m).to(model.device)\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m decoded_list = [tokenizer.decode(o, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m outputs]\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m decoded_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/utils.py:2326\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2318\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2319\u001b[39m         input_ids=input_ids,\n\u001b[32m   2320\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2321\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2322\u001b[39m         **model_kwargs,\n\u001b[32m   2323\u001b[39m     )\n\u001b[32m   2325\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2326\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2334\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2337\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2338\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2339\u001b[39m         input_ids=input_ids,\n\u001b[32m   2340\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2341\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2342\u001b[39m         **model_kwargs,\n\u001b[32m   2343\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/utils.py:3289\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3287\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3289\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3291\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3292\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3293\u001b[39m     outputs,\n\u001b[32m   3294\u001b[39m     model_kwargs,\n\u001b[32m   3295\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3296\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:842\u001b[39m, in \u001b[36mMistralForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    857\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:566\u001b[39m, in \u001b[36mMistralModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    555\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    556\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    563\u001b[39m         position_embeddings,\n\u001b[32m    564\u001b[39m     )\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:263\u001b[39m, in \u001b[36mMistralDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    261\u001b[39m residual = hidden_states\n\u001b[32m    262\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    266\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:57\u001b[39m, in \u001b[36mMistralMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     down_proj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/accelerate/hooks.py:170\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/accelerate/hooks.py:360\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    353\u001b[39m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    354\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map\n\u001b[32m    356\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map[value.data_ptr()]\n\u001b[32m    357\u001b[39m         ):\n\u001b[32m    358\u001b[39m             \u001b[38;5;28mself\u001b[39m.tied_pointers_to_remove.add((value.data_ptr(), \u001b[38;5;28mself\u001b[39m.execution_device))\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m.execution_device), send_to_device(\n\u001b[32m    370\u001b[39m     kwargs, \u001b[38;5;28mself\u001b[39m.execution_device, skip_keys=\u001b[38;5;28mself\u001b[39m.skip_keys\n\u001b[32m    371\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lin/lib/python3.11/site-packages/accelerate/utils/modeling.py:337\u001b[39m, in \u001b[36mset_module_tensor_to_device\u001b[39m\u001b[34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[39m\n\u001b[32m    335\u001b[39m             module._parameters[tensor_name] = param_cls(new_value, requires_grad=old_value.requires_grad)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     new_value = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    339\u001b[39m     new_value = torch.tensor(value, device=device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "input_file = \"/home/student1/ai/task1_answer.txt\"\n",
    "output_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "batch_size = 4  # ÂèØË™øÊï¥\n",
    "\n",
    "# === ËºâÂÖ•Ê®°ÂûãËàá tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === PHI Ê®ôÁ±§ ===\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === ËÆÄÂèñË≥áÊñô‰∏¶Ë£Ω‰Ωú Prompt ===\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        uid, text = line.strip().split(\"\\t\", 1)\n",
    "        prompt = f\"\"\"You are an information extraction assistant. Extract the following sensitive entities explicitly mentioned in the input text. Respond strictly in JSON format with categories as keys and lists of extracted values.\n",
    "\n",
    "Definitions and examples:\n",
    "- PATIENT, DOCTOR, PERSONALNAME, FAMILYNAME: Person names including patients, doctors, family members. Example: \"Dr. Chen\", \"James\"\n",
    "- PROFESSION: Job titles or professions, e.g., \"pastor\", \"psychologist\"\n",
    "- HOSPITAL: Names of hospitals or medical centers, e.g., \"Taipei General Hospital\"\n",
    "- ORGANIZATION: Names of organizations or companies, e.g., \"Cambridge University\"\n",
    "- STREET: Street addresses or road names, e.g., \"Main Street\"\n",
    "- CITY: City or town names, e.g., \"New York\"\n",
    "- STATE: State or province names, e.g., \"California\", \"New South Wales\"\n",
    "- ZIP: Postal or ZIP codes, e.g., \"90210\"\n",
    "- AGE: Ages or durations of life, e.g., \"25 years old\", \"six months\"\n",
    "- DATE: Calendar dates in any format, e.g., \"June 1, 1990\", \"2023-05-10\"\n",
    "- TIME: Times of day or time periods, e.g., \"09:03 AM\", \"evening\"\n",
    "- DURATION: Lengths of time intervals, e.g., \"two hours\", \"last week\"\n",
    "- ID_NUMBER: Identification numbers such as social security or medical record numbers, e.g., \"A123456789\", \"123-45-6789\"\n",
    "- PHONE, FAX, EMAIL, URL, IPADDRESS: Contact and network info\n",
    "- OTHER: Any other sensitive information not covered above\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        data.append((uid, prompt))\n",
    "\n",
    "# === ÂàÜÊâπÊé®Ë´ñÂáΩÂºè ===\n",
    "def batch_predict(batch_prompts):\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded_list = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "    return decoded_list\n",
    "\n",
    "# === ‰∏ªÊé®Ë´ñÊµÅÁ®ãÔºåÊØèÊâπÂ≠òÊ™î ===\n",
    "predictions = {}\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    uids, prompts = zip(*batch)\n",
    "    decoded_outputs = batch_predict(prompts)\n",
    "\n",
    "    for uid, decoded in zip(uids, decoded_outputs):\n",
    "        try:\n",
    "            json_start = decoded.index(\"{\")\n",
    "            json_str = decoded[json_start:]\n",
    "            parsed = json.loads(json_str)\n",
    "        except Exception:\n",
    "            parsed = {}\n",
    "        predictions[uid] = parsed\n",
    "\n",
    "    # ÊØèÊâπÂØ´Ê™î‰∏ÄÊ¨°ÔºåË¶ÜËìãÊ™îÊ°à\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ {i // batch_size + 1} ÊâπÔºåÁ¥ØÁ©ç {len(predictions)} Á≠ÜÁµêÊûúÂØ´ÂÖ• {output_file}\")\n",
    "\n",
    "print(f\"üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776bc0a",
   "metadata": {},
   "source": [
    "### 0.397\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b04a4418344460a1b66355e33798f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/student1/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 1 ÊâπÔºåÁ¥ØÁ©ç 4 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 2 ÊâπÔºåÁ¥ØÁ©ç 8 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 3 ÊâπÔºåÁ¥ØÁ©ç 12 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 4 ÊâπÔºåÁ¥ØÁ©ç 16 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 5 ÊâπÔºåÁ¥ØÁ©ç 20 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 6 ÊâπÔºåÁ¥ØÁ©ç 24 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 7 ÊâπÔºåÁ¥ØÁ©ç 28 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 8 ÊâπÔºåÁ¥ØÁ©ç 32 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 9 ÊâπÔºåÁ¥ØÁ©ç 36 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 10 ÊâπÔºåÁ¥ØÁ©ç 40 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 11 ÊâπÔºåÁ¥ØÁ©ç 44 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 12 ÊâπÔºåÁ¥ØÁ©ç 48 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 13 ÊâπÔºåÁ¥ØÁ©ç 52 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 14 ÊâπÔºåÁ¥ØÁ©ç 56 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 15 ÊâπÔºåÁ¥ØÁ©ç 60 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 16 ÊâπÔºåÁ¥ØÁ©ç 64 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 17 ÊâπÔºåÁ¥ØÁ©ç 68 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 18 ÊâπÔºåÁ¥ØÁ©ç 72 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 19 ÊâπÔºåÁ¥ØÁ©ç 76 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 20 ÊâπÔºåÁ¥ØÁ©ç 80 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 21 ÊâπÔºåÁ¥ØÁ©ç 84 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 22 ÊâπÔºåÁ¥ØÁ©ç 88 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 23 ÊâπÔºåÁ¥ØÁ©ç 92 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 24 ÊâπÔºåÁ¥ØÁ©ç 96 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 25 ÊâπÔºåÁ¥ØÁ©ç 100 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 26 ÊâπÔºåÁ¥ØÁ©ç 104 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 27 ÊâπÔºåÁ¥ØÁ©ç 108 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 28 ÊâπÔºåÁ¥ØÁ©ç 112 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 29 ÊâπÔºåÁ¥ØÁ©ç 116 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 30 ÊâπÔºåÁ¥ØÁ©ç 120 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 31 ÊâπÔºåÁ¥ØÁ©ç 124 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 32 ÊâπÔºåÁ¥ØÁ©ç 128 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 33 ÊâπÔºåÁ¥ØÁ©ç 132 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 34 ÊâπÔºåÁ¥ØÁ©ç 136 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 35 ÊâπÔºåÁ¥ØÁ©ç 140 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 36 ÊâπÔºåÁ¥ØÁ©ç 144 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 37 ÊâπÔºåÁ¥ØÁ©ç 148 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 38 ÊâπÔºåÁ¥ØÁ©ç 152 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 39 ÊâπÔºåÁ¥ØÁ©ç 156 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 40 ÊâπÔºåÁ¥ØÁ©ç 160 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 41 ÊâπÔºåÁ¥ØÁ©ç 164 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 42 ÊâπÔºåÁ¥ØÁ©ç 168 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 43 ÊâπÔºåÁ¥ØÁ©ç 172 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 44 ÊâπÔºåÁ¥ØÁ©ç 176 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 45 ÊâπÔºåÁ¥ØÁ©ç 180 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 46 ÊâπÔºåÁ¥ØÁ©ç 184 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 47 ÊâπÔºåÁ¥ØÁ©ç 188 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 48 ÊâπÔºåÁ¥ØÁ©ç 192 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 49 ÊâπÔºåÁ¥ØÁ©ç 196 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 50 ÊâπÔºåÁ¥ØÁ©ç 200 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 51 ÊâπÔºåÁ¥ØÁ©ç 204 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 52 ÊâπÔºåÁ¥ØÁ©ç 208 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 53 ÊâπÔºåÁ¥ØÁ©ç 212 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 54 ÊâπÔºåÁ¥ØÁ©ç 216 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 55 ÊâπÔºåÁ¥ØÁ©ç 220 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 56 ÊâπÔºåÁ¥ØÁ©ç 224 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 57 ÊâπÔºåÁ¥ØÁ©ç 228 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 58 ÊâπÔºåÁ¥ØÁ©ç 232 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 59 ÊâπÔºåÁ¥ØÁ©ç 236 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 60 ÊâπÔºåÁ¥ØÁ©ç 240 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 61 ÊâπÔºåÁ¥ØÁ©ç 244 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 62 ÊâπÔºåÁ¥ØÁ©ç 248 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 63 ÊâπÔºåÁ¥ØÁ©ç 252 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 64 ÊâπÔºåÁ¥ØÁ©ç 256 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 65 ÊâπÔºåÁ¥ØÁ©ç 260 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 66 ÊâπÔºåÁ¥ØÁ©ç 264 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 67 ÊâπÔºåÁ¥ØÁ©ç 268 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 68 ÊâπÔºåÁ¥ØÁ©ç 272 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 69 ÊâπÔºåÁ¥ØÁ©ç 276 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 70 ÊâπÔºåÁ¥ØÁ©ç 280 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 71 ÊâπÔºåÁ¥ØÁ©ç 284 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 72 ÊâπÔºåÁ¥ØÁ©ç 288 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 73 ÊâπÔºåÁ¥ØÁ©ç 292 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 74 ÊâπÔºåÁ¥ØÁ©ç 296 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 75 ÊâπÔºåÁ¥ØÁ©ç 300 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 76 ÊâπÔºåÁ¥ØÁ©ç 304 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 77 ÊâπÔºåÁ¥ØÁ©ç 308 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 78 ÊâπÔºåÁ¥ØÁ©ç 312 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 79 ÊâπÔºåÁ¥ØÁ©ç 316 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 80 ÊâπÔºåÁ¥ØÁ©ç 320 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 81 ÊâπÔºåÁ¥ØÁ©ç 324 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 82 ÊâπÔºåÁ¥ØÁ©ç 328 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 83 ÊâπÔºåÁ¥ØÁ©ç 332 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 84 ÊâπÔºåÁ¥ØÁ©ç 336 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 85 ÊâπÔºåÁ¥ØÁ©ç 340 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 86 ÊâπÔºåÁ¥ØÁ©ç 344 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 87 ÊâπÔºåÁ¥ØÁ©ç 348 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 88 ÊâπÔºåÁ¥ØÁ©ç 352 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 89 ÊâπÔºåÁ¥ØÁ©ç 356 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 90 ÊâπÔºåÁ¥ØÁ©ç 360 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 91 ÊâπÔºåÁ¥ØÁ©ç 364 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 92 ÊâπÔºåÁ¥ØÁ©ç 368 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 93 ÊâπÔºåÁ¥ØÁ©ç 372 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 94 ÊâπÔºåÁ¥ØÁ©ç 376 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 95 ÊâπÔºåÁ¥ØÁ©ç 380 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 96 ÊâπÔºåÁ¥ØÁ©ç 384 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 97 ÊâπÔºåÁ¥ØÁ©ç 388 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 98 ÊâπÔºåÁ¥ØÁ©ç 392 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 99 ÊâπÔºåÁ¥ØÁ©ç 396 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 100 ÊâπÔºåÁ¥ØÁ©ç 400 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 101 ÊâπÔºåÁ¥ØÁ©ç 404 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 102 ÊâπÔºåÁ¥ØÁ©ç 408 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 103 ÊâπÔºåÁ¥ØÁ©ç 412 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 104 ÊâπÔºåÁ¥ØÁ©ç 416 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 105 ÊâπÔºåÁ¥ØÁ©ç 420 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 106 ÊâπÔºåÁ¥ØÁ©ç 424 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 107 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 108 ÊâπÔºåÁ¥ØÁ©ç 432 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 109 ÊâπÔºåÁ¥ØÁ©ç 436 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 110 ÊâπÔºåÁ¥ØÁ©ç 440 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 111 ÊâπÔºåÁ¥ØÁ©ç 444 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 112 ÊâπÔºåÁ¥ØÁ©ç 448 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 113 ÊâπÔºåÁ¥ØÁ©ç 452 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 114 ÊâπÔºåÁ¥ØÁ©ç 456 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 115 ÊâπÔºåÁ¥ØÁ©ç 460 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 116 ÊâπÔºåÁ¥ØÁ©ç 464 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 117 ÊâπÔºåÁ¥ØÁ©ç 468 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 118 ÊâπÔºåÁ¥ØÁ©ç 472 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 119 ÊâπÔºåÁ¥ØÁ©ç 476 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 120 ÊâπÔºåÁ¥ØÁ©ç 480 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 121 ÊâπÔºåÁ¥ØÁ©ç 484 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 122 ÊâπÔºåÁ¥ØÁ©ç 488 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 123 ÊâπÔºåÁ¥ØÁ©ç 492 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 124 ÊâπÔºåÁ¥ØÁ©ç 496 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 125 ÊâπÔºåÁ¥ØÁ©ç 500 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 126 ÊâπÔºåÁ¥ØÁ©ç 504 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 127 ÊâπÔºåÁ¥ØÁ©ç 508 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 128 ÊâπÔºåÁ¥ØÁ©ç 512 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 129 ÊâπÔºåÁ¥ØÁ©ç 516 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 130 ÊâπÔºåÁ¥ØÁ©ç 520 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 131 ÊâπÔºåÁ¥ØÁ©ç 524 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 132 ÊâπÔºåÁ¥ØÁ©ç 528 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 133 ÊâπÔºåÁ¥ØÁ©ç 532 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 134 ÊâπÔºåÁ¥ØÁ©ç 536 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 135 ÊâπÔºåÁ¥ØÁ©ç 540 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 136 ÊâπÔºåÁ¥ØÁ©ç 544 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 137 ÊâπÔºåÁ¥ØÁ©ç 548 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 138 ÊâπÔºåÁ¥ØÁ©ç 552 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 139 ÊâπÔºåÁ¥ØÁ©ç 556 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 140 ÊâπÔºåÁ¥ØÁ©ç 560 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 141 ÊâπÔºåÁ¥ØÁ©ç 564 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 142 ÊâπÔºåÁ¥ØÁ©ç 568 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 143 ÊâπÔºåÁ¥ØÁ©ç 572 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 144 ÊâπÔºåÁ¥ØÁ©ç 576 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 145 ÊâπÔºåÁ¥ØÁ©ç 580 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 146 ÊâπÔºåÁ¥ØÁ©ç 584 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 147 ÊâπÔºåÁ¥ØÁ©ç 588 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 148 ÊâπÔºåÁ¥ØÁ©ç 592 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 149 ÊâπÔºåÁ¥ØÁ©ç 596 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 150 ÊâπÔºåÁ¥ØÁ©ç 600 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 151 ÊâπÔºåÁ¥ØÁ©ç 604 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 152 ÊâπÔºåÁ¥ØÁ©ç 608 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 153 ÊâπÔºåÁ¥ØÁ©ç 612 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 154 ÊâπÔºåÁ¥ØÁ©ç 616 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 155 ÊâπÔºåÁ¥ØÁ©ç 620 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 156 ÊâπÔºåÁ¥ØÁ©ç 624 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 157 ÊâπÔºåÁ¥ØÁ©ç 628 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 158 ÊâπÔºåÁ¥ØÁ©ç 632 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 159 ÊâπÔºåÁ¥ØÁ©ç 636 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 160 ÊâπÔºåÁ¥ØÁ©ç 640 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 161 ÊâπÔºåÁ¥ØÁ©ç 644 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 162 ÊâπÔºåÁ¥ØÁ©ç 648 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 163 ÊâπÔºåÁ¥ØÁ©ç 652 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 164 ÊâπÔºåÁ¥ØÁ©ç 656 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 165 ÊâπÔºåÁ¥ØÁ©ç 660 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 166 ÊâπÔºåÁ¥ØÁ©ç 664 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 167 ÊâπÔºåÁ¥ØÁ©ç 668 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 168 ÊâπÔºåÁ¥ØÁ©ç 672 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 169 ÊâπÔºåÁ¥ØÁ©ç 676 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 170 ÊâπÔºåÁ¥ØÁ©ç 680 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 171 ÊâπÔºåÁ¥ØÁ©ç 684 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 172 ÊâπÔºåÁ¥ØÁ©ç 688 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 173 ÊâπÔºåÁ¥ØÁ©ç 692 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 174 ÊâπÔºåÁ¥ØÁ©ç 696 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 175 ÊâπÔºåÁ¥ØÁ©ç 700 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 176 ÊâπÔºåÁ¥ØÁ©ç 704 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 177 ÊâπÔºåÁ¥ØÁ©ç 708 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 178 ÊâπÔºåÁ¥ØÁ©ç 712 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 179 ÊâπÔºåÁ¥ØÁ©ç 716 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 180 ÊâπÔºåÁ¥ØÁ©ç 720 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 181 ÊâπÔºåÁ¥ØÁ©ç 724 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 182 ÊâπÔºåÁ¥ØÁ©ç 728 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 183 ÊâπÔºåÁ¥ØÁ©ç 732 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 184 ÊâπÔºåÁ¥ØÁ©ç 736 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 185 ÊâπÔºåÁ¥ØÁ©ç 740 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 186 ÊâπÔºåÁ¥ØÁ©ç 744 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 187 ÊâπÔºåÁ¥ØÁ©ç 748 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 188 ÊâπÔºåÁ¥ØÁ©ç 752 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 189 ÊâπÔºåÁ¥ØÁ©ç 756 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 190 ÊâπÔºåÁ¥ØÁ©ç 760 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 191 ÊâπÔºåÁ¥ØÁ©ç 764 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 192 ÊâπÔºåÁ¥ØÁ©ç 768 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 193 ÊâπÔºåÁ¥ØÁ©ç 772 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 194 ÊâπÔºåÁ¥ØÁ©ç 775 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº /home/student1/ai/task1_prediction.json\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "input_file = \"/home/student1/ai/task1_answer.txt\"\n",
    "output_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "batch_size = 4  # ÂèØË™øÊï¥\n",
    "\n",
    "# === ËºâÂÖ•Ê®°ÂûãËàá tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === PHI Ê®ôÁ±§ ===\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === ËÆÄÂèñË≥áÊñô‰∏¶Ë£Ω‰Ωú Prompt ===\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        uid, text = line.strip().split(\"\\t\", 1)\n",
    "        prompt = f\"\"\"You are an information extraction assistant. Extract the following sensitive entities explicitly mentioned in the input text. Respond strictly in JSON format with categories as keys and lists of extracted values.\n",
    "\n",
    "Definitions and examples:\n",
    "- PATIENT, DOCTOR, PERSONALNAME, FAMILYNAME: Person names including patients, doctors, family members. Example: \"Dr. Chen\", \"James\"\n",
    "- PROFESSION: Job titles or professions, e.g., \"pastor\", \"psychologist\"\n",
    "- HOSPITAL: Names of hospitals or medical centers, e.g., \"Taipei General Hospital\"\n",
    "- ORGANIZATION: Names of organizations or companies, e.g., \"Cambridge University\"\n",
    "- STREET: Street addresses or road names, e.g., \"Main Street\"\n",
    "- CITY: City or town names, e.g., \"New York\"\n",
    "- STATE: State or province names, e.g., \"California\", \"New South Wales\"\n",
    "- ZIP: Postal or ZIP codes, e.g., \"90210\"\n",
    "- AGE: Ages or durations of life, e.g., \"25 years old\", \"six months\"\n",
    "- DATE: Calendar dates in any format, e.g., \"June 1, 1990\", \"2023-05-10\"\n",
    "- TIME: Times of day or time periods, e.g., \"09:03 AM\", \"evening\", \"morning\"\n",
    "- DURATION: Lengths of time intervals, e.g., \"two hours\", \"last week\"\n",
    "- ID_NUMBER: Identification numbers such as social security or medical record numbers, e.g., \"A123456789\", \"123-45-6789\"\n",
    "- PHONE, FAX, EMAIL, URL, IPADDRESS: Contact and network info\n",
    "- OTHER: Any other sensitive information not covered above\n",
    "- COUNTRY: Countries such as \"United States\", \"Australia\", \"Japan\"\n",
    "- COUNTY: Administrative regions smaller than states but larger than cities, e.g., \"Los Angeles County\", \"Orange County\"\n",
    "- DISTRICT: Smaller political or administrative divisions, e.g., \"Manhattan District\", \"Central District\"\n",
    "- LOCATION-OTHER: Neighborhoods, landmarks, or other places not covered above, e.g., \"Downtown\", \"Central Park\", \"Financial District\"\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        data.append((uid, prompt))\n",
    "\n",
    "# === ÂàÜÊâπÊé®Ë´ñÂáΩÂºè ===\n",
    "def batch_predict(batch_prompts):\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded_list = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "    return decoded_list\n",
    "\n",
    "# === ‰∏ªÊé®Ë´ñÊµÅÁ®ãÔºåÊØèÊâπÂ≠òÊ™î ===\n",
    "predictions = {}\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    uids, prompts = zip(*batch)\n",
    "    decoded_outputs = batch_predict(prompts)\n",
    "\n",
    "    for uid, decoded in zip(uids, decoded_outputs):\n",
    "        try:\n",
    "            json_start = decoded.index(\"{\")\n",
    "            json_str = decoded[json_start:]\n",
    "            parsed = json.loads(json_str)\n",
    "        except Exception:\n",
    "            parsed = {}\n",
    "        predictions[uid] = parsed\n",
    "\n",
    "    # ÊØèÊâπÂØ´Ê™î‰∏ÄÊ¨°ÔºåË¶ÜËìãÊ™îÊ°à\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ {i // batch_size + 1} ÊâπÔºåÁ¥ØÁ©ç {len(predictions)} Á≠ÜÁµêÊûúÂØ´ÂÖ• {output_file}\")\n",
    "\n",
    "print(f\"üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8e399",
   "metadata": {},
   "source": [
    "### 0.3882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d63fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f0abb7b27245a48688573053160f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/student1/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 1 ÊâπÔºåÁ¥ØÁ©ç 4 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 2 ÊâπÔºåÁ¥ØÁ©ç 8 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 3 ÊâπÔºåÁ¥ØÁ©ç 12 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 4 ÊâπÔºåÁ¥ØÁ©ç 16 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 5 ÊâπÔºåÁ¥ØÁ©ç 20 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 6 ÊâπÔºåÁ¥ØÁ©ç 24 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 7 ÊâπÔºåÁ¥ØÁ©ç 28 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 8 ÊâπÔºåÁ¥ØÁ©ç 32 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 9 ÊâπÔºåÁ¥ØÁ©ç 36 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 10 ÊâπÔºåÁ¥ØÁ©ç 40 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 11 ÊâπÔºåÁ¥ØÁ©ç 44 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 12 ÊâπÔºåÁ¥ØÁ©ç 48 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 13 ÊâπÔºåÁ¥ØÁ©ç 52 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 14 ÊâπÔºåÁ¥ØÁ©ç 56 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 15 ÊâπÔºåÁ¥ØÁ©ç 60 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 16 ÊâπÔºåÁ¥ØÁ©ç 64 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 17 ÊâπÔºåÁ¥ØÁ©ç 68 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 18 ÊâπÔºåÁ¥ØÁ©ç 72 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 19 ÊâπÔºåÁ¥ØÁ©ç 76 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 20 ÊâπÔºåÁ¥ØÁ©ç 80 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 21 ÊâπÔºåÁ¥ØÁ©ç 84 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 22 ÊâπÔºåÁ¥ØÁ©ç 88 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 23 ÊâπÔºåÁ¥ØÁ©ç 92 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 24 ÊâπÔºåÁ¥ØÁ©ç 96 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 25 ÊâπÔºåÁ¥ØÁ©ç 100 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 26 ÊâπÔºåÁ¥ØÁ©ç 104 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 27 ÊâπÔºåÁ¥ØÁ©ç 108 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 28 ÊâπÔºåÁ¥ØÁ©ç 112 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 29 ÊâπÔºåÁ¥ØÁ©ç 116 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 30 ÊâπÔºåÁ¥ØÁ©ç 120 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 31 ÊâπÔºåÁ¥ØÁ©ç 124 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 32 ÊâπÔºåÁ¥ØÁ©ç 128 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 33 ÊâπÔºåÁ¥ØÁ©ç 132 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 34 ÊâπÔºåÁ¥ØÁ©ç 136 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 35 ÊâπÔºåÁ¥ØÁ©ç 140 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 36 ÊâπÔºåÁ¥ØÁ©ç 144 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 37 ÊâπÔºåÁ¥ØÁ©ç 148 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 38 ÊâπÔºåÁ¥ØÁ©ç 152 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 39 ÊâπÔºåÁ¥ØÁ©ç 156 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 40 ÊâπÔºåÁ¥ØÁ©ç 160 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 41 ÊâπÔºåÁ¥ØÁ©ç 164 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 42 ÊâπÔºåÁ¥ØÁ©ç 168 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 43 ÊâπÔºåÁ¥ØÁ©ç 172 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 44 ÊâπÔºåÁ¥ØÁ©ç 176 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 45 ÊâπÔºåÁ¥ØÁ©ç 180 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 46 ÊâπÔºåÁ¥ØÁ©ç 184 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 47 ÊâπÔºåÁ¥ØÁ©ç 188 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 48 ÊâπÔºåÁ¥ØÁ©ç 192 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 49 ÊâπÔºåÁ¥ØÁ©ç 196 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 50 ÊâπÔºåÁ¥ØÁ©ç 200 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 51 ÊâπÔºåÁ¥ØÁ©ç 204 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 52 ÊâπÔºåÁ¥ØÁ©ç 208 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 53 ÊâπÔºåÁ¥ØÁ©ç 212 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 54 ÊâπÔºåÁ¥ØÁ©ç 216 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 55 ÊâπÔºåÁ¥ØÁ©ç 220 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 56 ÊâπÔºåÁ¥ØÁ©ç 224 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 57 ÊâπÔºåÁ¥ØÁ©ç 228 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 58 ÊâπÔºåÁ¥ØÁ©ç 232 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 59 ÊâπÔºåÁ¥ØÁ©ç 236 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 60 ÊâπÔºåÁ¥ØÁ©ç 240 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 61 ÊâπÔºåÁ¥ØÁ©ç 244 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 62 ÊâπÔºåÁ¥ØÁ©ç 248 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 63 ÊâπÔºåÁ¥ØÁ©ç 252 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 64 ÊâπÔºåÁ¥ØÁ©ç 256 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 65 ÊâπÔºåÁ¥ØÁ©ç 260 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 66 ÊâπÔºåÁ¥ØÁ©ç 264 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 67 ÊâπÔºåÁ¥ØÁ©ç 268 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 68 ÊâπÔºåÁ¥ØÁ©ç 272 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 69 ÊâπÔºåÁ¥ØÁ©ç 276 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 70 ÊâπÔºåÁ¥ØÁ©ç 280 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 71 ÊâπÔºåÁ¥ØÁ©ç 284 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 72 ÊâπÔºåÁ¥ØÁ©ç 288 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 73 ÊâπÔºåÁ¥ØÁ©ç 292 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 74 ÊâπÔºåÁ¥ØÁ©ç 296 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 75 ÊâπÔºåÁ¥ØÁ©ç 300 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 76 ÊâπÔºåÁ¥ØÁ©ç 304 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 77 ÊâπÔºåÁ¥ØÁ©ç 308 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 78 ÊâπÔºåÁ¥ØÁ©ç 312 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 79 ÊâπÔºåÁ¥ØÁ©ç 316 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 80 ÊâπÔºåÁ¥ØÁ©ç 320 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 81 ÊâπÔºåÁ¥ØÁ©ç 324 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 82 ÊâπÔºåÁ¥ØÁ©ç 328 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 83 ÊâπÔºåÁ¥ØÁ©ç 332 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 84 ÊâπÔºåÁ¥ØÁ©ç 336 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 85 ÊâπÔºåÁ¥ØÁ©ç 340 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 86 ÊâπÔºåÁ¥ØÁ©ç 344 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 87 ÊâπÔºåÁ¥ØÁ©ç 348 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 88 ÊâπÔºåÁ¥ØÁ©ç 352 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 89 ÊâπÔºåÁ¥ØÁ©ç 356 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 90 ÊâπÔºåÁ¥ØÁ©ç 360 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 91 ÊâπÔºåÁ¥ØÁ©ç 364 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 92 ÊâπÔºåÁ¥ØÁ©ç 368 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 93 ÊâπÔºåÁ¥ØÁ©ç 372 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 94 ÊâπÔºåÁ¥ØÁ©ç 376 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 95 ÊâπÔºåÁ¥ØÁ©ç 380 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 96 ÊâπÔºåÁ¥ØÁ©ç 384 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 97 ÊâπÔºåÁ¥ØÁ©ç 388 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 98 ÊâπÔºåÁ¥ØÁ©ç 392 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 99 ÊâπÔºåÁ¥ØÁ©ç 396 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 100 ÊâπÔºåÁ¥ØÁ©ç 400 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 101 ÊâπÔºåÁ¥ØÁ©ç 404 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 102 ÊâπÔºåÁ¥ØÁ©ç 408 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 103 ÊâπÔºåÁ¥ØÁ©ç 412 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 104 ÊâπÔºåÁ¥ØÁ©ç 416 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 105 ÊâπÔºåÁ¥ØÁ©ç 420 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 106 ÊâπÔºåÁ¥ØÁ©ç 424 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 107 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 108 ÊâπÔºåÁ¥ØÁ©ç 432 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 109 ÊâπÔºåÁ¥ØÁ©ç 436 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 110 ÊâπÔºåÁ¥ØÁ©ç 440 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 111 ÊâπÔºåÁ¥ØÁ©ç 444 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 112 ÊâπÔºåÁ¥ØÁ©ç 448 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 113 ÊâπÔºåÁ¥ØÁ©ç 452 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 114 ÊâπÔºåÁ¥ØÁ©ç 456 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 115 ÊâπÔºåÁ¥ØÁ©ç 460 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 116 ÊâπÔºåÁ¥ØÁ©ç 464 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 117 ÊâπÔºåÁ¥ØÁ©ç 468 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 118 ÊâπÔºåÁ¥ØÁ©ç 472 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 119 ÊâπÔºåÁ¥ØÁ©ç 476 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 120 ÊâπÔºåÁ¥ØÁ©ç 480 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 121 ÊâπÔºåÁ¥ØÁ©ç 484 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 122 ÊâπÔºåÁ¥ØÁ©ç 488 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 123 ÊâπÔºåÁ¥ØÁ©ç 492 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 124 ÊâπÔºåÁ¥ØÁ©ç 496 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 125 ÊâπÔºåÁ¥ØÁ©ç 500 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 126 ÊâπÔºåÁ¥ØÁ©ç 504 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 127 ÊâπÔºåÁ¥ØÁ©ç 508 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 128 ÊâπÔºåÁ¥ØÁ©ç 512 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 129 ÊâπÔºåÁ¥ØÁ©ç 516 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 130 ÊâπÔºåÁ¥ØÁ©ç 520 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 131 ÊâπÔºåÁ¥ØÁ©ç 524 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 132 ÊâπÔºåÁ¥ØÁ©ç 528 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 133 ÊâπÔºåÁ¥ØÁ©ç 532 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 134 ÊâπÔºåÁ¥ØÁ©ç 536 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 135 ÊâπÔºåÁ¥ØÁ©ç 540 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 136 ÊâπÔºåÁ¥ØÁ©ç 544 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 137 ÊâπÔºåÁ¥ØÁ©ç 548 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 138 ÊâπÔºåÁ¥ØÁ©ç 552 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 139 ÊâπÔºåÁ¥ØÁ©ç 556 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 140 ÊâπÔºåÁ¥ØÁ©ç 560 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 141 ÊâπÔºåÁ¥ØÁ©ç 564 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 142 ÊâπÔºåÁ¥ØÁ©ç 568 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 143 ÊâπÔºåÁ¥ØÁ©ç 572 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 144 ÊâπÔºåÁ¥ØÁ©ç 576 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 145 ÊâπÔºåÁ¥ØÁ©ç 580 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 146 ÊâπÔºåÁ¥ØÁ©ç 584 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 147 ÊâπÔºåÁ¥ØÁ©ç 588 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 148 ÊâπÔºåÁ¥ØÁ©ç 592 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 149 ÊâπÔºåÁ¥ØÁ©ç 596 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 150 ÊâπÔºåÁ¥ØÁ©ç 600 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 151 ÊâπÔºåÁ¥ØÁ©ç 604 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 152 ÊâπÔºåÁ¥ØÁ©ç 608 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 153 ÊâπÔºåÁ¥ØÁ©ç 612 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 154 ÊâπÔºåÁ¥ØÁ©ç 616 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 155 ÊâπÔºåÁ¥ØÁ©ç 620 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 156 ÊâπÔºåÁ¥ØÁ©ç 624 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 157 ÊâπÔºåÁ¥ØÁ©ç 628 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 158 ÊâπÔºåÁ¥ØÁ©ç 632 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 159 ÊâπÔºåÁ¥ØÁ©ç 636 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 160 ÊâπÔºåÁ¥ØÁ©ç 640 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 161 ÊâπÔºåÁ¥ØÁ©ç 644 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 162 ÊâπÔºåÁ¥ØÁ©ç 648 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 163 ÊâπÔºåÁ¥ØÁ©ç 652 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 164 ÊâπÔºåÁ¥ØÁ©ç 656 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 165 ÊâπÔºåÁ¥ØÁ©ç 660 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 166 ÊâπÔºåÁ¥ØÁ©ç 664 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 167 ÊâπÔºåÁ¥ØÁ©ç 668 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 168 ÊâπÔºåÁ¥ØÁ©ç 672 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 169 ÊâπÔºåÁ¥ØÁ©ç 676 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 170 ÊâπÔºåÁ¥ØÁ©ç 680 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 171 ÊâπÔºåÁ¥ØÁ©ç 684 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 172 ÊâπÔºåÁ¥ØÁ©ç 688 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 173 ÊâπÔºåÁ¥ØÁ©ç 692 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 174 ÊâπÔºåÁ¥ØÁ©ç 696 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 175 ÊâπÔºåÁ¥ØÁ©ç 700 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 176 ÊâπÔºåÁ¥ØÁ©ç 704 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 177 ÊâπÔºåÁ¥ØÁ©ç 708 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 178 ÊâπÔºåÁ¥ØÁ©ç 712 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 179 ÊâπÔºåÁ¥ØÁ©ç 716 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 180 ÊâπÔºåÁ¥ØÁ©ç 720 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 181 ÊâπÔºåÁ¥ØÁ©ç 724 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 182 ÊâπÔºåÁ¥ØÁ©ç 728 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 183 ÊâπÔºåÁ¥ØÁ©ç 732 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 184 ÊâπÔºåÁ¥ØÁ©ç 736 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 185 ÊâπÔºåÁ¥ØÁ©ç 740 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 186 ÊâπÔºåÁ¥ØÁ©ç 744 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 187 ÊâπÔºåÁ¥ØÁ©ç 748 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 188 ÊâπÔºåÁ¥ØÁ©ç 752 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 189 ÊâπÔºåÁ¥ØÁ©ç 756 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 190 ÊâπÔºåÁ¥ØÁ©ç 760 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 191 ÊâπÔºåÁ¥ØÁ©ç 764 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 192 ÊâπÔºåÁ¥ØÁ©ç 768 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 193 ÊâπÔºåÁ¥ØÁ©ç 772 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 194 ÊâπÔºåÁ¥ØÁ©ç 775 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº /home/student1/ai/task1_prediction.json\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "input_file = \"/home/student1/ai/task1_answer.txt\"\n",
    "output_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "batch_size = 4  # ÂèØË™øÊï¥\n",
    "\n",
    "# === ËºâÂÖ•Ê®°ÂûãËàá tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === PHI Ê®ôÁ±§ ===\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === ËÆÄÂèñË≥áÊñô‰∏¶Ë£Ω‰Ωú Prompt ===\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        uid, text = line.strip().split(\"\\t\", 1)\n",
    "        prompt = f\"\"\"You are an information extraction assistant. Extract the following sensitive entities explicitly mentioned in the input text. Respond strictly in JSON format with categories as keys and lists of extracted values.\n",
    "\n",
    "Definitions and examples:\n",
    "- **PATIENT**: A person who is receiving medical treatment or care. This can refer to someone in a healthcare context, such as \"patient John Doe\" or \"Mr. Lee, the patient\". \n",
    "  Example: \"Patient John Doe was admitted for a heart procedure.\"\n",
    "  \n",
    "- **DOCTOR**: A medical professional who is diagnosing or treating patients. This may include titles like \"Dr.\" or \"Physician\". \n",
    "  Example: \"Dr. Smith examined the patient.\"\n",
    "\n",
    "- **PERSONALNAME**: A general person name that can refer to anyone. This can include both first names and full names.\n",
    "  Example: \"James\" or \"Mary Johnson\"\n",
    "\n",
    "- **FAMILYNAME**: The last name or surname of a person, often found as the first part of a full name.\n",
    "  Example: \"Doe\" in \"John Doe\" or \"Chen\" in \"Li Chen\".\n",
    "\n",
    "- **PROFESSION**: Job titles or professions, e.g., \"pastor\", \"psychologist\", \"chiropractor\", \"teacher\", \"engineer\".\n",
    "  Example: \"He is a skilled **psychologist**.\"\n",
    "\n",
    "- **HOSPITAL**: Names of hospitals or medical centers, e.g., \"Taipei General Hospital\", \"Memorial Hospital\".\n",
    "  Example: \"The patient was transferred to **Taipei General Hospital**.\"\n",
    "\n",
    "- **ORGANIZATION**: Names of organizations or companies, e.g., \"Cambridge University\", \"Microsoft\", \"YMCA\", \"Bank of America\".\n",
    "  Example: \"She works at **Bank of America**.\"\n",
    "\n",
    "- **STREET**: Street addresses or road names, e.g., \"Main Street\", \"Elm Street\".\n",
    "  Example: \"Their office is located on **Main Street**.\"\n",
    "\n",
    "- **CITY**: City or town names, e.g., \"New York\", \"Los Angeles\".\n",
    "  Example: \"I live in **New York**.\"\n",
    "\n",
    "- **STATE**: State or province names, e.g., \"California\", \"New South Wales\".\n",
    "  Example: \"He moved to **California** last year.\"\n",
    "\n",
    "- **ZIP**: Postal or ZIP codes, e.g., \"90210\".\n",
    "  Example: \"The ZIP code for my address is **90210**.\"\n",
    "\n",
    "- **AGE**: Ages or durations of life, e.g., \"25 years old\", \"six months\".\n",
    "  Example: \"She is **25 years old**.\"\n",
    "\n",
    "- **DATE**: Calendar dates in any format, e.g., \"June 1, 1990\", \"2023-05-10\".\n",
    "  Example: \"The event is scheduled for **2023-05-10**.\"\n",
    "\n",
    "- **TIME**: Times of day or time periods, e.g., \"09:03 AM\", \"evening\", \"morning\".\n",
    "  Example: \"The meeting starts at **09:03 AM**.\"\n",
    "\n",
    "- **DURATION**: Lengths of time intervals, e.g., \"two hours\", \"last week\".\n",
    "  Example: \"The treatment lasted for **two hours**.\"\n",
    "\n",
    "- **ID_NUMBER**: Identification numbers such as social security or medical record numbers, e.g., \"A123456789\", \"123-45-6789\".\n",
    "  Example: \"Her medical record number is **A123456789**.\"\n",
    "\n",
    "- **PHONE, FAX, EMAIL, URL, IPADDRESS**: Contact and network info.\n",
    "  Example: \"You can contact him at **john.doe@example.com**.\"\n",
    "\n",
    "- **OTHER**: Any other sensitive information not covered above.\n",
    "  Example: \"The patient's **insurance policy number** is **123456789**.\"\n",
    "\n",
    "- **COUNTRY**: Countries such as \"United States\", \"Australia\", \"Japan\".\n",
    "  Example: \"He moved from **Japan** to **Australia**.\"\n",
    "\n",
    "- **COUNTY**: Administrative regions smaller than states but larger than cities, e.g., \"Los Angeles County\", \"Orange County\".\n",
    "  Example: \"**Los Angeles County** has many scenic locations.\"\n",
    "\n",
    "- **DISTRICT**: Smaller political or administrative divisions, e.g., \"Manhattan District\", \"Central District\".\n",
    "  Example: \"I live in the **Manhattan District**.\"\n",
    "\n",
    "- **LOCATION-OTHER**: Neighborhoods, landmarks, or other places not covered above, e.g., \"Downtown\", \"Central Park\", \"Financial District\".\n",
    "  Example: \"We met in **Central Park**.\"\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "        data.append((uid, prompt))\n",
    "\n",
    "# === ÂàÜÊâπÊé®Ë´ñÂáΩÂºè ===\n",
    "def batch_predict(batch_prompts):\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded_list = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "    return decoded_list\n",
    "\n",
    "# === ‰∏ªÊé®Ë´ñÊµÅÁ®ãÔºåÊØèÊâπÂ≠òÊ™î ===\n",
    "predictions = {}\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    uids, prompts = zip(*batch)\n",
    "    decoded_outputs = batch_predict(prompts)\n",
    "\n",
    "    for uid, decoded in zip(uids, decoded_outputs):\n",
    "        try:\n",
    "            json_start = decoded.index(\"{\")\n",
    "            json_str = decoded[json_start:]\n",
    "            parsed = json.loads(json_str)\n",
    "        except Exception:\n",
    "            parsed = {}\n",
    "        predictions[uid] = parsed\n",
    "\n",
    "    # ÊØèÊâπÂØ´Ê™î‰∏ÄÊ¨°ÔºåË¶ÜËìãÊ™îÊ°à\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ {i // batch_size + 1} ÊâπÔºåÁ¥ØÁ©ç {len(predictions)} Á≠ÜÁµêÊûúÂØ´ÂÖ• {output_file}\")\n",
    "\n",
    "print(f\"üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5dd1b6",
   "metadata": {},
   "source": [
    "### 0.4122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae060877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0ead2fa9a04bec8d7142ddaacf7892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/student1/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 1 ÊâπÔºåÁ¥ØÁ©ç 4 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 2 ÊâπÔºåÁ¥ØÁ©ç 8 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 3 ÊâπÔºåÁ¥ØÁ©ç 12 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 4 ÊâπÔºåÁ¥ØÁ©ç 16 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 5 ÊâπÔºåÁ¥ØÁ©ç 20 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 6 ÊâπÔºåÁ¥ØÁ©ç 24 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 7 ÊâπÔºåÁ¥ØÁ©ç 28 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 8 ÊâπÔºåÁ¥ØÁ©ç 32 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 9 ÊâπÔºåÁ¥ØÁ©ç 36 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 10 ÊâπÔºåÁ¥ØÁ©ç 40 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 11 ÊâπÔºåÁ¥ØÁ©ç 44 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 12 ÊâπÔºåÁ¥ØÁ©ç 48 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 13 ÊâπÔºåÁ¥ØÁ©ç 52 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 14 ÊâπÔºåÁ¥ØÁ©ç 56 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 15 ÊâπÔºåÁ¥ØÁ©ç 60 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 16 ÊâπÔºåÁ¥ØÁ©ç 64 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 17 ÊâπÔºåÁ¥ØÁ©ç 68 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 18 ÊâπÔºåÁ¥ØÁ©ç 72 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 19 ÊâπÔºåÁ¥ØÁ©ç 76 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 20 ÊâπÔºåÁ¥ØÁ©ç 80 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 21 ÊâπÔºåÁ¥ØÁ©ç 84 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 22 ÊâπÔºåÁ¥ØÁ©ç 88 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 23 ÊâπÔºåÁ¥ØÁ©ç 92 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 24 ÊâπÔºåÁ¥ØÁ©ç 96 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 25 ÊâπÔºåÁ¥ØÁ©ç 100 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 26 ÊâπÔºåÁ¥ØÁ©ç 104 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 27 ÊâπÔºåÁ¥ØÁ©ç 108 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 28 ÊâπÔºåÁ¥ØÁ©ç 112 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 29 ÊâπÔºåÁ¥ØÁ©ç 116 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 30 ÊâπÔºåÁ¥ØÁ©ç 120 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 31 ÊâπÔºåÁ¥ØÁ©ç 124 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 32 ÊâπÔºåÁ¥ØÁ©ç 128 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 33 ÊâπÔºåÁ¥ØÁ©ç 132 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 34 ÊâπÔºåÁ¥ØÁ©ç 136 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 35 ÊâπÔºåÁ¥ØÁ©ç 140 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 36 ÊâπÔºåÁ¥ØÁ©ç 144 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 37 ÊâπÔºåÁ¥ØÁ©ç 148 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 38 ÊâπÔºåÁ¥ØÁ©ç 152 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 39 ÊâπÔºåÁ¥ØÁ©ç 156 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 40 ÊâπÔºåÁ¥ØÁ©ç 160 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 41 ÊâπÔºåÁ¥ØÁ©ç 164 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 42 ÊâπÔºåÁ¥ØÁ©ç 168 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 43 ÊâπÔºåÁ¥ØÁ©ç 172 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 44 ÊâπÔºåÁ¥ØÁ©ç 176 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 45 ÊâπÔºåÁ¥ØÁ©ç 180 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 46 ÊâπÔºåÁ¥ØÁ©ç 184 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 47 ÊâπÔºåÁ¥ØÁ©ç 188 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 48 ÊâπÔºåÁ¥ØÁ©ç 192 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 49 ÊâπÔºåÁ¥ØÁ©ç 196 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 50 ÊâπÔºåÁ¥ØÁ©ç 200 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 51 ÊâπÔºåÁ¥ØÁ©ç 204 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 52 ÊâπÔºåÁ¥ØÁ©ç 208 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 53 ÊâπÔºåÁ¥ØÁ©ç 212 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 54 ÊâπÔºåÁ¥ØÁ©ç 216 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 55 ÊâπÔºåÁ¥ØÁ©ç 220 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 56 ÊâπÔºåÁ¥ØÁ©ç 224 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 57 ÊâπÔºåÁ¥ØÁ©ç 228 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 58 ÊâπÔºåÁ¥ØÁ©ç 232 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 59 ÊâπÔºåÁ¥ØÁ©ç 236 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 60 ÊâπÔºåÁ¥ØÁ©ç 240 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 61 ÊâπÔºåÁ¥ØÁ©ç 244 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 62 ÊâπÔºåÁ¥ØÁ©ç 248 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 63 ÊâπÔºåÁ¥ØÁ©ç 252 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 64 ÊâπÔºåÁ¥ØÁ©ç 256 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 65 ÊâπÔºåÁ¥ØÁ©ç 260 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 66 ÊâπÔºåÁ¥ØÁ©ç 264 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 67 ÊâπÔºåÁ¥ØÁ©ç 268 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 68 ÊâπÔºåÁ¥ØÁ©ç 272 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 69 ÊâπÔºåÁ¥ØÁ©ç 276 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 70 ÊâπÔºåÁ¥ØÁ©ç 280 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 71 ÊâπÔºåÁ¥ØÁ©ç 284 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 72 ÊâπÔºåÁ¥ØÁ©ç 288 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 73 ÊâπÔºåÁ¥ØÁ©ç 292 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 74 ÊâπÔºåÁ¥ØÁ©ç 296 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 75 ÊâπÔºåÁ¥ØÁ©ç 300 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 76 ÊâπÔºåÁ¥ØÁ©ç 304 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 77 ÊâπÔºåÁ¥ØÁ©ç 308 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 78 ÊâπÔºåÁ¥ØÁ©ç 312 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 79 ÊâπÔºåÁ¥ØÁ©ç 316 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 80 ÊâπÔºåÁ¥ØÁ©ç 320 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 81 ÊâπÔºåÁ¥ØÁ©ç 324 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 82 ÊâπÔºåÁ¥ØÁ©ç 328 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 83 ÊâπÔºåÁ¥ØÁ©ç 332 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 84 ÊâπÔºåÁ¥ØÁ©ç 336 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 85 ÊâπÔºåÁ¥ØÁ©ç 340 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 86 ÊâπÔºåÁ¥ØÁ©ç 344 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 87 ÊâπÔºåÁ¥ØÁ©ç 348 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 88 ÊâπÔºåÁ¥ØÁ©ç 352 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 89 ÊâπÔºåÁ¥ØÁ©ç 356 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 90 ÊâπÔºåÁ¥ØÁ©ç 360 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 91 ÊâπÔºåÁ¥ØÁ©ç 364 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 92 ÊâπÔºåÁ¥ØÁ©ç 368 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 93 ÊâπÔºåÁ¥ØÁ©ç 372 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 94 ÊâπÔºåÁ¥ØÁ©ç 376 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 95 ÊâπÔºåÁ¥ØÁ©ç 380 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 96 ÊâπÔºåÁ¥ØÁ©ç 384 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 97 ÊâπÔºåÁ¥ØÁ©ç 388 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 98 ÊâπÔºåÁ¥ØÁ©ç 392 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 99 ÊâπÔºåÁ¥ØÁ©ç 396 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 100 ÊâπÔºåÁ¥ØÁ©ç 400 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 101 ÊâπÔºåÁ¥ØÁ©ç 404 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 102 ÊâπÔºåÁ¥ØÁ©ç 408 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 103 ÊâπÔºåÁ¥ØÁ©ç 412 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 104 ÊâπÔºåÁ¥ØÁ©ç 416 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 105 ÊâπÔºåÁ¥ØÁ©ç 420 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 106 ÊâπÔºåÁ¥ØÁ©ç 424 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 107 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 108 ÊâπÔºåÁ¥ØÁ©ç 432 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 109 ÊâπÔºåÁ¥ØÁ©ç 436 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 110 ÊâπÔºåÁ¥ØÁ©ç 440 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 111 ÊâπÔºåÁ¥ØÁ©ç 444 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 112 ÊâπÔºåÁ¥ØÁ©ç 448 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 113 ÊâπÔºåÁ¥ØÁ©ç 452 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 114 ÊâπÔºåÁ¥ØÁ©ç 456 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 115 ÊâπÔºåÁ¥ØÁ©ç 460 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 116 ÊâπÔºåÁ¥ØÁ©ç 464 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 117 ÊâπÔºåÁ¥ØÁ©ç 468 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 118 ÊâπÔºåÁ¥ØÁ©ç 472 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 119 ÊâπÔºåÁ¥ØÁ©ç 476 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 120 ÊâπÔºåÁ¥ØÁ©ç 480 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 121 ÊâπÔºåÁ¥ØÁ©ç 484 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 122 ÊâπÔºåÁ¥ØÁ©ç 488 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 123 ÊâπÔºåÁ¥ØÁ©ç 492 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 124 ÊâπÔºåÁ¥ØÁ©ç 496 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 125 ÊâπÔºåÁ¥ØÁ©ç 500 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 126 ÊâπÔºåÁ¥ØÁ©ç 504 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 127 ÊâπÔºåÁ¥ØÁ©ç 508 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 128 ÊâπÔºåÁ¥ØÁ©ç 512 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 129 ÊâπÔºåÁ¥ØÁ©ç 516 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 130 ÊâπÔºåÁ¥ØÁ©ç 520 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 131 ÊâπÔºåÁ¥ØÁ©ç 524 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 132 ÊâπÔºåÁ¥ØÁ©ç 528 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 133 ÊâπÔºåÁ¥ØÁ©ç 532 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 134 ÊâπÔºåÁ¥ØÁ©ç 536 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 135 ÊâπÔºåÁ¥ØÁ©ç 540 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 136 ÊâπÔºåÁ¥ØÁ©ç 544 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 137 ÊâπÔºåÁ¥ØÁ©ç 548 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 138 ÊâπÔºåÁ¥ØÁ©ç 552 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 139 ÊâπÔºåÁ¥ØÁ©ç 556 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 140 ÊâπÔºåÁ¥ØÁ©ç 560 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 141 ÊâπÔºåÁ¥ØÁ©ç 564 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 142 ÊâπÔºåÁ¥ØÁ©ç 568 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 143 ÊâπÔºåÁ¥ØÁ©ç 572 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 144 ÊâπÔºåÁ¥ØÁ©ç 576 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 145 ÊâπÔºåÁ¥ØÁ©ç 580 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 146 ÊâπÔºåÁ¥ØÁ©ç 584 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 147 ÊâπÔºåÁ¥ØÁ©ç 588 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 148 ÊâπÔºåÁ¥ØÁ©ç 592 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 149 ÊâπÔºåÁ¥ØÁ©ç 596 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 150 ÊâπÔºåÁ¥ØÁ©ç 600 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 151 ÊâπÔºåÁ¥ØÁ©ç 604 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 152 ÊâπÔºåÁ¥ØÁ©ç 608 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 153 ÊâπÔºåÁ¥ØÁ©ç 612 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 154 ÊâπÔºåÁ¥ØÁ©ç 616 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 155 ÊâπÔºåÁ¥ØÁ©ç 620 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 156 ÊâπÔºåÁ¥ØÁ©ç 624 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 157 ÊâπÔºåÁ¥ØÁ©ç 628 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 158 ÊâπÔºåÁ¥ØÁ©ç 632 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 159 ÊâπÔºåÁ¥ØÁ©ç 636 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 160 ÊâπÔºåÁ¥ØÁ©ç 640 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 161 ÊâπÔºåÁ¥ØÁ©ç 644 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 162 ÊâπÔºåÁ¥ØÁ©ç 648 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 163 ÊâπÔºåÁ¥ØÁ©ç 652 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 164 ÊâπÔºåÁ¥ØÁ©ç 656 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 165 ÊâπÔºåÁ¥ØÁ©ç 660 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 166 ÊâπÔºåÁ¥ØÁ©ç 664 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 167 ÊâπÔºåÁ¥ØÁ©ç 668 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 168 ÊâπÔºåÁ¥ØÁ©ç 672 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 169 ÊâπÔºåÁ¥ØÁ©ç 676 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 170 ÊâπÔºåÁ¥ØÁ©ç 680 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 171 ÊâπÔºåÁ¥ØÁ©ç 684 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 172 ÊâπÔºåÁ¥ØÁ©ç 688 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 173 ÊâπÔºåÁ¥ØÁ©ç 692 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 174 ÊâπÔºåÁ¥ØÁ©ç 696 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 175 ÊâπÔºåÁ¥ØÁ©ç 700 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 176 ÊâπÔºåÁ¥ØÁ©ç 704 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 177 ÊâπÔºåÁ¥ØÁ©ç 708 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 178 ÊâπÔºåÁ¥ØÁ©ç 712 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 179 ÊâπÔºåÁ¥ØÁ©ç 716 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 180 ÊâπÔºåÁ¥ØÁ©ç 720 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 181 ÊâπÔºåÁ¥ØÁ©ç 724 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 182 ÊâπÔºåÁ¥ØÁ©ç 728 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 183 ÊâπÔºåÁ¥ØÁ©ç 732 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 184 ÊâπÔºåÁ¥ØÁ©ç 736 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 185 ÊâπÔºåÁ¥ØÁ©ç 740 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 186 ÊâπÔºåÁ¥ØÁ©ç 744 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 187 ÊâπÔºåÁ¥ØÁ©ç 748 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 188 ÊâπÔºåÁ¥ØÁ©ç 752 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 189 ÊâπÔºåÁ¥ØÁ©ç 756 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 190 ÊâπÔºåÁ¥ØÁ©ç 760 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 191 ÊâπÔºåÁ¥ØÁ©ç 764 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 192 ÊâπÔºåÁ¥ØÁ©ç 768 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 193 ÊâπÔºåÁ¥ØÁ©ç 772 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 194 ÊâπÔºåÁ¥ØÁ©ç 775 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº /home/student1/ai/task1_prediction.json\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "input_file = \"/home/student1/ai/task1_answer.txt\"\n",
    "output_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "batch_size = 4  # ÂèØË™øÊï¥\n",
    "\n",
    "# === ËºâÂÖ•Ê®°ÂûãËàá tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === PHI Ê®ôÁ±§ ===\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === ËÆÄÂèñË≥áÊñô‰∏¶Ë£Ω‰Ωú Prompt ===\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        uid, text = line.strip().split(\"\\t\", 1)\n",
    "        prompt = f\"\"\"You are an information extraction assistant. Your task is to strictly extract the sensitive entities explicitly mentioned in the provided text. Do **not** generate any new information, only extract what is already present in the text. Respond strictly in JSON format with categories as keys and lists of extracted values. \n",
    "\n",
    "Definitions and examples:\n",
    "- **PATIENT**: A person who is receiving medical treatment or care. This can refer to someone in a healthcare context, such as \"patient John Doe\" or \"Mr. Lee, the patient\".\n",
    "  Example: \"Patient John Doe was admitted for a heart procedure.\"\n",
    "  \n",
    "- **DOCTOR**: A medical professional who is diagnosing or treating patients. This may include titles like \"Dr.\" or \"Physician\".\n",
    "  Example: \"Dr. Smith examined the patient.\"\n",
    "  \n",
    "- **PERSONALNAME**: A general person name that can refer to anyone. This can include both first names and full names.\n",
    "  Example: \"James\" or \"Mary Johnson\"\n",
    "  \n",
    "- **FAMILYNAME**: The last name or surname of a person, often found as the first part of a full name.\n",
    "  Example: \"Doe\" in \"John Doe\" or \"Chen\" in \"Li Chen\".\n",
    "  \n",
    "- **PROFESSION**: Job titles or professions, e.g., \"pastor\", \"psychologist\", \"teacher\", \"engineer\", \"chiropractor\", \"archbishop\".\n",
    "  Example: \"She is a skilled **psychologist**.\"\n",
    "  \n",
    "- **HOSPITAL**: Names of hospitals or medical centers, e.g., \"Taipei General Hospital\", \"Memorial Hospital\", \"St. Peter‚Äôs Hospital\".\n",
    "  Example: \"The patient was transferred to **Taipei General Hospital**.\"\n",
    "  \n",
    "- **ORGANIZATION**: Names of organizations or companies, e.g., \"Cambridge University\", \"YMCA\", \"Bank of America\", \"Microsoft\".\n",
    "  Example: \"He works at **Bank of America**.\"\n",
    "  \n",
    "- **STREET**: Street addresses or road names, e.g., \"Main Street\", \"Elm Street\", \"Oak Avenue\", \"Highway 101\".\n",
    "  Example: \"They live on **Main Street**.\"\n",
    "  \n",
    "- **CITY**: City or town names, e.g., \"New York\", \"Los Angeles\", \"San Francisco\".\n",
    "  Example: \"He is from **Los Angeles**.\"\n",
    "  \n",
    "- **STATE**: State or province names, e.g., \"California\", \"New South Wales\", \"Texas\".\n",
    "  Example: \"The company is based in **California**.\"\n",
    "  \n",
    "- **ZIP**: Postal or ZIP codes, e.g., \"90210\", \"10001\".\n",
    "  Example: \"Her ZIP code is **90210**.\"\n",
    "  \n",
    "- **AGE**: Ages or durations of life, e.g., \"25 years old\", \"six months\".\n",
    "  Example: \"She is **25 years old**.\"\n",
    "  \n",
    "- **DATE**: Calendar dates in any format, e.g., \"June 1, 1990\", \"2023-05-10\", \"01/02/2021\".\n",
    "  Example: \"The meeting is scheduled for **2023-05-10**.\"\n",
    "  \n",
    "- **TIME**: Specific times of day or periods of time, e.g., \"09:03 AM\", \"evening\", \"morning\", \"2:30 PM\".\n",
    "  Example: \"The event will begin at **09:03 AM**.\"\n",
    "  \n",
    "- **DURATION**: Lengths of time intervals, e.g., \"two hours\", \"last week\", \"several months\".\n",
    "  Example: \"The meeting lasted **two hours**.\"\n",
    "  \n",
    "- **ID_NUMBER**: Identification numbers such as social security or medical record numbers, e.g., \"A123456789\", \"123-45-6789\".\n",
    "  Example: \"Her social security number is **A123456789**.\"\n",
    "  \n",
    "- **MEDICAL_RECORD_NUMBER**: Specific identification numbers assigned to a patient for medical purposes, typically used by hospitals or healthcare providers to track patient records.\n",
    "  Example: \"The patient‚Äôs medical record number is **A123456789**.\"\n",
    "  \n",
    "- **PHONE, FAX, EMAIL, URL, IPADDRESS**: Contact and network info.\n",
    "  Example: \"You can contact him at **john.doe@example.com**.\"\n",
    "  \n",
    "- **OTHER**: Any other sensitive information not covered above.\n",
    "  Example: \"The patient‚Äôs **insurance policy number** is **123456789**.\"\n",
    "  \n",
    "- **COUNTRY**: Countries such as \"United States\", \"Australia\", \"Japan\".\n",
    "  Example: \"He moved from **Japan** to **Australia**.\"\n",
    "  \n",
    "- **COUNTY**: Administrative regions smaller than states but larger than cities, e.g., \"Los Angeles County\", \"Orange County\".\n",
    "  Example: \"**Los Angeles County** has many scenic locations.\"\n",
    "  \n",
    "- **DISTRICT**: Smaller political or administrative divisions, e.g., \"Manhattan District\", \"Central District\".\n",
    "  Example: \"I live in the **Manhattan District**.\"\n",
    "  \n",
    "- **LOCATION-OTHER**: Neighborhoods, landmarks, or other places not covered above, e.g., \"Downtown\", \"Central Park\", \"Financial District\".\n",
    "  Example: \"We met in **Central Park**.\"\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        data.append((uid, prompt))\n",
    "\n",
    "# === ÂàÜÊâπÊé®Ë´ñÂáΩÂºè ===\n",
    "def batch_predict(batch_prompts):\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded_list = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "    return decoded_list\n",
    "\n",
    "# === ‰∏ªÊé®Ë´ñÊµÅÁ®ãÔºåÊØèÊâπÂ≠òÊ™î ===\n",
    "predictions = {}\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    uids, prompts = zip(*batch)\n",
    "    decoded_outputs = batch_predict(prompts)\n",
    "\n",
    "    for uid, decoded in zip(uids, decoded_outputs):\n",
    "        try:\n",
    "            json_start = decoded.index(\"{\")\n",
    "            json_str = decoded[json_start:]\n",
    "            parsed = json.loads(json_str)\n",
    "        except Exception:\n",
    "            parsed = {}\n",
    "        predictions[uid] = parsed\n",
    "\n",
    "    # ÊØèÊâπÂØ´Ê™î‰∏ÄÊ¨°ÔºåË¶ÜËìãÊ™îÊ°à\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ {i // batch_size + 1} ÊâπÔºåÁ¥ØÁ©ç {len(predictions)} Á≠ÜÁµêÊûúÂØ´ÂÖ• {output_file}\")\n",
    "\n",
    "print(f\"üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3fa57",
   "metadata": {},
   "source": [
    "### 0.422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4089e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c6eba5357449a2b92ea07940889e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/student1/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 1 ÊâπÔºåÁ¥ØÁ©ç 4 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 2 ÊâπÔºåÁ¥ØÁ©ç 8 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 3 ÊâπÔºåÁ¥ØÁ©ç 12 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 4 ÊâπÔºåÁ¥ØÁ©ç 16 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 5 ÊâπÔºåÁ¥ØÁ©ç 20 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 6 ÊâπÔºåÁ¥ØÁ©ç 24 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 7 ÊâπÔºåÁ¥ØÁ©ç 28 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 8 ÊâπÔºåÁ¥ØÁ©ç 32 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 9 ÊâπÔºåÁ¥ØÁ©ç 36 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 10 ÊâπÔºåÁ¥ØÁ©ç 40 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 11 ÊâπÔºåÁ¥ØÁ©ç 44 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 12 ÊâπÔºåÁ¥ØÁ©ç 48 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 13 ÊâπÔºåÁ¥ØÁ©ç 52 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 14 ÊâπÔºåÁ¥ØÁ©ç 56 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 15 ÊâπÔºåÁ¥ØÁ©ç 60 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 16 ÊâπÔºåÁ¥ØÁ©ç 64 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 17 ÊâπÔºåÁ¥ØÁ©ç 68 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 18 ÊâπÔºåÁ¥ØÁ©ç 72 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 19 ÊâπÔºåÁ¥ØÁ©ç 76 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 20 ÊâπÔºåÁ¥ØÁ©ç 80 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 21 ÊâπÔºåÁ¥ØÁ©ç 84 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 22 ÊâπÔºåÁ¥ØÁ©ç 88 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 23 ÊâπÔºåÁ¥ØÁ©ç 92 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 24 ÊâπÔºåÁ¥ØÁ©ç 96 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 25 ÊâπÔºåÁ¥ØÁ©ç 100 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 26 ÊâπÔºåÁ¥ØÁ©ç 104 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 27 ÊâπÔºåÁ¥ØÁ©ç 108 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 28 ÊâπÔºåÁ¥ØÁ©ç 112 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 29 ÊâπÔºåÁ¥ØÁ©ç 116 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 30 ÊâπÔºåÁ¥ØÁ©ç 120 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 31 ÊâπÔºåÁ¥ØÁ©ç 124 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 32 ÊâπÔºåÁ¥ØÁ©ç 128 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 33 ÊâπÔºåÁ¥ØÁ©ç 132 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 34 ÊâπÔºåÁ¥ØÁ©ç 136 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 35 ÊâπÔºåÁ¥ØÁ©ç 140 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 36 ÊâπÔºåÁ¥ØÁ©ç 144 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 37 ÊâπÔºåÁ¥ØÁ©ç 148 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 38 ÊâπÔºåÁ¥ØÁ©ç 152 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 39 ÊâπÔºåÁ¥ØÁ©ç 156 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 40 ÊâπÔºåÁ¥ØÁ©ç 160 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 41 ÊâπÔºåÁ¥ØÁ©ç 164 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 42 ÊâπÔºåÁ¥ØÁ©ç 168 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 43 ÊâπÔºåÁ¥ØÁ©ç 172 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 44 ÊâπÔºåÁ¥ØÁ©ç 176 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 45 ÊâπÔºåÁ¥ØÁ©ç 180 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 46 ÊâπÔºåÁ¥ØÁ©ç 184 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 47 ÊâπÔºåÁ¥ØÁ©ç 188 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 48 ÊâπÔºåÁ¥ØÁ©ç 192 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 49 ÊâπÔºåÁ¥ØÁ©ç 196 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 50 ÊâπÔºåÁ¥ØÁ©ç 200 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 51 ÊâπÔºåÁ¥ØÁ©ç 204 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 52 ÊâπÔºåÁ¥ØÁ©ç 208 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 53 ÊâπÔºåÁ¥ØÁ©ç 212 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 54 ÊâπÔºåÁ¥ØÁ©ç 216 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 55 ÊâπÔºåÁ¥ØÁ©ç 220 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 56 ÊâπÔºåÁ¥ØÁ©ç 224 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 57 ÊâπÔºåÁ¥ØÁ©ç 228 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 58 ÊâπÔºåÁ¥ØÁ©ç 232 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 59 ÊâπÔºåÁ¥ØÁ©ç 236 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 60 ÊâπÔºåÁ¥ØÁ©ç 240 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 61 ÊâπÔºåÁ¥ØÁ©ç 244 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 62 ÊâπÔºåÁ¥ØÁ©ç 248 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 63 ÊâπÔºåÁ¥ØÁ©ç 252 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 64 ÊâπÔºåÁ¥ØÁ©ç 256 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 65 ÊâπÔºåÁ¥ØÁ©ç 260 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 66 ÊâπÔºåÁ¥ØÁ©ç 264 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 67 ÊâπÔºåÁ¥ØÁ©ç 268 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 68 ÊâπÔºåÁ¥ØÁ©ç 272 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 69 ÊâπÔºåÁ¥ØÁ©ç 276 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 70 ÊâπÔºåÁ¥ØÁ©ç 280 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 71 ÊâπÔºåÁ¥ØÁ©ç 284 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 72 ÊâπÔºåÁ¥ØÁ©ç 288 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 73 ÊâπÔºåÁ¥ØÁ©ç 292 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 74 ÊâπÔºåÁ¥ØÁ©ç 296 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 75 ÊâπÔºåÁ¥ØÁ©ç 300 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 76 ÊâπÔºåÁ¥ØÁ©ç 304 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 77 ÊâπÔºåÁ¥ØÁ©ç 308 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 78 ÊâπÔºåÁ¥ØÁ©ç 312 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 79 ÊâπÔºåÁ¥ØÁ©ç 316 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 80 ÊâπÔºåÁ¥ØÁ©ç 320 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 81 ÊâπÔºåÁ¥ØÁ©ç 324 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 82 ÊâπÔºåÁ¥ØÁ©ç 328 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 83 ÊâπÔºåÁ¥ØÁ©ç 332 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 84 ÊâπÔºåÁ¥ØÁ©ç 336 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 85 ÊâπÔºåÁ¥ØÁ©ç 340 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 86 ÊâπÔºåÁ¥ØÁ©ç 344 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 87 ÊâπÔºåÁ¥ØÁ©ç 348 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 88 ÊâπÔºåÁ¥ØÁ©ç 352 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 89 ÊâπÔºåÁ¥ØÁ©ç 356 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 90 ÊâπÔºåÁ¥ØÁ©ç 360 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 91 ÊâπÔºåÁ¥ØÁ©ç 364 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 92 ÊâπÔºåÁ¥ØÁ©ç 368 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 93 ÊâπÔºåÁ¥ØÁ©ç 372 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 94 ÊâπÔºåÁ¥ØÁ©ç 376 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 95 ÊâπÔºåÁ¥ØÁ©ç 380 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 96 ÊâπÔºåÁ¥ØÁ©ç 384 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 97 ÊâπÔºåÁ¥ØÁ©ç 388 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 98 ÊâπÔºåÁ¥ØÁ©ç 392 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 99 ÊâπÔºåÁ¥ØÁ©ç 396 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 100 ÊâπÔºåÁ¥ØÁ©ç 400 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 101 ÊâπÔºåÁ¥ØÁ©ç 404 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 102 ÊâπÔºåÁ¥ØÁ©ç 408 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 103 ÊâπÔºåÁ¥ØÁ©ç 412 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 104 ÊâπÔºåÁ¥ØÁ©ç 416 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 105 ÊâπÔºåÁ¥ØÁ©ç 420 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 106 ÊâπÔºåÁ¥ØÁ©ç 424 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 107 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 108 ÊâπÔºåÁ¥ØÁ©ç 432 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 109 ÊâπÔºåÁ¥ØÁ©ç 436 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 110 ÊâπÔºåÁ¥ØÁ©ç 440 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 111 ÊâπÔºåÁ¥ØÁ©ç 444 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 112 ÊâπÔºåÁ¥ØÁ©ç 448 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 113 ÊâπÔºåÁ¥ØÁ©ç 452 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 114 ÊâπÔºåÁ¥ØÁ©ç 456 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 115 ÊâπÔºåÁ¥ØÁ©ç 460 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 116 ÊâπÔºåÁ¥ØÁ©ç 464 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 117 ÊâπÔºåÁ¥ØÁ©ç 468 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 118 ÊâπÔºåÁ¥ØÁ©ç 472 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 119 ÊâπÔºåÁ¥ØÁ©ç 476 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 120 ÊâπÔºåÁ¥ØÁ©ç 480 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 121 ÊâπÔºåÁ¥ØÁ©ç 484 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 122 ÊâπÔºåÁ¥ØÁ©ç 488 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 123 ÊâπÔºåÁ¥ØÁ©ç 492 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 124 ÊâπÔºåÁ¥ØÁ©ç 496 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 125 ÊâπÔºåÁ¥ØÁ©ç 500 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 126 ÊâπÔºåÁ¥ØÁ©ç 504 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 127 ÊâπÔºåÁ¥ØÁ©ç 508 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 128 ÊâπÔºåÁ¥ØÁ©ç 512 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 129 ÊâπÔºåÁ¥ØÁ©ç 516 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 130 ÊâπÔºåÁ¥ØÁ©ç 520 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 131 ÊâπÔºåÁ¥ØÁ©ç 524 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 132 ÊâπÔºåÁ¥ØÁ©ç 528 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 133 ÊâπÔºåÁ¥ØÁ©ç 532 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 134 ÊâπÔºåÁ¥ØÁ©ç 536 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 135 ÊâπÔºåÁ¥ØÁ©ç 540 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 136 ÊâπÔºåÁ¥ØÁ©ç 544 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 137 ÊâπÔºåÁ¥ØÁ©ç 548 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 138 ÊâπÔºåÁ¥ØÁ©ç 552 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 139 ÊâπÔºåÁ¥ØÁ©ç 556 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 140 ÊâπÔºåÁ¥ØÁ©ç 560 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 141 ÊâπÔºåÁ¥ØÁ©ç 564 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 142 ÊâπÔºåÁ¥ØÁ©ç 568 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 143 ÊâπÔºåÁ¥ØÁ©ç 572 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 144 ÊâπÔºåÁ¥ØÁ©ç 576 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 145 ÊâπÔºåÁ¥ØÁ©ç 580 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 146 ÊâπÔºåÁ¥ØÁ©ç 584 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 147 ÊâπÔºåÁ¥ØÁ©ç 588 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 148 ÊâπÔºåÁ¥ØÁ©ç 592 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 149 ÊâπÔºåÁ¥ØÁ©ç 596 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 150 ÊâπÔºåÁ¥ØÁ©ç 600 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 151 ÊâπÔºåÁ¥ØÁ©ç 604 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 152 ÊâπÔºåÁ¥ØÁ©ç 608 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 153 ÊâπÔºåÁ¥ØÁ©ç 612 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 154 ÊâπÔºåÁ¥ØÁ©ç 616 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 155 ÊâπÔºåÁ¥ØÁ©ç 620 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 156 ÊâπÔºåÁ¥ØÁ©ç 624 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 157 ÊâπÔºåÁ¥ØÁ©ç 628 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 158 ÊâπÔºåÁ¥ØÁ©ç 632 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 159 ÊâπÔºåÁ¥ØÁ©ç 636 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 160 ÊâπÔºåÁ¥ØÁ©ç 640 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 161 ÊâπÔºåÁ¥ØÁ©ç 644 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 162 ÊâπÔºåÁ¥ØÁ©ç 648 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 163 ÊâπÔºåÁ¥ØÁ©ç 652 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 164 ÊâπÔºåÁ¥ØÁ©ç 656 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 165 ÊâπÔºåÁ¥ØÁ©ç 660 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 166 ÊâπÔºåÁ¥ØÁ©ç 664 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 167 ÊâπÔºåÁ¥ØÁ©ç 668 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 168 ÊâπÔºåÁ¥ØÁ©ç 672 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 169 ÊâπÔºåÁ¥ØÁ©ç 676 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 170 ÊâπÔºåÁ¥ØÁ©ç 680 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 171 ÊâπÔºåÁ¥ØÁ©ç 684 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 172 ÊâπÔºåÁ¥ØÁ©ç 688 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 173 ÊâπÔºåÁ¥ØÁ©ç 692 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 174 ÊâπÔºåÁ¥ØÁ©ç 696 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 175 ÊâπÔºåÁ¥ØÁ©ç 700 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 176 ÊâπÔºåÁ¥ØÁ©ç 704 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 177 ÊâπÔºåÁ¥ØÁ©ç 708 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 178 ÊâπÔºåÁ¥ØÁ©ç 709 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº /home/student1/ai/task1_prediction.json\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "input_file = \"/home/student1/ai/task1_answer.txt\"\n",
    "output_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "batch_size = 4  # ÂèØË™øÊï¥\n",
    "\n",
    "# === ËºâÂÖ•Ê®°ÂûãËàá tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === PHI Ê®ôÁ±§ ===\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === ËÆÄÂèñË≥áÊñô‰∏¶Ë£Ω‰Ωú Prompt ===\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        uid, text = line.strip().split(\"\\t\", 1)\n",
    "        prompt = f\"\"\"You are an information extraction assistant. Your task is to strictly extract the sensitive entities explicitly mentioned in the provided text. Do **not** generate any new information, only extract what is already present in the text. Respond strictly in JSON format with categories as keys and lists of extracted values. \n",
    "\n",
    "Definitions and examples:\n",
    "- **PATIENT**: A person who is receiving medical treatment or care. This can refer to someone in a healthcare context, such as \"patient John Doe\" or \"Mr. Lee, the patient\".\n",
    "  Example: \"Patient John Doe was admitted for a heart procedure.\"\n",
    "  \n",
    "- **DOCTOR**: A medical professional who is diagnosing or treating patients. This may include titles like \"Dr.\" or \"Physician\".\n",
    "  Example: \"Dr. Smith examined the patient.\"\n",
    "  \n",
    "- **PERSONALNAME**: A general person name that can refer to anyone. This can include both first names and full names.\n",
    "  Example: \"James\" or \"Mary Johnson\"\n",
    "  \n",
    "- **FAMILYNAME**: The last name or surname of a person, often found as the first part of a full name.\n",
    "  Example: \"Doe\" in \"John Doe\" or \"Chen\" in \"Li Chen\".\n",
    "  \n",
    "- **PROFESSION**: Job titles or professions, e.g., \"pastor\", \"psychologist\", \"teacher\", \"engineer\", \"chiropractor\", \"archbishop\".\n",
    "  Example: \"She is a skilled **psychologist**.\"\n",
    "  \n",
    "- **HOSPITAL**: Names of hospitals or medical centers, e.g., \"Taipei General Hospital\", \"Memorial Hospital\", \"St. Peter‚Äôs Hospital\".\n",
    "  Example: \"The patient was transferred to **Taipei General Hospital**.\"\n",
    "  \n",
    "- **ORGANIZATION**: Names of organizations or companies, e.g., \"Cambridge University\", \"YMCA\", \"Bank of America\", \"Microsoft\".\n",
    "  Example: \"He works at **Bank of America**.\"\n",
    "  \n",
    "- **STREET**: Street addresses or road names, e.g., \"Main Street\", \"Elm Street\", \"Oak Avenue\", \"Highway 101\".\n",
    "  Example: \"They live on **Main Street**.\"\n",
    "  \n",
    "- **CITY**: City or town names, e.g., \"New York\", \"Los Angeles\", \"San Francisco\".\n",
    "  Example: \"He is from **Los Angeles**.\"\n",
    "  \n",
    "- **STATE**: State or province names, e.g., \"California\", \"New South Wales\", \"Texas\".\n",
    "  Example: \"The company is based in **California**.\"\n",
    "  \n",
    "- **ZIP**: Postal codes or similar numeric identifiers, which may not follow the standard ZIP code format but are used for location identification, e.g., \"5067.\", \"3137\".\n",
    "  Example: \"The office is located in **5067.**.\"\n",
    "  Example: \"His postal code is **3137**.\"\n",
    "  \n",
    "- **AGE**: Ages or durations of life, including numerical values, years, months, and decades. Common formats may include: \n",
    "  - Specific ages in numbers (e.g., \"25\", \"78\", \"56\").\n",
    "  - Ages with years or other units (e.g., \"25 years\", \"56 years old\").\n",
    "  - General age ranges or groupings (e.g., \"20s\", \"30s\").\n",
    "  - Phrasing with \"old\" (e.g., \"She is 25 years old\", \"He is in his 30s\").\n",
    "  Example: \"He is **56 years ** old.\"\n",
    "  Example: \"She is in her **20s**.\"\n",
    "  Example: \"The patient is **78**.\"\n",
    "  \n",
    "- **DATE**: Calendar dates in any format, including full date expressions such as days of the week, months, or specific day/month/year formats, e.g., \"Sunday\", \"February 21, 2062\", \"August 21, 2062\", \"2023-05-10\", \"01/02/2021\".\n",
    "  Example: \"The event will be held on **Sunday**.\"\n",
    "  Example: \"Her birthday is on **February 21, 2062**.\"\n",
    "  Example: \"The meeting is scheduled for **August 21, 2062**.\"\n",
    "  Example: \"The flight is on **2023-05-10**.\"\n",
    "  \n",
    "- **TIME**: Specific times of day or periods of time, e.g., \"09:03 AM\", \"evening\", \"morning\", \"12:50\".\n",
    "  Example: \"The event will begin at **09:03 AM**.\"\n",
    "  \n",
    "- **DURATION**: Lengths of time intervals, e.g., \"two hours\", \"last week\", \"several months\".\n",
    "  Example: \"The meeting lasted **two hours**.\"\n",
    "  \n",
    "- **ID_NUMBER**: Identification numbers such as social security numbers, medical record numbers, or other alphanumeric IDs. These include:\n",
    "  - Alphanumeric codes without extensions, e.g., \"75J36260\", \"88D941303V\".\n",
    "  - Pure numeric IDs, e.g., \"195034545\", \"123456789\".\n",
    "  Example: \"Her ID number is **75J36260**.\"\n",
    "  Example: \"His unique identifier is **88D941303V**.\"\n",
    "  \n",
    "- **MEDICAL_RECORD_NUMBER**: Specific identification numbers assigned to a patient for medical purposes, typically used by hospitals or healthcare providers to track patient records. These are always in the following format:\n",
    "  - Alphanumeric IDs with a period and a fixed extension, e.g., \"271830.QJV\", \"4821383.OMF\".\n",
    "  Example: \"The patient's medical record number is **271830.QJV**.\"\n",
    "  Example: \"His medical record number is **4821383.OMF**.\"\n",
    "\n",
    "- **PHONE, FAX, EMAIL, URL, IPADDRESS**: Contact and network info.\n",
    "  Example: \"You can contact him at **john.doe@example.com**.\"\n",
    "  \n",
    "- **OTHER**: Any other sensitive information not covered above.\n",
    "  Example: \"The patient‚Äôs **insurance policy number** is **123456789**.\"\n",
    "  \n",
    "- **COUNTRY**: Countries such as \"United States\", \"Australia\", \"Japan\".\n",
    "  Example: \"He moved from **Japan** to **Australia**.\"\n",
    "  \n",
    "- **COUNTY**: Administrative regions smaller than states but larger than cities, e.g., \"Los Angeles County\", \"Orange County\".\n",
    "  Example: \"**Los Angeles County** has many scenic locations.\"\n",
    "  \n",
    "- **DISTRICT**: Smaller political or administrative divisions, e.g., \"Manhattan District\", \"Central District\".\n",
    "  Example: \"I live in the **Manhattan District**.\"\n",
    "  \n",
    "- **LOCATION-OTHER**: Neighborhoods, towns, landmarks, or other places not covered above, such as specific towns or small regions, e.g., \"Mystic\", \"Canterbury\", \"Andover\".\n",
    "  - These could be names of towns, villages, neighborhoods, or other unique geographic locations that are not part of larger cities or districts.\n",
    "  Example: \"The meeting will be held in **Mystic**.\"\n",
    "  Example: \"He lives in **Canterbury**.\"\n",
    "  Example: \"They moved to **Andover**.\"\n",
    "\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "output:\n",
    "\"\"\"\n",
    "\n",
    "        data.append((uid, prompt))\n",
    "\n",
    "# === ÂàÜÊâπÊé®Ë´ñÂáΩÂºè ===\n",
    "def batch_predict(batch_prompts):\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded_list = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "    return decoded_list\n",
    "\n",
    "# === ‰∏ªÊé®Ë´ñÊµÅÁ®ãÔºåÊØèÊâπÂ≠òÊ™î ===\n",
    "predictions = {}\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    uids, prompts = zip(*batch)\n",
    "    decoded_outputs = batch_predict(prompts)\n",
    "\n",
    "    for uid, decoded in zip(uids, decoded_outputs):\n",
    "        try:\n",
    "            json_start = decoded.index(\"{\")\n",
    "            json_str = decoded[json_start:]\n",
    "            parsed = json.loads(json_str)\n",
    "        except Exception:\n",
    "            parsed = {}\n",
    "        predictions[uid] = parsed\n",
    "\n",
    "    # ÊØèÊâπÂØ´Ê™î‰∏ÄÊ¨°ÔºåË¶ÜËìãÊ™îÊ°à\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ {i // batch_size + 1} ÊâπÔºåÁ¥ØÁ©ç {len(predictions)} Á≠ÜÁµêÊûúÂØ´ÂÖ• {output_file}\")\n",
    "\n",
    "print(f\"üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5588532",
   "metadata": {},
   "source": [
    "### 0.3791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd82575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56269c538c254dd782e66e5b691f83b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/student1/miniconda3/envs/lin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 1 ÊâπÔºåÁ¥ØÁ©ç 4 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 2 ÊâπÔºåÁ¥ØÁ©ç 8 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 3 ÊâπÔºåÁ¥ØÁ©ç 12 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 4 ÊâπÔºåÁ¥ØÁ©ç 16 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 5 ÊâπÔºåÁ¥ØÁ©ç 20 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 6 ÊâπÔºåÁ¥ØÁ©ç 24 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 7 ÊâπÔºåÁ¥ØÁ©ç 28 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 8 ÊâπÔºåÁ¥ØÁ©ç 32 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 9 ÊâπÔºåÁ¥ØÁ©ç 36 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 10 ÊâπÔºåÁ¥ØÁ©ç 40 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 11 ÊâπÔºåÁ¥ØÁ©ç 44 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 12 ÊâπÔºåÁ¥ØÁ©ç 48 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 13 ÊâπÔºåÁ¥ØÁ©ç 52 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 14 ÊâπÔºåÁ¥ØÁ©ç 56 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 15 ÊâπÔºåÁ¥ØÁ©ç 60 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 16 ÊâπÔºåÁ¥ØÁ©ç 64 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 17 ÊâπÔºåÁ¥ØÁ©ç 68 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 18 ÊâπÔºåÁ¥ØÁ©ç 72 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 19 ÊâπÔºåÁ¥ØÁ©ç 76 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 20 ÊâπÔºåÁ¥ØÁ©ç 80 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 21 ÊâπÔºåÁ¥ØÁ©ç 84 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 22 ÊâπÔºåÁ¥ØÁ©ç 88 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 23 ÊâπÔºåÁ¥ØÁ©ç 92 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 24 ÊâπÔºåÁ¥ØÁ©ç 96 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 25 ÊâπÔºåÁ¥ØÁ©ç 100 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 26 ÊâπÔºåÁ¥ØÁ©ç 104 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 27 ÊâπÔºåÁ¥ØÁ©ç 108 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 28 ÊâπÔºåÁ¥ØÁ©ç 112 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 29 ÊâπÔºåÁ¥ØÁ©ç 116 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 30 ÊâπÔºåÁ¥ØÁ©ç 120 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 31 ÊâπÔºåÁ¥ØÁ©ç 124 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 32 ÊâπÔºåÁ¥ØÁ©ç 128 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 33 ÊâπÔºåÁ¥ØÁ©ç 132 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 34 ÊâπÔºåÁ¥ØÁ©ç 136 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 35 ÊâπÔºåÁ¥ØÁ©ç 140 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 36 ÊâπÔºåÁ¥ØÁ©ç 144 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 37 ÊâπÔºåÁ¥ØÁ©ç 148 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 38 ÊâπÔºåÁ¥ØÁ©ç 152 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 39 ÊâπÔºåÁ¥ØÁ©ç 156 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 40 ÊâπÔºåÁ¥ØÁ©ç 160 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 41 ÊâπÔºåÁ¥ØÁ©ç 164 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 42 ÊâπÔºåÁ¥ØÁ©ç 168 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 43 ÊâπÔºåÁ¥ØÁ©ç 172 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 44 ÊâπÔºåÁ¥ØÁ©ç 176 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 45 ÊâπÔºåÁ¥ØÁ©ç 180 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 46 ÊâπÔºåÁ¥ØÁ©ç 184 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 47 ÊâπÔºåÁ¥ØÁ©ç 188 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 48 ÊâπÔºåÁ¥ØÁ©ç 192 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 49 ÊâπÔºåÁ¥ØÁ©ç 196 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 50 ÊâπÔºåÁ¥ØÁ©ç 200 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 51 ÊâπÔºåÁ¥ØÁ©ç 204 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 52 ÊâπÔºåÁ¥ØÁ©ç 208 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 53 ÊâπÔºåÁ¥ØÁ©ç 212 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 54 ÊâπÔºåÁ¥ØÁ©ç 216 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 55 ÊâπÔºåÁ¥ØÁ©ç 220 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 56 ÊâπÔºåÁ¥ØÁ©ç 224 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 57 ÊâπÔºåÁ¥ØÁ©ç 228 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 58 ÊâπÔºåÁ¥ØÁ©ç 232 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 59 ÊâπÔºåÁ¥ØÁ©ç 236 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 60 ÊâπÔºåÁ¥ØÁ©ç 240 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 61 ÊâπÔºåÁ¥ØÁ©ç 244 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 62 ÊâπÔºåÁ¥ØÁ©ç 248 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 63 ÊâπÔºåÁ¥ØÁ©ç 252 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 64 ÊâπÔºåÁ¥ØÁ©ç 256 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 65 ÊâπÔºåÁ¥ØÁ©ç 260 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 66 ÊâπÔºåÁ¥ØÁ©ç 264 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 67 ÊâπÔºåÁ¥ØÁ©ç 268 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 68 ÊâπÔºåÁ¥ØÁ©ç 272 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 69 ÊâπÔºåÁ¥ØÁ©ç 276 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 70 ÊâπÔºåÁ¥ØÁ©ç 280 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 71 ÊâπÔºåÁ¥ØÁ©ç 284 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 72 ÊâπÔºåÁ¥ØÁ©ç 288 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 73 ÊâπÔºåÁ¥ØÁ©ç 292 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 74 ÊâπÔºåÁ¥ØÁ©ç 296 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 75 ÊâπÔºåÁ¥ØÁ©ç 300 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 76 ÊâπÔºåÁ¥ØÁ©ç 304 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 77 ÊâπÔºåÁ¥ØÁ©ç 308 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 78 ÊâπÔºåÁ¥ØÁ©ç 312 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 79 ÊâπÔºåÁ¥ØÁ©ç 316 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 80 ÊâπÔºåÁ¥ØÁ©ç 320 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 81 ÊâπÔºåÁ¥ØÁ©ç 324 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 82 ÊâπÔºåÁ¥ØÁ©ç 328 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 83 ÊâπÔºåÁ¥ØÁ©ç 332 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 84 ÊâπÔºåÁ¥ØÁ©ç 336 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 85 ÊâπÔºåÁ¥ØÁ©ç 340 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 86 ÊâπÔºåÁ¥ØÁ©ç 344 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 87 ÊâπÔºåÁ¥ØÁ©ç 348 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 88 ÊâπÔºåÁ¥ØÁ©ç 352 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 89 ÊâπÔºåÁ¥ØÁ©ç 356 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 90 ÊâπÔºåÁ¥ØÁ©ç 360 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 91 ÊâπÔºåÁ¥ØÁ©ç 364 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 92 ÊâπÔºåÁ¥ØÁ©ç 368 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 93 ÊâπÔºåÁ¥ØÁ©ç 372 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 94 ÊâπÔºåÁ¥ØÁ©ç 376 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 95 ÊâπÔºåÁ¥ØÁ©ç 380 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 96 ÊâπÔºåÁ¥ØÁ©ç 384 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 97 ÊâπÔºåÁ¥ØÁ©ç 388 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 98 ÊâπÔºåÁ¥ØÁ©ç 392 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 99 ÊâπÔºåÁ¥ØÁ©ç 396 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 100 ÊâπÔºåÁ¥ØÁ©ç 400 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 101 ÊâπÔºåÁ¥ØÁ©ç 404 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 102 ÊâπÔºåÁ¥ØÁ©ç 408 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 103 ÊâπÔºåÁ¥ØÁ©ç 412 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 104 ÊâπÔºåÁ¥ØÁ©ç 416 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 105 ÊâπÔºåÁ¥ØÁ©ç 420 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 106 ÊâπÔºåÁ¥ØÁ©ç 424 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 107 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 108 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 109 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 110 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 111 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 112 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 113 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 114 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 115 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 116 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 117 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 118 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 119 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 120 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 121 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 122 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 123 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 124 ÊâπÔºåÁ¥ØÁ©ç 426 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 125 ÊâπÔºåÁ¥ØÁ©ç 427 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 126 ÊâπÔºåÁ¥ØÁ©ç 427 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 127 ÊâπÔºåÁ¥ØÁ©ç 427 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 128 ÊâπÔºåÁ¥ØÁ©ç 427 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 129 ÊâπÔºåÁ¥ØÁ©ç 427 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 130 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 131 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 132 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 133 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 134 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 135 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 136 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 137 ÊâπÔºåÁ¥ØÁ©ç 428 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 138 ÊâπÔºåÁ¥ØÁ©ç 431 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 139 ÊâπÔºåÁ¥ØÁ©ç 435 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 140 ÊâπÔºåÁ¥ØÁ©ç 439 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 141 ÊâπÔºåÁ¥ØÁ©ç 443 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 142 ÊâπÔºåÁ¥ØÁ©ç 447 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 143 ÊâπÔºåÁ¥ØÁ©ç 451 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 144 ÊâπÔºåÁ¥ØÁ©ç 455 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 145 ÊâπÔºåÁ¥ØÁ©ç 459 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 146 ÊâπÔºåÁ¥ØÁ©ç 463 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 147 ÊâπÔºåÁ¥ØÁ©ç 467 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 148 ÊâπÔºåÁ¥ØÁ©ç 471 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 149 ÊâπÔºåÁ¥ØÁ©ç 475 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 150 ÊâπÔºåÁ¥ØÁ©ç 479 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 151 ÊâπÔºåÁ¥ØÁ©ç 483 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 152 ÊâπÔºåÁ¥ØÁ©ç 487 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 153 ÊâπÔºåÁ¥ØÁ©ç 491 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 154 ÊâπÔºåÁ¥ØÁ©ç 495 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 155 ÊâπÔºåÁ¥ØÁ©ç 499 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 156 ÊâπÔºåÁ¥ØÁ©ç 503 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 157 ÊâπÔºåÁ¥ØÁ©ç 507 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 158 ÊâπÔºåÁ¥ØÁ©ç 511 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 159 ÊâπÔºåÁ¥ØÁ©ç 515 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 160 ÊâπÔºåÁ¥ØÁ©ç 519 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 161 ÊâπÔºåÁ¥ØÁ©ç 523 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 162 ÊâπÔºåÁ¥ØÁ©ç 527 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 163 ÊâπÔºåÁ¥ØÁ©ç 531 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 164 ÊâπÔºåÁ¥ØÁ©ç 535 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 165 ÊâπÔºåÁ¥ØÁ©ç 539 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 166 ÊâπÔºåÁ¥ØÁ©ç 543 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 167 ÊâπÔºåÁ¥ØÁ©ç 547 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 168 ÊâπÔºåÁ¥ØÁ©ç 551 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 169 ÊâπÔºåÁ¥ØÁ©ç 555 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 170 ÊâπÔºåÁ¥ØÁ©ç 559 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 171 ÊâπÔºåÁ¥ØÁ©ç 563 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 172 ÊâπÔºåÁ¥ØÁ©ç 567 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 173 ÊâπÔºåÁ¥ØÁ©ç 571 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 174 ÊâπÔºåÁ¥ØÁ©ç 575 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 175 ÊâπÔºåÁ¥ØÁ©ç 579 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 176 ÊâπÔºåÁ¥ØÁ©ç 583 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 177 ÊâπÔºåÁ¥ØÁ©ç 587 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 178 ÊâπÔºåÁ¥ØÁ©ç 591 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 179 ÊâπÔºåÁ¥ØÁ©ç 595 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 180 ÊâπÔºåÁ¥ØÁ©ç 599 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 181 ÊâπÔºåÁ¥ØÁ©ç 603 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 182 ÊâπÔºåÁ¥ØÁ©ç 607 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 183 ÊâπÔºåÁ¥ØÁ©ç 611 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 184 ÊâπÔºåÁ¥ØÁ©ç 615 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 185 ÊâπÔºåÁ¥ØÁ©ç 619 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 186 ÊâπÔºåÁ¥ØÁ©ç 623 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 187 ÊâπÔºåÁ¥ØÁ©ç 627 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 188 ÊâπÔºåÁ¥ØÁ©ç 631 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 189 ÊâπÔºåÁ¥ØÁ©ç 635 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 190 ÊâπÔºåÁ¥ØÁ©ç 639 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 191 ÊâπÔºåÁ¥ØÁ©ç 643 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 192 ÊâπÔºåÁ¥ØÁ©ç 647 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 193 ÊâπÔºåÁ¥ØÁ©ç 651 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 194 ÊâπÔºåÁ¥ØÁ©ç 655 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 195 ÊâπÔºåÁ¥ØÁ©ç 659 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 196 ÊâπÔºåÁ¥ØÁ©ç 663 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 197 ÊâπÔºåÁ¥ØÁ©ç 667 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 198 ÊâπÔºåÁ¥ØÁ©ç 671 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 199 ÊâπÔºåÁ¥ØÁ©ç 675 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 200 ÊâπÔºåÁ¥ØÁ©ç 679 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 201 ÊâπÔºåÁ¥ØÁ©ç 683 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 202 ÊâπÔºåÁ¥ØÁ©ç 687 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 203 ÊâπÔºåÁ¥ØÁ©ç 691 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 204 ÊâπÔºåÁ¥ØÁ©ç 695 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 205 ÊâπÔºåÁ¥ØÁ©ç 699 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 206 ÊâπÔºåÁ¥ØÁ©ç 703 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 207 ÊâπÔºåÁ¥ØÁ©ç 707 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ 208 ÊâπÔºåÁ¥ØÁ©ç 708 Á≠ÜÁµêÊûúÂØ´ÂÖ• /home/student1/ai/task1_prediction.json\n",
      "üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº /home/student1/ai/task1_prediction.json\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "# === Âü∫Êú¨ÂèÉÊï∏ ===\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "lora_model_path = \"/home/student1/ai/mistral7b-phi-lora/checkpoint-365\"\n",
    "input_file = \"/home/student1/ai/task1_answer.txt\"\n",
    "output_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "batch_size = 4  # ÂèØË™øÊï¥\n",
    "\n",
    "# === ËºâÂÖ•Ê®°ÂûãËàá tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, lora_model_path)\n",
    "model.eval()\n",
    "\n",
    "# === PHI Ê®ôÁ±§ ===\n",
    "phi_labels = [\n",
    "    'PATIENT', 'DOCTOR', 'USERNAME', 'FAMILYNAME', 'PERSONALNAME', 'PROFESSION',\n",
    "    'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY',\n",
    "    'DISTRICT', 'COUNTY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "    'AGE', 'DATE', 'TIME', 'DURATION', 'SET',\n",
    "    'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDRESS',\n",
    "    'SOCIAL_SECURITY_NUMBER', 'MEDICAL_RECORD_NUMBER', 'HEALTH_PLAN_NUMBER', 'ACCOUNT_NUMBER',\n",
    "    'LICENSE_NUMBER', 'VEHICLE_ID', 'DEVICE_ID', 'BIOMETRIC_ID', 'ID_NUMBER',\n",
    "    'OTHER'\n",
    "]\n",
    "\n",
    "# === ËÆÄÂèñË≥áÊñô‰∏¶Ë£Ω‰Ωú Prompt ===\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        uid, text = line.strip().split(\"\\t\", 1)\n",
    "        prompt = f\"\"\"You are a professional information extraction assistant. Your task is to accurately extract sensitive entities explicitly mentioned in the provided text. You MUST NOT make any assumptions or infer missing information. Output only what is present in the text. Respond in JSON format, with each entity category as a key and a list of extracted values as the value.\n",
    "\n",
    "Definitions and examples:\n",
    "\n",
    "- **PATIENT**: A person receiving medical treatment or care. \n",
    "  Example: \"Patient John Doe was admitted for surgery.\" ‚Üí PATIENT: [\"John Doe\"]\n",
    "\n",
    "- **DOCTOR**: A healthcare professional diagnosing or treating patients. May include prefixes like \"Dr.\" or Chinese names like \"Èô≥ÈÜ´Áîü\".\n",
    "  Example: \"Dr. Smith reviewed the report.\" ‚Üí DOCTOR: [\"Smith\"]\n",
    "  Example: \"ÈÄô‰ªΩÂ†±ÂëäÁî±Èô≥ÈÜ´ÁîüÁ∞ΩÁΩ≤„ÄÇ\" ‚Üí DOCTOR: [\"Èô≥\"]\n",
    "\n",
    "- **PERSONALNAME**: A general personal name (full or partial).\n",
    "  Example: \"Mary Johnson\" ‚Üí PERSONALNAME: [\"Mary Johnson\"]\n",
    "\n",
    "- **FAMILYNAME**: A surname, typically the last name.\n",
    "  Example: \"Chen\" in \"Li Chen\" ‚Üí FAMILYNAME: [\"Chen\"]\n",
    "\n",
    "- **PROFESSION**: Occupations or job titles.\n",
    "  Example: \"She is a talented psychologist.\" ‚Üí PROFESSION: [\"psychologist\"]\n",
    "\n",
    "- **HOSPITAL**: Full names of hospitals or medical centers.\n",
    "  Example: \"Rubino Hospital\" ‚Üí HOSPITAL: [\"Rubino Hospital\"]\n",
    "\n",
    "- **DEPARTMENT**: Medical departments, units, clinics, or wards.\n",
    "  Example: \"She works in the Radiology Department.\" ‚Üí DEPARTMENT: [\"Radiology Department\"]\n",
    "  Example: \"ÁóÖÊÇ£Âú®ËÖ´Áò§ÁßëÊé•ÂèóÊ≤ªÁôÇ„ÄÇ\" ‚Üí DEPARTMENT: [\"ËÖ´Áò§Áßë\"]\n",
    "\n",
    "- **ORGANIZATION**: Non-medical organizations or companies.\n",
    "  Example: \"He works at Microsoft.\" ‚Üí ORGANIZATION: [\"Microsoft\"]\n",
    "\n",
    "- **STREET**: Street or road names.\n",
    "  Example: \"123 Main Street\" ‚Üí STREET: [\"Main Street\"]\n",
    "\n",
    "- **CITY**: Cities or towns.\n",
    "  Example: \"She lives in San Francisco.\" ‚Üí CITY: [\"San Francisco\"]\n",
    "\n",
    "- **STATE**: States or provinces.\n",
    "  Example: \"Texas\" ‚Üí STATE: [\"Texas\"]\n",
    "\n",
    "- **ZIP**: Postal codes.\n",
    "  Example: \"3137\" ‚Üí ZIP: [\"3137\"]\n",
    "\n",
    "- **COUNTRY**, **COUNTY**, **DISTRICT**, **LOCATION-OTHER**: Regional names or locations.\n",
    "\n",
    "- **AGE**: Numerical or textual representation of age.\n",
    "  Example: \"She is 78 years old.\" ‚Üí AGE: [\"78 \"]\n",
    "\n",
    "- **DATE**: Full or partial calendar dates, including relative ones like \"yesterday\", \"Sunday\", \"June 6, 2063\".\n",
    "  Example: \"The appointment is on Tuesday.\" ‚Üí DATE: [\"Tuesday\"]\n",
    "  Example: \"Her record was updated June 6, 2063.\" ‚Üí DATE: [\"June 6, 2063\"]\n",
    "\n",
    "- **TIME**: Clock times or parts of the day.\n",
    "  Example: \"09:00 AM\" or \"evening\" or \"yesterday\"\n",
    "\n",
    "- **DURATION**: Time intervals or lengths of time.\n",
    "  Example: \"two weeks\", \"three hours\"\n",
    "\n",
    "- **MEDICAL_RECORD_NUMBER**: Patient-specific alphanumeric IDs for record tracking, often with a dot and 2‚Äì3 uppercase letters (e.g., \"719660.OVY\").\n",
    "  Example: \"The record number is 222485.OEE.\" ‚Üí MEDICAL_RECORD_NUMBER: [\"222485.OEE\"]\n",
    "  Example: \"Á∑®ËôüÁÇ∫ 719660.OVY\" ‚Üí MEDICAL_RECORD_NUMBER: [\"719660.OVY\"]\n",
    "\n",
    "- **ID_NUMBER**: General-purpose alphanumeric identifiers not in MEDICAL_RECORD_NUMBER format.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "output:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "        data.append((uid, prompt))\n",
    "\n",
    "# === ÂàÜÊâπÊé®Ë´ñÂáΩÂºè ===\n",
    "def batch_predict(batch_prompts):\n",
    "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.2,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded_list = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "    return decoded_list\n",
    "\n",
    "# === ‰∏ªÊé®Ë´ñÊµÅÁ®ãÔºåÊØèÊâπÂ≠òÊ™î ===\n",
    "predictions = {}\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    uids, prompts = zip(*batch)\n",
    "    decoded_outputs = batch_predict(prompts)\n",
    "\n",
    "    for uid, decoded in zip(uids, decoded_outputs):\n",
    "        try:\n",
    "            json_start = decoded.index(\"{\")\n",
    "            json_str = decoded[json_start:]\n",
    "            parsed = json.loads(json_str)\n",
    "        except Exception:\n",
    "            parsed = {}\n",
    "        predictions[uid] = parsed\n",
    "\n",
    "    # ÊØèÊâπÂØ´Ê™î‰∏ÄÊ¨°ÔºåË¶ÜËìãÊ™îÊ°à\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Â∑≤ÂÆåÊàêÁ¨¨ {i // batch_size + 1} ÊâπÔºåÁ¥ØÁ©ç {len(predictions)} Á≠ÜÁµêÊûúÂØ´ÂÖ• {output_file}\")\n",
    "\n",
    "print(f\"üéâ ÂÖ®ÈÉ®È†êÊ∏¨ÂÆåÊàêÔºåÁµêÊûúÂ∑≤Â≠òÊñº {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d20822",
   "metadata": {},
   "source": [
    "### Ë≥áÊñôÂæåËôïÁêÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d969c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ËôïÁêÜÂÆåÊàêÔºåDr. ÁßªÈô§ + Á∑®ËôüÈ°ûÂà•ÈáçÂàÜÈ°ûÂ∑≤ÂÑ≤Â≠òËá≥Ôºö/home/student1/ai/task1_prediction_cleaned.json\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import re\n",
    "\n",
    "input_file = \"/home/student1/ai/task1_prediction.json\"\n",
    "output_file = \"/home/student1/ai/task1_prediction_cleaned.json\"\n",
    "\n",
    "def remove_doctor_prefix(name):\n",
    "    return re.sub(r'(?i)^Dr\\.?\\s+', '', name).strip()\n",
    "\n",
    "# Áî®ÊñºËæ®Ë≠ò medical record Ê†ºÂºèÔºàÊï∏Â≠ó.Â§ßÂØ´Â≠óÊØçÔºâ\n",
    "med_record_pattern = re.compile(r\"^\\d+\\.[A-Z]{2,}$\")\n",
    "\n",
    "# ËÆÄÂÖ•ÂéüÂßãÈ†êÊ∏¨ÁµêÊûú\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "for uid, entity_dict in predictions.items():\n",
    "    new_medical_record_numbers = []\n",
    "\n",
    "    # ÁßªÈô§ DOCTOR Ê¨Ñ‰Ωç‰∏≠ÁöÑ Dr.\n",
    "    if \"DOCTOR\" in entity_dict and isinstance(entity_dict[\"DOCTOR\"], list):\n",
    "        cleaned = []\n",
    "        for name in entity_dict[\"DOCTOR\"]:\n",
    "            if isinstance(name, str):\n",
    "                cleaned.append(remove_doctor_prefix(name))\n",
    "            else:\n",
    "                cleaned.append(name)  # ÊàñÁï•ÈÅéÁÑ°ÊïàÂÄºÔºåÁî® continue\n",
    "        entity_dict[\"DOCTOR\"] = cleaned\n",
    "\n",
    "\n",
    "    # Ê™¢Êü•ÊØè‰∏ÄÊ¨ÑÊòØÂê¶ÊúâÁ¨¶Âêà MEDICAL_RECORD_NUMBER Ê†ºÂºèÁöÑÂÄº\n",
    "    for ent_type in list(entity_dict.keys()):\n",
    "        values = entity_dict[ent_type]\n",
    "        if not isinstance(values, list):\n",
    "            continue\n",
    "\n",
    "        retained = []\n",
    "        for val in values:\n",
    "            if isinstance(val, str) and med_record_pattern.match(val):\n",
    "                new_medical_record_numbers.append(val)\n",
    "            else:\n",
    "                retained.append(val)\n",
    "\n",
    "        # Êõ¥Êñ∞ÂéüÊ¨Ñ‰ΩçÔºåÊàñÁßªÈô§Á©∫Ê¨Ñ‰Ωç\n",
    "        if retained:\n",
    "            entity_dict[ent_type] = retained\n",
    "        else:\n",
    "            del entity_dict[ent_type]\n",
    "\n",
    "    # Âä†Âà∞ MEDICAL_RECORD_NUMBER È°ûÂà•\n",
    "    if new_medical_record_numbers:\n",
    "        if \"MEDICAL_RECORD_NUMBER\" not in entity_dict:\n",
    "            entity_dict[\"MEDICAL_RECORD_NUMBER\"] = []\n",
    "        entity_dict[\"MEDICAL_RECORD_NUMBER\"].extend(new_medical_record_numbers)\n",
    "\n",
    "# ÂØ´ÂÖ•Êñ∞Ê™îÊ°à\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ ËôïÁêÜÂÆåÊàêÔºåDr. ÁßªÈô§ + Á∑®ËôüÈ°ûÂà•ÈáçÂàÜÈ°ûÂ∑≤ÂÑ≤Â≠òËá≥Ôºö{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6fb046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÂÖ±Âêà‰Ωµ 708 Á≠ÜË≥áÊñôÔºåËº∏Âá∫Ëá≥Ôºö/home/student1/ai/predictions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# === Ê™îÊ°àË∑ØÂæë ===\n",
    "ground_truth_path = \"/home/student1/ai/GPT/merged_phi_by_audio.json\"\n",
    "prediction_path = \"/home/student1/ai/task1_prediction_cleaned.json\"\n",
    "raw_doctor_path = \"/home/student1/ai/GPT/doctors_by_line.json\"\n",
    "zhanswer_path = \"/home/student1/ai/GPT/zhanswer.json\"\n",
    "output_path = \"/home/student1/ai/predictions.json\"\n",
    "\n",
    "# === ËÆÄÂèñ JSON Ê™î ===\n",
    "with open(ground_truth_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "with open(prediction_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "with open(raw_doctor_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_doctor_predictions = json.load(f)\n",
    "\n",
    "with open(zhanswer_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    zh_predictions = json.load(f)\n",
    "\n",
    "# === Â∑•ÂÖ∑ÂáΩÊï∏ ===\n",
    "def is_medical_record_number(text):\n",
    "    text = text.strip()\n",
    "    return bool(re.match(r\"^\\d+\\.[A-Z]{2,}$\", text)) or (\n",
    "        text.count('-') >= 2 and re.search(r\"[A-Za-z]\", text) and re.search(r\"\\d\", text)\n",
    "    )\n",
    "\n",
    "def is_similar(a, b, threshold=0.85):\n",
    "    a_lower = a.lower().strip()\n",
    "    b_lower = b.lower().strip()\n",
    "    return (\n",
    "        a_lower == b_lower or\n",
    "        a_lower in b_lower or\n",
    "        b_lower in a_lower or\n",
    "        SequenceMatcher(None, a_lower, b_lower).ratio() >= threshold\n",
    "    )\n",
    "\n",
    "def normalize_labels(entity_dict):\n",
    "    normalized = {}\n",
    "    for label, values in entity_dict.items():\n",
    "        for val in values:\n",
    "            val = val.strip()\n",
    "            label_upper = label.upper()\n",
    "            val_upper = val.upper()\n",
    "\n",
    "            # ‰øÆÊ≠£ ZIP ÂâçÁ∂¥\n",
    "            if label_upper == \"ZIP\" and val_upper.startswith(\"ZIP\"):\n",
    "                val = val[3:].lstrip(\".:Ôºö \\u3000\").strip()\n",
    "\n",
    "            # Ê†πÊìöÂÖßÂÆπËàáÊ†ºÂºè‰øÆÊ≠£Ê®ôÁ±§\n",
    "            text_lower = val.lower()\n",
    "            if is_medical_record_number(val):\n",
    "                true_label = \"MEDICAL_RECORD_NUMBER\"\n",
    "            elif \"street\" in text_lower:\n",
    "                true_label = \"STREET\"\n",
    "            elif \"hospital\" in text_lower:\n",
    "                true_label = \"HOSPITAL\"\n",
    "            elif \"dr.\" in text_lower:\n",
    "                true_label = \"DOCTOR\"\n",
    "            else:\n",
    "                true_label = \"HOSPITAL\" if \"hospital\" in label.lower() else label\n",
    "\n",
    "            if true_label not in normalized:\n",
    "                normalized[true_label] = set()\n",
    "            normalized[true_label].add(val)\n",
    "\n",
    "    return {k: list(v) for k, v in normalized.items()}\n",
    "\n",
    "# === Âêà‰Ωµ zhanswer.json ÈÄ≤ predictions ===\n",
    "for audio_id, zh_data in zh_predictions.items():\n",
    "    if audio_id not in predictions:\n",
    "        predictions[audio_id] = zh_data\n",
    "    else:\n",
    "        for label, zh_values in zh_data.items():\n",
    "            if label not in predictions[audio_id]:\n",
    "                predictions[audio_id][label] = zh_values\n",
    "            else:\n",
    "                predictions[audio_id][label].extend(zh_values)\n",
    "\n",
    "# === ÂéªÈô§ÈáçË§á + ÂéªÁ©∫ÁôΩ ===\n",
    "for audio_id, entity_dict in predictions.items():\n",
    "    for label in entity_dict:\n",
    "        entity_dict[label] = list(set([v.strip() for v in entity_dict[label] if v.strip()]))\n",
    "\n",
    "# === ‰ª•ÊâÄÊúâ IDÔºàÂåÖÂê´ ground_truth„ÄÅpredictions„ÄÅzhanswerÔºâÁÇ∫‰∏ªÂêà‰Ωµ ===\n",
    "all_audio_ids = set(list(ground_truth.keys()) + list(predictions.keys()) + list(zh_predictions.keys()))\n",
    "merged_predictions = {}\n",
    "\n",
    "for audio_id in all_audio_ids:\n",
    "    gt = normalize_labels(ground_truth.get(audio_id, {}))\n",
    "    pred = normalize_labels(predictions.get(audio_id, {}))\n",
    "    merged = {}\n",
    "\n",
    "    # Âä†ÂÖ•È†êÊ∏¨Ë≥áÊñô\n",
    "    for label, pred_values in pred.items():\n",
    "        merged[label] = list(set(pred_values))\n",
    "\n",
    "    # Ë£úÂÖ• ground_truth Áº∫ÁöÑ\n",
    "    for label, gt_values in gt.items():\n",
    "        if label not in merged:\n",
    "            merged[label] = []\n",
    "        for gt_val in sorted(gt_values, key=lambda x: -len(x.strip())):\n",
    "            if not any(is_similar(gt_val, pred_val) for pred_val in merged[label]):\n",
    "                merged[label].append(gt_val)\n",
    "\n",
    "    # DOCTOR Áî®ÂéüÂßã DOCTOR ÁÇ∫‰∏ª\n",
    "    if audio_id in raw_doctor_predictions and \"DOCTOR\" in raw_doctor_predictions[audio_id]:\n",
    "        merged[\"DOCTOR\"] = raw_doctor_predictions[audio_id][\"DOCTOR\"]\n",
    "\n",
    "    merged_predictions[audio_id] = merged\n",
    "\n",
    "# === Ëº∏Âá∫ÁµêÊûú ===\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ ÂÖ±Âêà‰Ωµ {len(merged_predictions)} Á≠ÜË≥áÊñôÔºåËº∏Âá∫Ëá≥Ôºö{output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684613e",
   "metadata": {},
   "source": [
    "### ÊâæÊôÇÈñìÊà≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cc3766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Â∞çÈΩäÂÆåÊàêÔºåËº∏Âá∫Âà∞Ôºö/home/student1/ai/task2_answer.txt\n",
      "ü™µ Êú™ÂåπÈÖçÁöÑË®òÈåÑÂ∑≤ÂØ´ÂÖ•Ôºö/home/student1/ai/not_found_log.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# === Ë∑ØÂæëË®≠ÂÆö ===\n",
    "prediction_path = \"/home/student1/ai/predictions.json\"\n",
    "timestamp_path = \"/home/student1/ai/model_result/task1/v1/val_time_step.json\"\n",
    "output_path = \"/home/student1/ai/task2_answer.txt\"\n",
    "not_found_log_path = \"/home/student1/ai/not_found_log.txt\"\n",
    "\n",
    "# === ËÆÄÂèñÊ™îÊ°à ===\n",
    "with open(prediction_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    predictions = json.load(f)\n",
    "with open(timestamp_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    timestamps = json.load(f)\n",
    "\n",
    "# === Ê≠£Ë¶èÂåñÊñáÊú¨ÂáΩÂºè ===\n",
    "def normalize_text(text):\n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(map(str, text))\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# === ÂñÆÂ≠óÂ∞çÈΩäÂáΩÂºè ===\n",
    "def find_phrase_timestamp(phrase, words_list, max_window=7):\n",
    "    phrase_norm = normalize_text(phrase).split()\n",
    "    best_score = 0\n",
    "    best_span = None\n",
    "    best_match = None\n",
    "\n",
    "    # Â§öË©ûÁµÑÊªëÂãïË¶ñÁ™óÊØîÂ∞ç\n",
    "    for window_size in range(min(len(phrase_norm), max_window), 0, -1):\n",
    "        for i in range(len(words_list) - window_size + 1):\n",
    "            window = words_list[i:i + window_size]\n",
    "            window_text = \" \".join([w[\"word\"] for w in window])\n",
    "            score = SequenceMatcher(None, \" \".join(phrase_norm), normalize_text(window_text)).ratio()\n",
    "            if score > best_score and score >= 0.6:\n",
    "                best_score = score\n",
    "                best_span = (window[0][\"start\"], window[-1][\"end\"])\n",
    "                best_match = window_text\n",
    "\n",
    "        if best_span:\n",
    "            return best_span[0], best_span[1], best_match\n",
    "\n",
    "    # ÂñÆÂ≠óÁ≤æÊ∫ñÊØîÂ∞ç\n",
    "    for w in words_list:\n",
    "        if normalize_text(w[\"word\"]) == \" \".join(phrase_norm):\n",
    "            return w[\"start\"], w[\"end\"], w[\"word\"]\n",
    "\n",
    "    # ÊúÄÁõ∏‰ººÂñÆÂ≠óÊØîÂ∞ç\n",
    "    for w in words_list:\n",
    "        score = SequenceMatcher(None, \" \".join(phrase_norm), normalize_text(w[\"word\"])).ratio()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = w\n",
    "    if best_score >= 0.6:\n",
    "        return best_match[\"start\"], best_match[\"end\"], best_match[\"word\"]\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "# === ‰∏ªËôïÁêÜÊµÅÁ®ã ===\n",
    "not_found_log = []\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for uid, entities in predictions.items():\n",
    "        ts = timestamps.get(uid)\n",
    "        if not ts or not ts.get(\"segments\"):\n",
    "            continue\n",
    "\n",
    "        all_words = []\n",
    "        for seg in ts[\"segments\"]:\n",
    "            all_words.extend(seg.get(\"words\", []))\n",
    "\n",
    "        for ent_type, words in entities.items():\n",
    "            if not words:\n",
    "                continue\n",
    "\n",
    "            for word in words:\n",
    "                start, end, matched = find_phrase_timestamp(word, all_words)\n",
    "\n",
    "                # Ëã•ÁÑ°Ê≥ïÂåπÈÖç ‚Üí ‰ΩøÁî®Â∞æÁ´ØÊé®‰º∞Ê≥ï\n",
    "                if start is None or end is None or start <= 0.0 or end <= 0.0:\n",
    "                    valid_ends = [w for w in reversed(all_words) if \"end\" in w and isinstance(w[\"end\"], (float, int))]\n",
    "                    if valid_ends:\n",
    "                        fallback_start = valid_ends[0][\"end\"]\n",
    "                        fallback_end = fallback_start + 0.5\n",
    "                        fout.write(f\"{uid}\\t{ent_type}\\t{fallback_start:.3f}\\t{fallback_end:.3f}\\t{word}\\n\")\n",
    "                    else:\n",
    "                        not_found_log.append((uid, ent_type, word))\n",
    "                    continue\n",
    "\n",
    "                fout.write(f\"{uid}\\t{ent_type}\\t{start:.3f}\\t{end:.3f}\\t{matched}\\n\")\n",
    "\n",
    "# === ÂØ´ÂÖ•Êâæ‰∏çÂà∞ÊôÇÈñìÊà≥ÁöÑÂØ¶È´î ===\n",
    "with open(not_found_log_path, \"w\", encoding=\"utf-8\") as logf:\n",
    "    for uid, ent_type, word in not_found_log:\n",
    "        logf.write(f\"{uid}\\t{ent_type}\\t{word}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Â∞çÈΩäÂÆåÊàêÔºåËº∏Âá∫Âà∞Ôºö{output_path}\")\n",
    "print(f\"ü™µ Êú™ÂåπÈÖçÁöÑË®òÈåÑÂ∑≤ÂØ´ÂÖ•Ôºö{not_found_log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c2e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ê®ôÁ±§Âá∫ÁèæÊ¨°Êï∏Áµ±Ë®àÔºö\n",
      "DOCTOR     835\n",
      "DATE       679\n",
      "PATIENT    324\n",
      "ID_NUMBER  295\n",
      "MEDICAL_RECORD_NUMBER 244\n",
      "CITY       199\n",
      "DEPARTMENT 160\n",
      "TIME       153\n",
      "HOSPITAL   147\n",
      "ZIP        105\n",
      "STREET     105\n",
      "STATE      94\n",
      "AGE        50\n",
      "DURATION   43\n",
      "PERSONALNAME 35\n",
      "FAMILYNAME 25\n",
      "ORGANIZATION 20\n",
      "LOCATION-OTHER 18\n",
      "SET        17\n",
      "LOCATION   8\n",
      "PROFESSION 7\n",
      "DISTANCE   5\n",
      "LAB_NUMBER 5\n",
      "DIAGNOSIS  4\n",
      "NUMBER     2\n",
      "TOWN       2\n",
      "YEAR       2\n",
      "COMPANY    1\n",
      "POSTAL_CODE 1\n",
      "FOOD       1\n",
      "LABEL_NUMBER 1\n",
      "MEDICAL_TERM 1\n",
      "ORGAN      1\n",
      "SIZE       1\n",
      "NOW        1\n",
      "TEACHER    1\n",
      "DISEASE    1\n",
      "DIAMETER   1\n",
      "POSTALCODE 1\n",
      "FINDING    1\n",
      "SPECIMEN   1\n",
      "OVARIAN_MASS 1\n",
      "PHONE      1\n",
      "DISTRICT   1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "input_path = \"/home/student1/ai/task2_answer.txt\"\n",
    "label_counter = Counter()\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) >= 2:\n",
    "            label = parts[1]\n",
    "            label_counter[label] += 1\n",
    "\n",
    "# Ëº∏Âá∫Áµ±Ë®àÁµêÊûú\n",
    "print(\"üìä Ê®ôÁ±§Âá∫ÁèæÊ¨°Êï∏Áµ±Ë®àÔºö\")\n",
    "for label, count in label_counter.most_common():\n",
    "    print(f\"{label:10} {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
